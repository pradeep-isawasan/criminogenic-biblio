<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>topic_modeling ‚Äì Criminogenic Bibliometric Analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Criminogenic Bibliometric Analysis</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../authors.html"> 
<span class="menu-text">Authors</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-analysis-notebooks" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Analysis Notebooks</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-analysis-notebooks">    
        <li>
    <a class="dropdown-item" href="../notebooks/01_preprocess.html">
 <span class="dropdown-text">01 Preprocessing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../notebooks/02_cooccurrence.ipynb">
 <span class="dropdown-text">02 Co-occurrence Network</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../notebooks/03_topic_modeling.html">
 <span class="dropdown-text">03 Topic Modeling</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#topic-modeling---v7" id="toc-topic-modeling---v7" class="nav-link active" data-scroll-target="#topic-modeling---v7">Topic Modeling - v7</a></li>
  <li><a href="#section-0-setup" id="toc-section-0-setup" class="nav-link" data-scroll-target="#section-0-setup">Section 0: Setup</a>
  <ul class="collapse">
  <li><a href="#imports" id="toc-imports" class="nav-link" data-scroll-target="#imports">0.2) Imports</a></li>
  <li><a href="#load-openai-api-key-from-colab-userdata" id="toc-load-openai-api-key-from-colab-userdata" class="nav-link" data-scroll-target="#load-openai-api-key-from-colab-userdata">0.3) Load OpenAI API key from Colab userdata</a></li>
  </ul></li>
  <li><a href="#section-1-data-preparation" id="toc-section-1-data-preparation" class="nav-link" data-scroll-target="#section-1-data-preparation">Section 1: Data Preparation</a>
  <ul class="collapse">
  <li><a href="#load-dataset-from-project-folder" id="toc-load-dataset-from-project-folder" class="nav-link" data-scroll-target="#load-dataset-from-project-folder">1.1) Load dataset from project folder</a></li>
  <li><a href="#remove-duplicates-based-on-unique_id" id="toc-remove-duplicates-based-on-unique_id" class="nav-link" data-scroll-target="#remove-duplicates-based-on-unique_id">1.2) Remove duplicates based on unique_id</a></li>
  <li><a href="#build-specter2-style-text-__text__" id="toc-build-specter2-style-text-__text__" class="nav-link" data-scroll-target="#build-specter2-style-text-__text__">1.3) Build SPECTER2-Style Text (<code>__text__</code>)</a>
  <ul class="collapse">
  <li><a href="#what-happens-in-this-step" id="toc-what-happens-in-this-step" class="nav-link" data-scroll-target="#what-happens-in-this-step">What happens in this step:</a></li>
  <li><a href="#why-this-matters" id="toc-why-this-matters" class="nav-link" data-scroll-target="#why-this-matters">Why this matters</a></li>
  </ul></li>
  <li><a href="#basic-text-cleaning-__clean__" id="toc-basic-text-cleaning-__clean__" class="nav-link" data-scroll-target="#basic-text-cleaning-__clean__">1.4) Basic Text Cleaning ‚Üí <code>__clean__</code></a>
  <ul class="collapse">
  <li><a href="#what-basic_clean-does" id="toc-what-basic_clean-does" class="nav-link" data-scroll-target="#what-basic_clean-does">üîç What <code>basic_clean()</code> does</a></li>
  </ul></li>
  <li><a href="#token-length-analysis" id="toc-token-length-analysis" class="nav-link" data-scroll-target="#token-length-analysis">1.5) Token Length Analysis</a>
  <ul class="collapse">
  <li><a href="#what-we-do-in-this-step" id="toc-what-we-do-in-this-step" class="nav-link" data-scroll-target="#what-we-do-in-this-step">What we do in this step:</a></li>
  </ul></li>
  <li><a href="#text-quality-summary-short-vs-long-documents" id="toc-text-quality-summary-short-vs-long-documents" class="nav-link" data-scroll-target="#text-quality-summary-short-vs-long-documents">1.6) Text Quality Summary (Short vs Long Documents)</a></li>
  <li><a href="#manual-removal-of-low-quality-documents" id="toc-manual-removal-of-low-quality-documents" class="nav-link" data-scroll-target="#manual-removal-of-low-quality-documents">1.7) Manual Removal of Low-Quality Documents</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">1.8) Conclusion</a>
  <ul class="collapse">
  <li><a href="#what-we-accomplished" id="toc-what-we-accomplished" class="nav-link" data-scroll-target="#what-we-accomplished">What we accomplished</a></li>
  <li><a href="#outputs-produced-in-section-1" id="toc-outputs-produced-in-section-1" class="nav-link" data-scroll-target="#outputs-produced-in-section-1">Outputs produced in Section 1</a></li>
  <li><a href="#whats-next" id="toc-whats-next" class="nav-link" data-scroll-target="#whats-next">What‚Äôs next?</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-2-embeddings-specter2" id="toc-section-2-embeddings-specter2" class="nav-link" data-scroll-target="#section-2-embeddings-specter2">Section 2: Embeddings (SPECTER2)</a>
  <ul class="collapse">
  <li><a href="#a-n-gram-nalysis" id="toc-a-n-gram-nalysis" class="nav-link" data-scroll-target="#a-n-gram-nalysis">2.1a) N-gram nalysis</a></li>
  <li><a href="#b-concept-normalization-for-criminogenic" id="toc-b-concept-normalization-for-criminogenic" class="nav-link" data-scroll-target="#b-concept-normalization-for-criminogenic">2.1b) Concept Normalization for Criminogenic</a></li>
  <li><a href="#c-concept-normalization-diagnostics-optional" id="toc-c-concept-normalization-diagnostics-optional" class="nav-link" data-scroll-target="#c-concept-normalization-diagnostics-optional">2.1c) Concept Normalization Diagnostics (Optional)</a></li>
  <li><a href="#build-embedding-text-__embed_text__" id="toc-build-embedding-text-__embed_text__" class="nav-link" data-scroll-target="#build-embedding-text-__embed_text__">2.2) Build Embedding Text (<code>__embed_text__</code>)</a></li>
  <li><a href="#generate-specter2-embeddings" id="toc-generate-specter2-embeddings" class="nav-link" data-scroll-target="#generate-specter2-embeddings">2.3) Generate SPECTER2 Embeddings</a>
  <ul class="collapse">
  <li><a href="#why-specter2" id="toc-why-specter2" class="nav-link" data-scroll-target="#why-specter2">üîç Why SPECTER2?</a></li>
  <li><a href="#input-text-used-for-embedding" id="toc-input-text-used-for-embedding" class="nav-link" data-scroll-target="#input-text-used-for-embedding">üß† Input Text Used for Embedding</a></li>
  <li><a href="#what-happens-during-embedding" id="toc-what-happens-during-embedding" class="nav-link" data-scroll-target="#what-happens-during-embedding">‚öôÔ∏è What Happens During Embedding?</a></li>
  <li><a href="#output-of-this-step" id="toc-output-of-this-step" class="nav-link" data-scroll-target="#output-of-this-step">üì¶ Output of This Step</a></li>
  </ul></li>
  <li><a href="#save-embeddings-for-reuse-optional" id="toc-save-embeddings-for-reuse-optional" class="nav-link" data-scroll-target="#save-embeddings-for-reuse-optional">2.4) Save Embeddings for Reuse (Optional)</a></li>
  <li><a href="#conclusion-1" id="toc-conclusion-1" class="nav-link" data-scroll-target="#conclusion-1">2.5) Conclusion</a>
  <ul class="collapse">
  <li><a href="#what-we-accomplished-1" id="toc-what-we-accomplished-1" class="nav-link" data-scroll-target="#what-we-accomplished-1">‚úî What we accomplished</a></li>
  <li><a href="#outputs-produced-in-section-2" id="toc-outputs-produced-in-section-2" class="nav-link" data-scroll-target="#outputs-produced-in-section-2">üì¶ Outputs produced in Section 2</a></li>
  <li><a href="#whats-next-1" id="toc-whats-next-1" class="nav-link" data-scroll-target="#whats-next-1">üöÄ What‚Äôs next?</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-3-topic-modelling-bertopic" id="toc-section-3-topic-modelling-bertopic" class="nav-link" data-scroll-target="#section-3-topic-modelling-bertopic">Section 3: Topic Modelling (BERTopic)</a>
  <ul class="collapse">
  <li><a href="#build-vectorizer-text-__vectorizer_text__" id="toc-build-vectorizer-text-__vectorizer_text__" class="nav-link" data-scroll-target="#build-vectorizer-text-__vectorizer_text__">3.1) Build Vectorizer Text (<code>__vectorizer_text__</code>)</a>
  <ul class="collapse">
  <li><a href="#a-explore-tfidf-of-non-english-stopwords" id="toc-a-explore-tfidf-of-non-english-stopwords" class="nav-link" data-scroll-target="#a-explore-tfidf-of-non-english-stopwords">3.1a) Explore TF‚ÄìIDF of Non-English Stopwords</a></li>
  <li><a href="#how-to-use-tfidf-insights-before-proceeding-to-step-3.1b" id="toc-how-to-use-tfidf-insights-before-proceeding-to-step-3.1b" class="nav-link" data-scroll-target="#how-to-use-tfidf-insights-before-proceeding-to-step-3.1b">How to Use TF‚ÄìIDF Insights Before Proceeding to Step 3.1b</a></li>
  <li><a href="#b-stopwords-boilerplate-setup-lemma-friendly" id="toc-b-stopwords-boilerplate-setup-lemma-friendly" class="nav-link" data-scroll-target="#b-stopwords-boilerplate-setup-lemma-friendly">üëâ <strong>3.1b Stopwords + Boilerplate Setup (Lemma-Friendly)</strong></a></li>
  <li><a href="#b-define-stopwords-and-boilerplate-terms-lemma-friendly" id="toc-b-define-stopwords-and-boilerplate-terms-lemma-friendly" class="nav-link" data-scroll-target="#b-define-stopwords-and-boilerplate-terms-lemma-friendly">3.1b) Define Stopwords and Boilerplate Terms (Lemma-Friendly)</a></li>
  <li><a href="#c-lemmatization-for-__vectorizer_text__-with-underscore-protection" id="toc-c-lemmatization-for-__vectorizer_text__-with-underscore-protection" class="nav-link" data-scroll-target="#c-lemmatization-for-__vectorizer_text__-with-underscore-protection">3.1c) Lemmatization for <code>__vectorizer_text__</code> (with Underscore Protection)</a></li>
  <li><a href="#d-inspect-stopword-boilerplate-removal-preview-only" id="toc-d-inspect-stopword-boilerplate-removal-preview-only" class="nav-link" data-scroll-target="#d-inspect-stopword-boilerplate-removal-preview-only">3.1d) Inspect Stopword + Boilerplate Removal (Preview Only)</a></li>
  <li><a href="#e-inspect-underscore-protected-tokens-in-__vectorizer_text__" id="toc-e-inspect-underscore-protected-tokens-in-__vectorizer_text__" class="nav-link" data-scroll-target="#e-inspect-underscore-protected-tokens-in-__vectorizer_text__">3.1e) Inspect Underscore-Protected Tokens in <code>__vectorizer_text__</code></a></li>
  <li><a href="#f-conclusion" id="toc-f-conclusion" class="nav-link" data-scroll-target="#f-conclusion">3.1f) Conclusion</a></li>
  <li><a href="#next-step-3.2-prepare-documents-check-embedding-alignment" id="toc-next-step-3.2-prepare-documents-check-embedding-alignment" class="nav-link" data-scroll-target="#next-step-3.2-prepare-documents-check-embedding-alignment">‚ñ∂Ô∏è Next Step: <strong>3.2 Prepare Documents &amp; Check Embedding Alignment</strong></a></li>
  </ul></li>
  <li><a href="#prepare-documents-and-validate-embedding-alignment" id="toc-prepare-documents-and-validate-embedding-alignment" class="nav-link" data-scroll-target="#prepare-documents-and-validate-embedding-alignment">3.2) Prepare Documents and Validate Embedding Alignment</a>
  <ul class="collapse">
  <li><a href="#b-document-embedding-sanity-check" id="toc-b-document-embedding-sanity-check" class="nav-link" data-scroll-target="#b-document-embedding-sanity-check">3.2b) Document &amp; Embedding Sanity Check</a></li>
  </ul></li>
  <li><a href="#bertopic" id="toc-bertopic" class="nav-link" data-scroll-target="#bertopic">3.3) BERTopic</a>
  <ul class="collapse">
  <li><a href="#a-imports-helper-functions" id="toc-a-imports-helper-functions" class="nav-link" data-scroll-target="#a-imports-helper-functions">3.3a) Imports &amp; Helper Functions</a></li>
  <li><a href="#b-parameter-grid-for-bertopic-auto-tuning" id="toc-b-parameter-grid-for-bertopic-auto-tuning" class="nav-link" data-scroll-target="#b-parameter-grid-for-bertopic-auto-tuning">3.3b) Parameter grid for BERTopic auto-tuning</a></li>
  <li><a href="#c-grid-search-scoring" id="toc-c-grid-search-scoring" class="nav-link" data-scroll-target="#c-grid-search-scoring">3.3c) Grid Search &amp; Scoring</a></li>
  <li><a href="#d-composite-scoring-formula-for-topic-model-evaluation" id="toc-d-composite-scoring-formula-for-topic-model-evaluation" class="nav-link" data-scroll-target="#d-composite-scoring-formula-for-topic-model-evaluation">3.3d) Composite Scoring Formula for Topic Model Evaluation</a></li>
  <li><a href="#e-optional-leaf-mode-refinement-near-best-eom" id="toc-e-optional-leaf-mode-refinement-near-best-eom" class="nav-link" data-scroll-target="#e-optional-leaf-mode-refinement-near-best-eom">3.3e) (Optional) Leaf-mode refinement near best EOM</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-4-topic-interpretation" id="toc-section-4-topic-interpretation" class="nav-link" data-scroll-target="#section-4-topic-interpretation">Section 4: Topic Interpretation</a>
  <ul class="collapse">
  <li><a href="#est-tagging" id="toc-est-tagging" class="nav-link" data-scroll-target="#est-tagging">3.1) EST Tagging</a></li>
  <li><a href="#ai-topic-interpretation" id="toc-ai-topic-interpretation" class="nav-link" data-scroll-target="#ai-topic-interpretation">3.2) AI Topic Interpretation</a></li>
  <li><a href="#generate-labels-for-all-non-noise-topics" id="toc-generate-labels-for-all-non-noise-topics" class="nav-link" data-scroll-target="#generate-labels-for-all-non-noise-topics">3.3) Generate Labels for All Non-Noise Topics</a></li>
  <li><a href="#save-as-final-excel" id="toc-save-as-final-excel" class="nav-link" data-scroll-target="#save-as-final-excel">3.4) Save as Final Excel</a></li>
  </ul></li>
  <li><a href="#section-14-semantic-search" id="toc-section-14-semantic-search" class="nav-link" data-scroll-target="#section-14-semantic-search">Section 14: Semantic Search</a></li>
  <li><a href="#section-4-topic-analysis" id="toc-section-4-topic-analysis" class="nav-link" data-scroll-target="#section-4-topic-analysis">Section 4: Topic Analysis</a>
  <ul class="collapse">
  <li><a href="#visualization-top-terms-per-topic" id="toc-visualization-top-terms-per-topic" class="nav-link" data-scroll-target="#visualization-top-terms-per-topic">10) Visualization ‚Äî Top Terms per Topic</a></li>
  <li><a href="#topic-similarity-heatmap-correlation-table" id="toc-topic-similarity-heatmap-correlation-table" class="nav-link" data-scroll-target="#topic-similarity-heatmap-correlation-table">11) Topic Similarity Heatmap + Correlation Table</a></li>
  <li><a href="#topic-trends-over-time" id="toc-topic-trends-over-time" class="nav-link" data-scroll-target="#topic-trends-over-time">12) Topic Trends Over Time</a>
  <ul class="collapse">
  <li><a href="#build-the-base-trend-table" id="toc-build-the-base-trend-table" class="nav-link" data-scroll-target="#build-the-base-trend-table">12.1) Build the base trend table</a></li>
  <li><a href="#compute-topic-level-metrics" id="toc-compute-topic-level-metrics" class="nav-link" data-scroll-target="#compute-topic-level-metrics">12.2) Compute topic-level metrics</a></li>
  </ul></li>
  <li><a href="#most-active-topics-by-total-documents" id="toc-most-active-topics-by-total-documents" class="nav-link" data-scroll-target="#most-active-topics-by-total-documents">12.3) Most Active Topics (by total documents)</a></li>
  <li><a href="#emerging-fast-growing-topics" id="toc-emerging-fast-growing-topics" class="nav-link" data-scroll-target="#emerging-fast-growing-topics">12.4) Emerging / Fast-Growing Topics</a>
  <ul class="collapse">
  <li><a href="#declining-topics" id="toc-declining-topics" class="nav-link" data-scroll-target="#declining-topics">12.5) Declining Topics</a></li>
  <li><a href="#plot-any-category" id="toc-plot-any-category" class="nav-link" data-scroll-target="#plot-any-category">12.6) Plot any category</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<p><a href="https://colab.research.google.com/github/pradeep-isawasan/criminogenic-biblio/blob/main/notebooks/03_topic_modeling.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></p>
<section id="topic-modeling---v7" class="level1">
<h1>Topic Modeling - v7</h1>
<p><strong>WOS Data Collected:</strong> 27 October 2025 <strong>Search syntax:</strong> ‚Äúcriminogenic*‚Äù</p>
</section>
<section id="section-0-setup" class="level1">
<h1>Section 0: Setup</h1>
<p>This section prepares the environment for the notebook.</p>
<p>We will: 1. Install required libraries (Google Colab) 2. Import Python packages 3. Load the OpenAI API key from Colab <code>userdata</code></p>
<blockquote class="blockquote">
<p><strong>Run Section 0 top-to-bottom before running anything else.</strong></p>
</blockquote>
<div id="TLe9io0pZesb" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install all required libraries (Colab only)</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">\</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    bertopic <span class="op">\</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    transformers <span class="op">\</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    umap<span class="op">-</span>learn <span class="op">\</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    hdbscan <span class="op">\</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    ripser <span class="op">\</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    kmapper <span class="op">\</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    openai <span class="op">\</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    gensim<span class="op">==</span><span class="fl">4.3.3</span> <span class="op">&gt;</span> <span class="op">/</span>dev<span class="op">/</span>null</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚úîÔ∏è Libraries installed"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<section id="imports" class="level2">
<h2 class="anchored" data-anchor-id="imports">0.2) Imports</h2>
<div id="89a866a7" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, AutoModel</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bertopic <span class="im">import</span> BERTopic</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> umap</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> hdbscan</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> openai <span class="im">import</span> OpenAI</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="load-openai-api-key-from-colab-userdata" class="level2">
<h2 class="anchored" data-anchor-id="load-openai-api-key-from-colab-userdata">0.3) Load OpenAI API key from Colab userdata</h2>
<div id="JcCCl7HJsZbl" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> userdata</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>OPENAI_KEY <span class="op">=</span> userdata.get(<span class="st">"OPENAI_API_KEY"</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> OPENAI_KEY <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Please add your OpenAI API key in Colab: Runtime ‚Üí Secrets ‚Üí User Data"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"OPENAI_API_KEY"</span>] <span class="op">=</span> OPENAI_KEY</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> OpenAI()</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚úîÔ∏è OpenAI key loaded"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
</section>
<section id="section-1-data-preparation" class="level1">
<h1>Section 1: Data Preparation</h1>
<div id="GAbubTuAdDD-" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Mount Google Drive (run once per session)</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> drive</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>drive.mount(<span class="st">'/content/drive'</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚úîÔ∏è Google Drive mounted."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<section id="load-dataset-from-project-folder" class="level2">
<h2 class="anchored" data-anchor-id="load-dataset-from-project-folder">1.1) Load dataset from project folder</h2>
<div id="2AQVDmwPpxok" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># üëá This is the ONE folder where everything lives</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>PROJECT_DIR <span class="op">=</span> <span class="st">"/content/drive/MyDrive/Colab Notebooks/biblio-criminogenic"</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>CSV_PATH <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>PROJECT_DIR<span class="sc">}</span><span class="ss">/bibfile_data.csv"</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(CSV_PATH, low_memory<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.rename(columns<span class="op">=</span>{<span class="st">"Unnamed: 0"</span>: <span class="st">"id"</span>})</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected columns check</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>expected <span class="op">=</span> [<span class="st">'unique_id'</span>, <span class="st">'abstract'</span>, <span class="st">'author_keywords'</span>, <span class="st">'keywords'</span>, <span class="st">'title'</span>]</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>missing <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> expected <span class="cf">if</span> c <span class="kw">not</span> <span class="kw">in</span> df.columns]</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> missing:</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ö†Ô∏è Warning: Missing expected columns:"</span>, missing)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚úÖ Columns OK:"</span>, expected)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üìÑ Loaded </span><span class="sc">{</span><span class="bu">len</span>(df)<span class="sc">}</span><span class="ss"> rows from </span><span class="sc">{</span>CSV_PATH<span class="sc">!r}</span><span class="ss">."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="remove-duplicates-based-on-unique_id" class="level2">
<h2 class="anchored" data-anchor-id="remove-duplicates-based-on-unique_id">1.2) Remove duplicates based on unique_id</h2>
<div id="Gd34EWfqqOUp" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>before <span class="op">=</span> <span class="bu">len</span>(df)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify rows with duplicate unique_id values</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>dup_mask <span class="op">=</span> df.duplicated(subset<span class="op">=</span>[<span class="st">'unique_id'</span>], keep<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>duplicates <span class="op">=</span> df[dup_mask]</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> duplicates.empty:</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"‚ö†Ô∏è Found </span><span class="sc">{</span>duplicates[<span class="st">'unique_id'</span>]<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss"> duplicated unique_id values."</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Drop duplicates, keep the first occurrence</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df.drop_duplicates(subset<span class="op">=</span>[<span class="st">'unique_id'</span>], keep<span class="op">=</span><span class="st">'first'</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    after <span class="op">=</span> <span class="bu">len</span>(df)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"üßπ Removed </span><span class="sc">{</span>before <span class="op">-</span> after<span class="sc">}</span><span class="ss"> duplicate rows. Remaining rows: </span><span class="sc">{</span>after<span class="sc">}</span><span class="ss">."</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚úÖ No duplicate unique_id entries found."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="build-specter2-style-text-__text__" class="level2">
<h2 class="anchored" data-anchor-id="build-specter2-style-text-__text__">1.3) Build SPECTER2-Style Text (<code>__text__</code>)</h2>
<p>In this step, we prepare a <strong>single unified text field</strong> that will be sent to the SPECTER2 / transformer embedding model.</p>
<p>We combine four bibliographic fields:</p>
<ul>
<li><strong>title</strong></li>
<li><strong>abstract</strong></li>
<li><strong>author_keywords</strong></li>
<li><strong>keywords</strong></li>
</ul>
<p>into one structured string using the SPECTER2-style format:</p>
<p>title [SEP] abstract [SEP] author_keywords [SEP] keywords</p>
<section id="what-happens-in-this-step" class="level3">
<h3 class="anchored" data-anchor-id="what-happens-in-this-step">What happens in this step:</h3>
<ol type="1">
<li><strong>Clean missing values</strong>
<ul>
<li>Convert <code>"unknown"</code>, <code>"nan"</code>, empty strings, and <code>None</code> into <code>NaN</code>.</li>
</ul></li>
<li><strong>Normalize keyword fields</strong>
<ul>
<li>Split on <code>,</code>, <code>;</code>, and <code>|</code></li>
<li>Trim each keyword</li>
<li>Rejoin using a standard format: <code>kw1; kw2; kw3</code></li>
</ul></li>
<li><strong>Normalize title and abstract</strong>
<ul>
<li>Collapse multiple spaces</li>
<li>Keep original casing and punctuation<br>
<em>(full cleaning happens later in Step 1.4)</em></li>
</ul></li>
<li><strong>Assemble the final text</strong>
<ul>
<li><p>Include only non-empty fields</p></li>
<li><p>Join all parts with <code>[SEP]</code></p></li>
<li><p>Save into:</p>
<pre><code>df["__text__"]</code></pre></li>
</ul></li>
</ol>
</section>
<section id="why-this-matters" class="level3">
<h3 class="anchored" data-anchor-id="why-this-matters">Why this matters</h3>
<p>Using structured <code>[SEP]</code> segments helps SPECTER2 understand the logical parts of a scientific article, leading to <strong>better-quality embeddings</strong> and <strong>more coherent topic modeling</strong> later in the workflow.</p>
<div id="w19rqwSSqqtL" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Text Preparation (SPECTER2-ready, no double-cleaning)</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># - Builds: title [SEP] abstract [SEP] author_keywords [SEP] keywords</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># - Preserves semicolons in keywords (normalized to "; ")</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># - Leaves case, URLs, punctuation cleanup to basic_clean()</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>TEXT_COLS <span class="op">=</span> [<span class="st">"abstract"</span>, <span class="st">"author_keywords"</span>, <span class="st">"keywords"</span>, <span class="st">"title"</span>]</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _to_nan(x):</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Convert 'unknown'/'nan'/''/None -&gt; np.nan; otherwise trimmed string."""</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> (<span class="bu">isinstance</span>(x, <span class="bu">float</span>) <span class="kw">and</span> np.isnan(x)):</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.nan</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> <span class="bu">str</span>(x).strip()</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> s <span class="op">==</span> <span class="st">""</span> <span class="kw">or</span> s.lower() <span class="kw">in</span> {<span class="st">"nan"</span>, <span class="st">"none"</span>, <span class="st">"unknown"</span>}:</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.nan</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> s</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply _to_nan to all text columns (if they exist)</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> c <span class="kw">in</span> TEXT_COLS:</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> c <span class="kw">in</span> df.columns:</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>        df[c] <span class="op">=</span> df[c].<span class="bu">apply</span>(_to_nan)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _normalize_keywords(s: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Normalize separators in keyword fields, keep '; ' as main separator."""</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> s.strip()</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Turn commas, pipes, slashes into semicolons</span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> re.sub(<span class="vs">r"</span><span class="dv">\s</span><span class="op">*</span><span class="pp">[,|/]</span><span class="dv">\s</span><span class="op">*</span><span class="vs">"</span>, <span class="st">"; "</span>, s)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize multiple semicolons / spacing</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> re.sub(<span class="vs">r"</span><span class="dv">\s</span><span class="op">*</span><span class="vs">;</span><span class="dv">\s</span><span class="op">*</span><span class="vs">"</span>, <span class="st">"; "</span>, s)</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> s</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _build_text(row: pd.Series) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Build SPECTER2 text: title [SEP] abstract [SEP] author_keywords [SEP] keywords."""</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>    parts <span class="op">=</span> []</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Title</span></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>    v <span class="op">=</span> row.get(<span class="st">"title"</span>)</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.notnull(v):</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>        parts.append(<span class="bu">str</span>(v).strip())</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Abstract</span></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>    v <span class="op">=</span> row.get(<span class="st">"abstract"</span>)</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.notnull(v):</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>        parts.append(<span class="bu">str</span>(v).strip())</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Author keywords</span></span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>    v <span class="op">=</span> row.get(<span class="st">"author_keywords"</span>)</span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.notnull(v):</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>        parts.append(_normalize_keywords(<span class="bu">str</span>(v)))</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Keywords</span></span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>    v <span class="op">=</span> row.get(<span class="st">"keywords"</span>)</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.notnull(v):</span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>        parts.append(_normalize_keywords(<span class="bu">str</span>(v)))</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">" [SEP] "</span>.join([p <span class="cf">for</span> p <span class="kw">in</span> parts <span class="cf">if</span> p])</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"__text__"</span>] <span class="op">=</span> df.<span class="bu">apply</span>(_build_text, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚úÖ Text prep done for SPECTER2-base."</span>)</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   Order: title [SEP] abstract [SEP] author_keywords [SEP] keywords"</span>)</span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="OMPB3PTusLlv" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>df[[<span class="st">"title"</span>, <span class="st">"abstract"</span>, <span class="st">"author_keywords"</span>, <span class="st">"keywords"</span>, <span class="st">"__text__"</span>]].head(<span class="dv">2</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
</section>
<section id="basic-text-cleaning-__clean__" class="level2">
<h2 class="anchored" data-anchor-id="basic-text-cleaning-__clean__">1.4) Basic Text Cleaning ‚Üí <code>__clean__</code></h2>
<p>In this step, we apply a <strong>light cleaning</strong> to the structured text stored in <code>__text__</code>, and save the result into:</p>
<p><code>df["__clean__"]</code></p>
<p>This cleaned text is used for:</p>
<ul>
<li>text quality checks (short/long documents)</li>
<li>preparing input for embeddings (<code>__embed_text__</code>)</li>
<li>providing a stable base before phrase/keyword normalization</li>
</ul>
<p>We intentionally avoid heavy cleaning because transformer embeddings (e.g., SPECTER2) work best when the text still looks like natural language. The goal is to remove noise while <strong>preserving meaning and structure</strong>, especially the <code>[SEP]</code> separators.</p>
<hr>
<section id="what-basic_clean-does" class="level3">
<h3 class="anchored" data-anchor-id="what-basic_clean-does">üîç What <code>basic_clean()</code> does</h3>
<p>The cleaning function performs the following steps:</p>
<ol type="1">
<li><strong>Normalize special tokens and punctuation</strong>
<ul>
<li>Convert variants like <code>[ sep ]</code>, <code>[SEP]</code>, <code>[Sep]</code> into a consistent <code>[SEP]</code></li>
<li>Convert curly quotes (<code>‚Äô</code>, <code>‚Äò</code>) into <code>'</code></li>
<li>Convert en/em dashes (<code>‚Äì</code>, <code>‚Äî</code>) into <code>-</code></li>
</ul></li>
<li><strong>Protect <code>[SEP]</code> before lowercasing</strong>
<ul>
<li>Temporarily replace <code>[SEP]</code> with a placeholder (e.g.&nbsp;<code>__sep__</code>)</li>
<li>Lowercase the entire text</li>
<li>This avoids breaking the <code>[SEP]</code> token during cleaning</li>
</ul></li>
<li><strong>Remove URLs</strong>
<ul>
<li>Strip out patterns like <code>http://...</code> or <code>www...</code> to reduce noise</li>
</ul></li>
<li><strong>Remove unusual characters but keep useful ones</strong>
<ul>
<li>Allow:
<ul>
<li>letters (<code>a‚Äìz</code>)</li>
<li>digits (<code>0‚Äì9</code>)</li>
<li>underscores (<code>_</code>)</li>
<li>punctuation (<code>; : . , ! ? ' -</code>)</li>
<li>square brackets (for <code>[SEP]</code>)</li>
</ul></li>
<li>Replace everything else with a space</li>
</ul></li>
<li><strong>Normalize semicolon spacing</strong>
<ul>
<li>Ensure keyword-style text follows a consistent format, e.g.:<br>
<code>kw1; kw2; kw3</code></li>
</ul></li>
<li><strong>Normalize whitespace</strong>
<ul>
<li>Collapse multiple spaces into one</li>
<li>Trim leading and trailing spaces</li>
</ul></li>
<li><strong>Remove standalone single-letter words that add noise</strong>
<ul>
<li>Remove <code>b‚Äìh</code> and <code>j‚Äìz</code></li>
<li>Keep valid English single-letter words:
<ul>
<li><code>a</code></li>
<li><code>i</code></li>
</ul></li>
</ul></li>
<li><strong>Restore <code>[SEP]</code></strong>
<ul>
<li>Convert the placeholder back to <code>[SEP]</code></li>
</ul></li>
</ol>
<div id="vOxq3zMly_RL" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 1.4 Basic Text Cleaning + Light Normalization</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># - keeps [SEP], semicolons, apostrophes</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># - removes noise characters</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># - removes single-letter words except 'a' and 'i'</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> basic_clean(s: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> s <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">""</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> <span class="bu">str</span>(s)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 0) Normalize [SEP] variants and unicode punctuation</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> re.sub(<span class="vs">r"</span><span class="ch">\[</span><span class="dv">\s</span><span class="op">*</span><span class="vs">sep</span><span class="dv">\s</span><span class="op">*</span><span class="ch">\]</span><span class="vs">"</span>, <span class="st">"[SEP]"</span>, s, flags<span class="op">=</span>re.IGNORECASE)  <span class="co"># any [ sep ] ‚Üí [SEP]</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> s.replace(<span class="st">"</span><span class="ch">\u2019</span><span class="st">"</span>, <span class="st">"'"</span>).replace(<span class="st">"</span><span class="ch">\u2018</span><span class="st">"</span>, <span class="st">"'"</span>)             <span class="co"># curly quotes ‚Üí '</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> s.replace(<span class="st">"</span><span class="ch">\u2013</span><span class="st">"</span>, <span class="st">"-"</span>).replace(<span class="st">"</span><span class="ch">\u2014</span><span class="st">"</span>, <span class="st">"-"</span>)             <span class="co"># en/em dashes ‚Üí -</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1) Protect [SEP] before lowercasing</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> s.replace(<span class="st">"[SEP]"</span>, <span class="st">" __sep__ "</span>)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2) Lowercase</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> s.lower()</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3) Remove URLs (just in case)</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> re.sub(<span class="vs">r"http</span><span class="dv">\S</span><span class="op">+</span><span class="cf">|</span><span class="vs">www</span><span class="ch">\.</span><span class="dv">\S</span><span class="op">+</span><span class="vs">"</span>, <span class="st">" "</span>, s)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4) Keep only letters, digits, spaces and basic punctuation</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">#    allowed: a-z, 0-9, space, _ ; : . , ! ? ' -</span></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> re.sub(<span class="vs">r"</span><span class="pp">[^a-z0-9_ ;:.,!?'</span><span class="ch">\-</span><span class="dv">\s</span><span class="pp">]</span><span class="vs">"</span>, <span class="st">" "</span>, s)</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5) Normalize semicolon spacing (for keywords)</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> re.sub(<span class="vs">r"</span><span class="dv">\s</span><span class="op">*</span><span class="vs">;</span><span class="dv">\s</span><span class="op">*</span><span class="vs">"</span>, <span class="st">"; "</span>, s)</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 6) Collapse multiple spaces</span></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> re.sub(<span class="vs">r"</span><span class="dv">\s</span><span class="op">+</span><span class="vs">"</span>, <span class="st">" "</span>, s).strip()</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 7) Remove standalone single-letter words EXCEPT 'a' and 'i'</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> re.sub(<span class="vs">r"</span><span class="dv">\b</span><span class="pp">[b-hj-z]</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">" "</span>, s)  <span class="co"># remove b‚Äìh and j‚Äìz</span></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> re.sub(<span class="vs">r"</span><span class="dv">\s</span><span class="op">+</span><span class="vs">"</span>, <span class="st">" "</span>, s).strip()</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 8) Restore [SEP]</span></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> s.replace(<span class="st">"__sep__"</span>, <span class="st">"[SEP]"</span>)</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> s</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply to build text for topic modelling / QC</span></span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"__clean__"</span>] <span class="op">=</span> df[<span class="st">"__text__"</span>].astype(<span class="bu">str</span>).<span class="bu">apply</span>(basic_clean)</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚úÖ Basic text cleaning complete (keeps [SEP], ';', apostrophes, and preserves 'a' and 'i')."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="q14zV6Ss5MAy" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>df[[<span class="st">"__text__"</span>, <span class="st">"__clean__"</span>]].head(<span class="dv">2</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
</section>
<section id="token-length-analysis" class="level2">
<h2 class="anchored" data-anchor-id="token-length-analysis">1.5) Token Length Analysis</h2>
<p>To check the quality of our cleaned text, we compute the number of tokens (words) in each document using:</p>
<p><code>df["__clean__"]</code></p>
<p>This helps us identify:</p>
<ul>
<li><p><strong>Very short documents</strong> (e.g., &lt; 15 tokens)<br>
These may not contain enough information for reliable embeddings or topic modelling.</p></li>
<li><p><strong>Very long documents</strong> (e.g., &gt; 400 tokens)<br>
These could indicate:</p>
<ul>
<li>merged abstracts</li>
<li>references accidentally included</li>
<li>PDF extraction errors</li>
<li>unusually verbose descriptions</li>
</ul></li>
</ul>
<p>Analyzing token length distribution helps ensure our dataset is suitable for SPECTER2 embeddings and BERTopic.</p>
<hr>
<section id="what-we-do-in-this-step" class="level3">
<h3 class="anchored" data-anchor-id="what-we-do-in-this-step">What we do in this step:</h3>
<ol type="1">
<li>Compute token length for each document.</li>
<li>Save the result in a new column:</li>
<li>Print descriptive statistics:</li>
</ol>
<ul>
<li>mean<br>
</li>
<li>min/max<br>
</li>
<li>quartiles<br>
</li>
</ul>
<ol start="4" type="1">
<li>Plot a histogram to visually inspect:</li>
</ol>
<ul>
<li>outliers</li>
<li>skewness</li>
<li>typical document sizes</li>
</ul>
<p>This step does <strong>not</strong> modify any text.<br>
It simply provides quality insight so we can clean or filter problematic records later.</p>
<div id="Yawd-3nJFx7m" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 1.5 Token Length Analysis</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Count tokens in __clean__</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"len_tokens"</span>] <span class="op">=</span> df[<span class="st">"__clean__"</span>].<span class="bu">str</span>.split().<span class="bu">apply</span>(<span class="bu">len</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"üìä Token length summary:"</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[<span class="st">"len_tokens"</span>].describe())</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"len_tokens"</span>].hist(bins<span class="op">=</span><span class="dv">40</span>, color<span class="op">=</span><span class="st">"skyblue"</span>, edgecolor<span class="op">=</span><span class="st">"black"</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Token Length per Document"</span>)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Number of Tokens"</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Count"</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
</section>
<section id="text-quality-summary-short-vs-long-documents" class="level2">
<h2 class="anchored" data-anchor-id="text-quality-summary-short-vs-long-documents">1.6) Text Quality Summary (Short vs Long Documents)</h2>
<p>After computing the token length in <code>len_tokens</code> (from <code>__clean__</code>), we now check how many documents are:</p>
<ul>
<li><strong>Very short</strong> ‚Üí fewer than <strong>15 tokens</strong></li>
<li><strong>Very long</strong> ‚Üí more than <strong>400 tokens</strong></li>
</ul>
<p>These are useful heuristics:</p>
<ul>
<li><strong>Very short documents (&lt; 15 tokens)</strong>
<ul>
<li>Often titles only<br>
</li>
<li>Incomplete abstracts<br>
</li>
<li>Records with almost no useful context<br>
</li>
<li>May become noise in embeddings and topic modelling</li>
</ul></li>
<li><strong>Very long documents (&gt; 400 tokens)</strong>
<ul>
<li>Possible merged abstracts or full-text chunks<br>
</li>
<li>References or extra sections accidentally included<br>
</li>
<li>Can dominate similarity space and distort topics</li>
</ul></li>
</ul>
<p>In this step, we:</p>
<ol type="1">
<li>Count how many documents fall below 15 tokens and above 400 tokens.</li>
<li>Print a summary of these counts.</li>
<li>Optionally display <strong>a few example records</strong> (ID, unique_id, and <code>__clean__</code>) for:
<ul>
<li>very short documents<br>
</li>
<li>very long documents</li>
</ul></li>
</ol>
<p>This step does <strong>not</strong> modify the dataset yet.<br>
It simply helps us decide later whether we should remove or manually inspect these outliers.</p>
<div id="KmEoRXv691ee" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 1.6 Text Quality Summary (based on __clean__)</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify short and long docs</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>df_short <span class="op">=</span> df[df[<span class="st">"len_tokens"</span>] <span class="op">&lt;</span> <span class="dv">15</span>][[<span class="st">"id"</span>, <span class="st">"unique_id"</span>, <span class="st">"__clean__"</span>, <span class="st">"len_tokens"</span>]]</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>df_long  <span class="op">=</span> df[df[<span class="st">"len_tokens"</span>] <span class="op">&gt;</span> <span class="dv">400</span>][[<span class="st">"id"</span>, <span class="st">"unique_id"</span>, <span class="st">"__clean__"</span>, <span class="st">"len_tokens"</span>]]</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"‚ö†Ô∏è Very short docs (&lt;15 tokens): </span><span class="sc">{</span><span class="bu">len</span>(df_short)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"‚ö†Ô∏è Very long docs (&gt;400 tokens): </span><span class="sc">{</span><span class="bu">len</span>(df_long)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Better display settings for Google Colab</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_colwidth'</span>, <span class="va">None</span>)    <span class="co"># show full text</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_rows'</span>, <span class="dv">200</span>)         <span class="co"># see more docs at once</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Show short docs (scrollable)</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">len</span>(df_short) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üîç **Short Documents (&lt;15 tokens)**"</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    display(df_short)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Show long docs (scrollable)</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">len</span>(df_long) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üîç **Long Documents (&gt;400 tokens)**"</span>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    display(df_long)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="manual-removal-of-low-quality-documents" class="level2">
<h2 class="anchored" data-anchor-id="manual-removal-of-low-quality-documents">1.7) Manual Removal of Low-Quality Documents</h2>
<p>Based on the inspection in <strong>1.6 (Text Quality Summary)</strong>, some documents may be:</p>
<ul>
<li>too short (e.g.&nbsp;just a title or a fragment)</li>
<li>extremely long (merged text, PDF extraction errors)</li>
<li>clearly irrelevant or corrupted (even if length is normal)</li>
</ul>
<p>Instead of automatically removing all documents below/above a fixed token threshold,<br>
we use a <strong>manual curation approach</strong>:</p>
<ol type="1">
<li>Inspect:
<ul>
<li>very short docs (<code>len_tokens &lt; 15</code>)</li>
<li>very long docs (<code>len_tokens &gt; 400</code>)</li>
<li>any other suspicious records</li>
</ul></li>
<li>Decide which ones are truly low-quality or unusable.</li>
<li>Collect their <code>id</code> values into a list.</li>
<li>Remove only those specific <code>id</code>s from the dataset.</li>
</ol>
<p>This avoids accidentally deleting valid articles with short or long abstracts.</p>
<p>In this step, we:</p>
<ul>
<li>define a manual list of <code>id</code>s to remove (<code>REMOVE_IDS</code>)</li>
<li>filter them out from <code>df</code></li>
<li>report how many documents were removed</li>
<li>keep the cleaned DataFrame for subsequent steps (embeddings and topic modelling)</li>
</ul>
<div id="NUsmKQgaIKKf" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 1.7 Manual Removal of Low-Quality Documents</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># üîß 1) Manually list the document IDs to remove</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">#    ‚Üí Fill this list after reviewing the outputs from Step 1.6</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>REMOVE_IDS <span class="op">=</span> [<span class="dv">1308</span>, <span class="dv">1349</span>, <span class="dv">1350</span>, <span class="dv">1355</span>, <span class="dv">1356</span>, <span class="dv">1357</span>, <span class="dv">1358</span>]</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>before <span class="op">=</span> <span class="bu">len</span>(df)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">len</span>(REMOVE_IDS) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df[<span class="op">~</span>df[<span class="st">"id"</span>].isin(REMOVE_IDS)].reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    after <span class="op">=</span> <span class="bu">len</span>(df)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"üßπ Removed </span><span class="sc">{</span>before <span class="op">-</span> after<span class="sc">}</span><span class="ss"> documents using manual ID list."</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"üìÑ Remaining documents: </span><span class="sc">{</span>after<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ÑπÔ∏è No IDs specified in REMOVE_IDS. No documents were removed."</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Optional: quick check of token length distribution after removal</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üìä Updated token length summary (len_tokens):"</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[<span class="st">"len_tokens"</span>].describe())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<hr>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">1.8) Conclusion</h2>
<p>In this section, we prepared our bibliographic dataset for downstream embeddings and topic modelling. We cleaned and structured the text in a way that supports transformer-based semantic embeddings (SPECTER2) and BERTopic‚Äôs vectorizer.</p>
<section id="what-we-accomplished" class="level3">
<h3 class="anchored" data-anchor-id="what-we-accomplished">What we accomplished</h3>
<ol type="1">
<li><strong>Loaded and validated the dataset</strong>
<ul>
<li>Fixed missing or malformed fields<br>
</li>
<li>Ensured consistent column naming (e.g., <code>id</code>, <code>unique_id</code>)</li>
</ul></li>
<li><strong>Built SPECTER2-style text (<code>__text__</code>)</strong>
<ul>
<li>Combined title, abstract, author keywords, and keywords<br>
</li>
<li>Used <code>[SEP]</code> tokens to separate logical document sections</li>
</ul></li>
<li><strong>Performed light but effective cleaning (<code>__clean__</code>)</strong>
<ul>
<li>Normalized punctuation and spacing<br>
</li>
<li>Preserved <code>[SEP]</code><br>
</li>
<li>Removed noisy characters<br>
</li>
<li>Removed single-letter words except valid ones (<code>a</code>, <code>i</code>)</li>
</ul></li>
<li><strong>Evaluated text quality (<code>len_tokens</code>)</strong>
<ul>
<li>Identified very short and very long documents<br>
</li>
<li>Viewed them clearly in Google Colab for manual inspection</li>
</ul></li>
<li><strong>Manually removed problematic documents (<code>REMOVE_IDS</code>)</strong>
<ul>
<li>Removed only documents confirmed as corrupted, irrelevant, or unusable<br>
</li>
<li>Preserved legitimate short/long documents to avoid losing valuable data</li>
</ul></li>
</ol>
</section>
<section id="outputs-produced-in-section-1" class="level3">
<h3 class="anchored" data-anchor-id="outputs-produced-in-section-1">Outputs produced in Section 1</h3>
<ul>
<li><code>__text__</code> ‚Äî structured document with <code>[SEP]</code> separators<br>
</li>
<li><code>__clean__</code> ‚Äî cleaned version for QC and embedding preparation<br>
</li>
<li><code>len_tokens</code> ‚Äî token counts for each document<br>
</li>
<li>A curated dataset after manual removals</li>
</ul>
</section>
<section id="whats-next" class="level3">
<h3 class="anchored" data-anchor-id="whats-next">What‚Äôs next?</h3>
<p>We now have a <strong>clean, consistent, high-quality dataset</strong>, ready for:</p>
<ul>
<li><strong><code>__embed_text__</code> construction</strong><br>
</li>
<li><strong>SPECTER2 embeddings (Section 2)</strong><br>
</li>
<li>BERTopic topic modelling<br>
</li>
<li>TDA (Mapper + Ripser)<br>
</li>
<li>Visual analytics</li>
</ul>
<p>No metadata processing is required at this stage; metadata can be extracted later during topic interpretation.</p>
<hr>
</section>
</section>
</section>
<section id="section-2-embeddings-specter2" class="level1">
<h1>Section 2: Embeddings (SPECTER2)</h1>
<p>In this section, we prepare text for transformer-based embeddings using the SPECTER2 model. The goal is to generate a dense vector representation for each document that captures its semantic content.</p>
<p>We separate the concerns as follows:</p>
<ul>
<li><code>__clean__</code> ‚Üí light-cleaned text from Section 1<br>
</li>
<li><code>__embed_text__</code> ‚Üí embedding-ready text (concept-normalized, still natural language)<br>
</li>
<li>later: embeddings ‚Üí used by BERTopic and TDA</li>
</ul>
<section id="a-n-gram-nalysis" class="level3">
<h3 class="anchored" data-anchor-id="a-n-gram-nalysis">2.1a) N-gram nalysis</h3>
<div id="qWOR3iGdkrBe" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1a.1 Noun Phrase Extraction (spaCy) + tqdm Progress Bar</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Load spaCy English model</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co"># If not installed:</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co"># !python -m spacy download en_core_web_sm</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>nlp_np <span class="op">=</span> spacy.load(<span class="st">"en_core_web_sm"</span>)  <span class="co"># full pipeline (noun_chunks needs parser)</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> df[<span class="st">"__clean__"</span>].fillna(<span class="st">""</span>).astype(<span class="bu">str</span>).tolist()</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>noun_phrases <span class="op">=</span> []</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="co"># tqdm-protected pipeline</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> doc <span class="kw">in</span> tqdm(nlp_np.pipe(texts, batch_size<span class="op">=</span><span class="dv">32</span>), total<span class="op">=</span><span class="bu">len</span>(texts), desc<span class="op">=</span><span class="st">"Extracting noun phrases"</span>):</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    noun_phrases.extend([np.text.lower().strip() <span class="cf">for</span> np <span class="kw">in</span> doc.noun_chunks])</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Count NP frequencies</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>np_counts <span class="op">=</span> Counter(noun_phrases)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>np_df <span class="op">=</span> (</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>    pd.DataFrame({<span class="st">"phrase"</span>: <span class="bu">list</span>(np_counts.keys()), <span class="st">"freq"</span>: <span class="bu">list</span>(np_counts.values())})</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>    .sort_values(<span class="st">"freq"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üì¶ Unique noun phrases: </span><span class="sc">{</span><span class="bu">len</span>(np_df)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>display(np_df.head(<span class="dv">40</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="bVqV7WX8sMiJ" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1a.2 PMI-Based Collocations (Bigrams + Trigrams)</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.collocations <span class="im">import</span> BigramAssocMeasures, BigramCollocationFinder</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.collocations <span class="im">import</span> TrigramAssocMeasures, TrigramCollocationFinder</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Download tokenizer if not already</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt'</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt_tab'</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenize corpus</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>tokens_per_doc <span class="op">=</span> [</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    nltk.word_tokenize(text.lower())</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> text <span class="kw">in</span> df[<span class="st">"__clean__"</span>].fillna(<span class="st">""</span>).astype(<span class="bu">str</span>).tolist()</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>all_tokens <span class="op">=</span> [t <span class="cf">for</span> doc <span class="kw">in</span> tokens_per_doc <span class="cf">for</span> t <span class="kw">in</span> doc]</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Bigram PMI</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>bigram_measures <span class="op">=</span> BigramAssocMeasures()</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>bigram_finder <span class="op">=</span> BigramCollocationFinder.from_words(all_tokens)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>bigram_finder.apply_freq_filter(<span class="dv">3</span>)  <span class="co"># at least 3 occurrences</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>bigram_scored <span class="op">=</span> bigram_finder.score_ngrams(bigram_measures.pmi)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>bigram_df <span class="op">=</span> (</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    pd.DataFrame(</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>        [{<span class="st">"phrase"</span>: <span class="st">" "</span>.join(b), <span class="st">"pmi"</span>: score} <span class="cf">for</span> b, score <span class="kw">in</span> bigram_scored]</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>    .sort_values(<span class="st">"pmi"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üì¶ Bigram PMI candidates: </span><span class="sc">{</span><span class="bu">len</span>(bigram_df)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>display(bigram_df.head(<span class="dv">40</span>))</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Trigram PMI</span></span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>trigram_measures <span class="op">=</span> TrigramAssocMeasures()</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>trigram_finder <span class="op">=</span> TrigramCollocationFinder.from_words(all_tokens)</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>trigram_finder.apply_freq_filter(<span class="dv">3</span>)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>trigram_scored <span class="op">=</span> trigram_finder.score_ngrams(trigram_measures.pmi)</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>trigram_df <span class="op">=</span> (</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>    pd.DataFrame(</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>        [{<span class="st">"phrase"</span>: <span class="st">" "</span>.join(t), <span class="st">"pmi"</span>: score} <span class="cf">for</span> t, score <span class="kw">in</span> trigram_scored]</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>    .sort_values(<span class="st">"pmi"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üì¶ Trigram PMI candidates: </span><span class="sc">{</span><span class="bu">len</span>(trigram_df)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>display(trigram_df.head(<span class="dv">40</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="ZI1v8t3HxPK7" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1a.3 Keyphrase Extraction with KeyBERT</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install keybert</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keybert <span class="im">import</span> KeyBERT</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>kw_model <span class="op">=</span> KeyBERT()  <span class="co"># uses a default sentence-transformer model</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co"># For efficiency, sample or concatenate docs</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>corpus_text <span class="op">=</span> <span class="st">" "</span>.join(df[<span class="st">"__clean__"</span>].fillna(<span class="st">""</span>).astype(<span class="bu">str</span>).tolist())</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>keyphrases <span class="op">=</span> kw_model.extract_keywords(</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    corpus_text,</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    keyphrase_ngram_range<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">4</span>),</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    stop_words<span class="op">=</span><span class="st">"english"</span>,</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    top_n<span class="op">=</span><span class="dv">100</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>kb_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    [{<span class="st">"phrase"</span>: kp, <span class="st">"score"</span>: score} <span class="cf">for</span> kp, score <span class="kw">in</span> keyphrases]</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>).sort_values(<span class="st">"score"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üì¶ KeyBERT keyphrases: </span><span class="sc">{</span><span class="bu">len</span>(kb_df)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>display(kb_df.head(<span class="dv">40</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="hH3N_Ak9xe6I" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>display(kb_df.head(<span class="dv">70</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="FYDcDBV-x_Eb" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1a.4 Merge NP + PMI + KeyBERT Candidates (2‚Äì3 grams only)</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> count_words(s):</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">len</span>(s.split())</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Reformat each source table consistently</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>concept_candidates_np <span class="op">=</span> np_df.rename(columns<span class="op">=</span>{<span class="st">"phrase"</span>: <span class="st">"term"</span>, <span class="st">"freq"</span>: <span class="st">"metric"</span>})</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>concept_candidates_np[<span class="st">"source"</span>] <span class="op">=</span> <span class="st">"noun_phrase"</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>concept_candidates_np[<span class="st">"score_type"</span>] <span class="op">=</span> <span class="st">"freq"</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>concept_candidates_bigram <span class="op">=</span> bigram_df.rename(columns<span class="op">=</span>{<span class="st">"phrase"</span>: <span class="st">"term"</span>, <span class="st">"pmi"</span>: <span class="st">"metric"</span>})</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>concept_candidates_bigram[<span class="st">"source"</span>] <span class="op">=</span> <span class="st">"bigram_pmi"</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>concept_candidates_bigram[<span class="st">"score_type"</span>] <span class="op">=</span> <span class="st">"pmi"</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>concept_candidates_trigram <span class="op">=</span> trigram_df.rename(columns<span class="op">=</span>{<span class="st">"phrase"</span>: <span class="st">"term"</span>, <span class="st">"pmi"</span>: <span class="st">"metric"</span>})</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>concept_candidates_trigram[<span class="st">"source"</span>] <span class="op">=</span> <span class="st">"trigram_pmi"</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>concept_candidates_trigram[<span class="st">"score_type"</span>] <span class="op">=</span> <span class="st">"pmi"</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>concept_candidates_kb <span class="op">=</span> kb_df.rename(columns<span class="op">=</span>{<span class="st">"phrase"</span>: <span class="st">"term"</span>, <span class="st">"score"</span>: <span class="st">"metric"</span>})</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>concept_candidates_kb[<span class="st">"source"</span>] <span class="op">=</span> <span class="st">"keybert"</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>concept_candidates_kb[<span class="st">"score_type"</span>] <span class="op">=</span> <span class="st">"semantic_score"</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge all candidates</span></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>all_candidates <span class="op">=</span> pd.concat(</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>    [</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>        concept_candidates_np,</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>        concept_candidates_bigram,</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>        concept_candidates_trigram,</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>        concept_candidates_kb,</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    ignore_index<span class="op">=</span><span class="va">True</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter to keep only 2‚Äì3 word phrases</span></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>filtered_candidates <span class="op">=</span> all_candidates[</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>    all_candidates[<span class="st">"term"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="dv">2</span> <span class="op">&lt;=</span> count_words(x) <span class="op">&lt;=</span> <span class="dv">3</span>)</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>].copy()</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Aggregate: keep max metric per term</span></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>filtered_candidates_agg <span class="op">=</span> (</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>    filtered_candidates</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>    .groupby(<span class="st">"term"</span>, as_index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>    .agg({<span class="st">"metric"</span>: <span class="st">"max"</span>})</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>    .sort_values(<span class="st">"metric"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Suggested underscore format</span></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>filtered_candidates_agg[<span class="st">"suggested_token"</span>] <span class="op">=</span> filtered_candidates_agg[<span class="st">"term"</span>].<span class="bu">str</span>.replace(<span class="st">" "</span>, <span class="st">"_"</span>)</span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üìå Unique 2‚Äì3 gram candidate terms: </span><span class="sc">{</span><span class="bu">len</span>(filtered_candidates_agg)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>display(filtered_candidates_agg.head(<span class="dv">50</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="46e6c0b1" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1a.5 Inspect Top Candidates to Select 'AUTO_PHRASES'</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># üîß Fix: Re-aggregate to ensure we keep the 'source' column</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co"># (The previous aggregation dropped it, so we rebuild it from filtered_candidates)</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"filtered_candidates"</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    filtered_candidates_agg <span class="op">=</span> (</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>        filtered_candidates</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>        .sort_values(<span class="st">"metric"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>        .groupby(<span class="st">"term"</span>, as_index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        .first()  <span class="co"># Keeps the row with max metric + preserves 'source'</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Top Frequent Noun Phrases (Frequency &gt; 10)</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>top_freq <span class="op">=</span> filtered_candidates_agg[</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    (filtered_candidates_agg[<span class="st">"source"</span>] <span class="op">==</span> <span class="st">"noun_phrase"</span>) <span class="op">&amp;</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    (filtered_candidates_agg[<span class="st">"metric"</span>] <span class="op">&gt;</span> <span class="dv">10</span>)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>].sort_values(<span class="st">"metric"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">50</span>)</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Top PMI Collocations (Strong statistical phrases)</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>top_pmi <span class="op">=</span> filtered_candidates_agg[</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    (filtered_candidates_agg[<span class="st">"source"</span>].<span class="bu">str</span>.contains(<span class="st">"pmi"</span>)) <span class="op">&amp;</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    (filtered_candidates_agg[<span class="st">"metric"</span>] <span class="op">&gt;</span> <span class="dv">5</span>)  <span class="co"># PMI threshold</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>].sort_values(<span class="st">"metric"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">50</span>)</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Top KeyBERT Semantic Phrases</span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>top_sem <span class="op">=</span> filtered_candidates_agg[</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>    (filtered_candidates_agg[<span class="st">"source"</span>] <span class="op">==</span> <span class="st">"keybert"</span>)</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>].sort_values(<span class="st">"metric"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">50</span>)</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üìä TOP 50 FREQUENT PHRASES (Good for general domain concepts):"</span>)</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_freq[[<span class="st">"term"</span>, <span class="st">"metric"</span>]].to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üîó TOP 50 HIGH-PMI PHRASES (Good for specific technical terms/names):"</span>)</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_pmi[[<span class="st">"term"</span>, <span class="st">"metric"</span>]].to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">ü§ñ TOP 50 SEMANTIC KEYPHRASES (Good for topic labels):"</span>)</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_sem[[<span class="st">"term"</span>, <span class="st">"metric"</span>]].to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Optional: Keyword Search within Candidates</span></span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>search_term <span class="op">=</span> <span class="st">"risk"</span></span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>subset <span class="op">=</span> filtered_candidates_agg[</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>    filtered_candidates_agg[<span class="st">"term"</span>].<span class="bu">str</span>.contains(search_term, case<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>].sort_values(<span class="st">"metric"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">20</span>)</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">üîç Top matches for '</span><span class="sc">{</span>search_term<span class="sc">}</span><span class="ss">':"</span>)</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(subset[[<span class="st">"term"</span>, <span class="st">"metric"</span>, <span class="st">"source"</span>]].to_string(index<span class="op">=</span><span class="va">False</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="b-concept-normalization-for-criminogenic" class="level3">
<h3 class="anchored" data-anchor-id="b-concept-normalization-for-criminogenic">2.1b) Concept Normalization for Criminogenic</h3>
<p>Before creating embeddings, we normalize key criminology and AI concepts so that different surface forms map to the <strong>same canonical phrase</strong>. For example:</p>
<ul>
<li>‚ÄúSAT‚Äù and ‚Äúsituational action theory‚Äù ‚Üí <code>situational action theory</code><br>
</li>
<li>‚ÄúRAT‚Äù and ‚Äúroutine activity theory‚Äù ‚Üí <code>routine activity theory</code><br>
</li>
<li>‚ÄúRNR‚Äù and ‚Äúrisk-need-responsivity‚Äù ‚Üí <code>risk need responsivity</code><br>
</li>
<li>‚ÄúAI‚Äù and ‚Äúartificial intelligence‚Äù ‚Üí <code>artificial intelligence</code></li>
</ul>
<p>This reduces fragmentation in the embedding space caused by acronyms, spelling variants, and short forms.</p>
<p>We implement this with:</p>
<ol type="1">
<li>A list of regex patterns and their canonical replacements (<code>CONCEPT_PATTERNS</code>).</li>
<li>A helper function <code>normalize_concepts(text, style)</code> that:
<ul>
<li>replaces all pattern matches with the canonical phrase</li>
<li>supports:
<ul>
<li><code>style="spaces"</code> ‚Üí natural phrases (for embeddings)</li>
<li><code>style="underscores"</code> ‚Üí protected tokens (for topic vectorization)</li>
</ul></li>
</ul></li>
</ol>
<div id="q2MuzCnu0tJh" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1 Concept patterns: unify acronyms/variants ‚Üí long form</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>CONCEPT_PATTERNS_CORE <span class="op">=</span> [</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Criminology theories ---</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">situational action theory</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">sat</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"situational action theory"</span>),</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">routine activity theory</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">rat</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"routine activity theory"</span>),</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">broken window</span><span class="pp">[s]</span><span class="op">?</span><span class="dv">\s</span><span class="op">+</span><span class="vs">theory</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">bwt</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"broken windows theory"</span>),</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">social disorganization theory</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">sdt</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"social disorganization theory"</span>),</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">general strain theory</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">gst</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"general strain theory"</span>),</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">social learning theory</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">slt</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"social learning theory"</span>),</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">labeling theory</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">lt</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"labeling theory"</span>),</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">social control theory</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">sct</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"social control theory"</span>),</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">rational choice theory</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">rct</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"rational choice theory"</span>),</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">rational choice</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"rational choice theory"</span>),</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">criminogenic needs</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"criminogenic need"</span>),</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">criminogenic need</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"criminogenic need"</span>),</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">criminogenic factors</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"criminogenic factor"</span>),</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">criminogenic factor</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"criminogenic factor"</span>),</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">risk factors</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"risk factors"</span>),</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">risk factor</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"risk factors"</span>),</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">juvenile offenders</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"juvenile offender"</span>),</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">juvenile offender</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"juvenile offender"</span>),</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Risk/Needs assessment tools ---</span></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">level of service inventory</span><span class="pp">[</span><span class="ch">\-</span><span class="dv">\s</span><span class="pp">]</span><span class="op">*</span><span class="vs">revised</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">lsi</span><span class="pp">[</span><span class="ch">\-</span><span class="dv">\s</span><span class="pp">]</span><span class="op">?</span><span class="vs">r</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"level of service inventory revised"</span>),</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">level of service</span><span class="dv">\s</span><span class="op">*</span><span class="vs">/</span><span class="dv">\s</span><span class="op">*</span><span class="vs">case management inventory</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">ls</span><span class="pp">[</span><span class="ch">\-</span><span class="dv">\s</span><span class="pp">]</span><span class="op">?</span><span class="vs">cmi</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"level of service case management inventory"</span>),</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">youth level of service</span><span class="dv">\s</span><span class="op">*</span><span class="vs">/</span><span class="dv">\s</span><span class="op">*</span><span class="vs">case management inventory</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">yls</span><span class="pp">[</span><span class="ch">\-</span><span class="dv">\s</span><span class="pp">]</span><span class="op">?</span><span class="vs">cmi</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"youth level of service case management inventory"</span>),</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">case management inventory</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">cmi</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"case management inventory"</span>),</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">youth level of service</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">yls</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"youth level of service"</span>),</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">level of service</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">ls</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"level of service"</span>),</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">offender risk assessment and case prioritisation questionnaire</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">oracpq</span><span class="dv">\b</span><span class="vs">"</span>,</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>     <span class="st">"offender risk assessment and case prioritisation questionnaire"</span>),</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Assessment &amp; rehabilitation frameworks ---</span></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">psychopathy checklist</span>(?:<span class="pp">[</span><span class="ch">\-\u2013\u2014</span><span class="pp">]</span><span class="dv">\s</span><span class="op">*</span><span class="vs">revised</span>)<span class="op">?</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">pcl</span><span class="pp">[</span><span class="ch">\-</span><span class="dv">\s</span><span class="pp">]</span><span class="op">?</span><span class="vs">r</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">pclr</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"psychopathy checklist revised"</span>),</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">psychopathy checklist</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">pcl</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"psychopathy checklist"</span>),</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">risk</span><span class="pp">[</span><span class="ch">\-</span><span class="dv">\s</span><span class="pp">]</span><span class="op">?</span><span class="vs">need</span><span class="pp">[</span><span class="ch">\-</span><span class="dv">\s</span><span class="pp">]</span><span class="op">?</span><span class="vs">responsivit</span>(?:<span class="vs">y</span><span class="cf">|</span><span class="vs">ies</span>)(?:<span class="dv">\s</span><span class="op">*</span><span class="vs">model</span>)<span class="op">?</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">rnr</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"risk need responsivity"</span>),</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">good</span><span class="dv">\s</span><span class="op">+</span><span class="vs">lives</span><span class="dv">\s</span><span class="op">+</span><span class="vs">model</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">glm</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"good lives model"</span>),</span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Other criminogenic constructs ---</span></span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">unstructured socializing with peer</span><span class="pp">[s]</span><span class="op">?</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">uswp</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"unstructured socializing with peers"</span>),</span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">intimate partner violence</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">ipv</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"intimate partner violence"</span>),</span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">traumatic brain injury</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">tbi</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"traumatic brain injury"</span>),</span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">post</span><span class="pp">[</span><span class="ch">\-</span><span class="dv">\s</span><span class="pp">]</span><span class="op">?</span><span class="vs">traumatic</span><span class="dv">\s</span><span class="op">+</span><span class="vs">stress</span><span class="dv">\s</span><span class="op">+</span><span class="vs">disorder</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">ptsd</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"post traumatic stress disorder"</span>),</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">child sexual abuse</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">csa</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"child sexual abuse"</span>),</span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">urban greenspace</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">ugs</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"urban greenspace"</span>),</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># User added from analysis</span></span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">out</span><span class="pp">[</span><span class="ch">\-</span><span class="dv">\s</span><span class="pp">]</span><span class="vs">of</span><span class="pp">[</span><span class="ch">\-</span><span class="dv">\s</span><span class="pp">]</span><span class="vs">home</span><span class="dv">\s</span><span class="op">+</span><span class="vs">care</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">oohc</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"out of home care"</span>),</span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- AI / ML terminology ---</span></span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">artificial intelligence</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">ai</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"artificial intelligence"</span>),</span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">r"</span><span class="dv">\b</span><span class="vs">machine learning</span><span class="dv">\b</span><span class="cf">|</span><span class="dv">\b</span><span class="vs">ml</span><span class="dv">\b</span><span class="vs">"</span>, <span class="st">"machine learning"</span>),</span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) Auto rules (selected from 2.1a.4 candidates)</span></span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a><span class="co">#    üëâ Manually copy-paste terms from `filtered_candidates_agg["term"]`</span></span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a>AUTO_PHRASES <span class="op">=</span> [</span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a>   <span class="st">"mental health"</span>, <span class="st">"criminal behavior"</span>, <span class="st">"substance use"</span>,</span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a>   <span class="st">"drug use"</span>, <span class="st">"criminogenic thinking"</span>, <span class="st">"violent crime"</span>, <span class="st">"mental illness"</span>,</span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a>   <span class="st">"criminogenic risk"</span>, <span class="st">"risk assessment"</span>, <span class="st">"criminogenic risk"</span>,</span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a>   <span class="st">"risk terrain modelling"</span>, <span class="st">"hostile attributional biases"</span>,</span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a>   <span class="st">"adult-child sex advocacy"</span>, <span class="st">"motor vehicle theft"</span>, <span class="st">"red light district"</span>,</span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>   <span class="st">"malicious hoax calls"</span>, <span class="st">"papua new guinea"</span>, <span class="st">"outlaw motorcycle gangs"</span></span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a>CONCEPT_PATTERNS_AUTO <span class="op">=</span> [</span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a>    (<span class="vs">rf"</span><span class="dv">\b</span><span class="sc">{</span>re<span class="sc">.</span>escape(p)<span class="sc">}</span><span class="dv">\b</span><span class="vs">"</span>, p) <span class="cf">for</span> p <span class="kw">in</span> AUTO_PHRASES</span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) Final combined concept patterns (keep original name)</span></span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a>CONCEPT_PATTERNS <span class="op">=</span> CONCEPT_PATTERNS_CORE <span class="op">+</span> CONCEPT_PATTERNS_AUTO</span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Pre-compile patterns</span></span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a>_CONCEPT_RX <span class="op">=</span> [(re.<span class="bu">compile</span>(p, re.IGNORECASE), canon) <span class="cf">for</span> p, canon <span class="kw">in</span> CONCEPT_PATTERNS]</span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-87"><a href="#cb21-87" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb21-88"><a href="#cb21-88" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1 Normalization function</span></span>
<span id="cb21-89"><a href="#cb21-89" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb21-90"><a href="#cb21-90" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> normalize_concepts(text: <span class="bu">str</span>, style: <span class="bu">str</span> <span class="op">=</span> <span class="st">"spaces"</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb21-91"><a href="#cb21-91" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""style='spaces' -&gt; natural phrase; style='underscores' -&gt; protected unigram."""</span></span>
<span id="cb21-92"><a href="#cb21-92" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(text, <span class="bu">str</span>) <span class="kw">or</span> <span class="kw">not</span> text:</span>
<span id="cb21-93"><a href="#cb21-93" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">""</span></span>
<span id="cb21-94"><a href="#cb21-94" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> text</span>
<span id="cb21-95"><a href="#cb21-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> rx, canon <span class="kw">in</span> _CONCEPT_RX:</span>
<span id="cb21-96"><a href="#cb21-96" aria-hidden="true" tabindex="-1"></a>        repl <span class="op">=</span> canon <span class="cf">if</span> style <span class="op">==</span> <span class="st">"spaces"</span> <span class="cf">else</span> canon.replace(<span class="st">" "</span>, <span class="st">"_"</span>)</span>
<span id="cb21-97"><a href="#cb21-97" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> rx.sub(repl, out)</span>
<span id="cb21-98"><a href="#cb21-98" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="c-concept-normalization-diagnostics-optional" class="level3">
<h3 class="anchored" data-anchor-id="c-concept-normalization-diagnostics-optional">2.1c) Concept Normalization Diagnostics (Optional)</h3>
<p>Before we build <code>__embed_text__</code>, we can quickly check <strong>which concepts are actually being detected</strong> by our regex patterns.</p>
<p>This helps to:</p>
<ul>
<li>verify that acronyms (e.g., SAT, RAT, RNR, AI) are being picked up</li>
<li>see which criminology and AI concepts are most common</li>
<li>debug patterns that might be too broad or too narrow</li>
</ul>
<p>We will:</p>
<ol type="1">
<li>Scan <code>__clean__</code> using the same compiled patterns (<code>_CONCEPT_RX</code>).</li>
<li>For each document, list which canonical concepts were found.</li>
<li>Aggregate counts to see how often each concept appears overall.</li>
</ol>
<div id="LI0J8R8Fkkp8" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.1b Concept Normalization Diagnostics (Optional)</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> detect_concepts(text: <span class="bu">str</span>):</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Return a sorted list of canonical concepts matched in this text."""</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(text, <span class="bu">str</span>) <span class="kw">or</span> <span class="kw">not</span> text:</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    found <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> rx, canon <span class="kw">in</span> _CONCEPT_RX:</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> rx.search(text):</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>            found.add(canon)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sorted</span>(found)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Per-document detected concepts (based on __clean__)</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"__concept_hits__"</span>] <span class="op">=</span> df[<span class="st">"__clean__"</span>].<span class="bu">apply</span>(detect_concepts)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Global frequency across the whole corpus</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>all_hits <span class="op">=</span> [c <span class="cf">for</span> hits <span class="kw">in</span> df[<span class="st">"__concept_hits__"</span>] <span class="cf">for</span> c <span class="kw">in</span> hits]</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> Counter(all_hits)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"üîé Detected canonical concepts (from CONCEPT_PATTERNS):"</span>)</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> canon, n <span class="kw">in</span> counts.most_common():</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"- </span><span class="sc">{</span>canon<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>n<span class="sc">}</span><span class="ss"> documents"</span>)</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st"> Example rows with detected concepts:"</span>)</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="uJEAuGCtxR_j" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>display(df[[<span class="st">"id"</span>, <span class="st">"unique_id"</span>, <span class="st">"__clean__"</span>, <span class="st">"__concept_hits__"</span>]].head(<span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="build-embedding-text-__embed_text__" class="level2">
<h2 class="anchored" data-anchor-id="build-embedding-text-__embed_text__">2.2) Build Embedding Text (<code>__embed_text__</code>)</h2>
<p>Using the <code>normalize_concepts()</code> function, we now construct the embedding-ready text:</p>
<ul>
<li>Start from <code>__clean__</code><br>
</li>
<li>Apply concept normalization with <code>style="spaces"</code><br>
</li>
<li>Store the result in:</li>
</ul>
<p><code>df["__embed_text__"]</code></p>
<p>This column will be the <strong>input text for SPECTER2 embeddings</strong> in the next step.</p>
<div id="Re6JofLUi0sa" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.2 Build embedding text from __clean__</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"__embed_text__"</span>] <span class="op">=</span> df[<span class="st">"__clean__"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> s: normalize_concepts(s, <span class="st">"spaces"</span>))</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚úÖ Created __embed_text__ for SPECTER2 embeddings."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="generate-specter2-embeddings" class="level2">
<h2 class="anchored" data-anchor-id="generate-specter2-embeddings">2.3) Generate SPECTER2 Embeddings</h2>
<p>In this step, we convert each document into a dense semantic vector using the SPECTER2 transformer model from AllenAI. These embeddings represent the conceptual meaning of the text and will later be used by BERTopic and TDA.</p>
<section id="why-specter2" class="level3">
<h3 class="anchored" data-anchor-id="why-specter2">üîç Why SPECTER2?</h3>
<p>SPECTER2 is trained specifically on scientific literature, which allows it to better understand academic text, citation contexts, research topics, and domain terminology. This leads to richer and more accurate embeddings than general-purpose language models.</p>
</section>
<section id="input-text-used-for-embedding" class="level3">
<h3 class="anchored" data-anchor-id="input-text-used-for-embedding">üß† Input Text Used for Embedding</h3>
<p>We embed the column <strong><code>__embed_text__</code></strong>, which was created in Step 2.2. This column contains lightly cleaned language with criminology and AI concepts normalized into consistent canonical phrases.</p>
<p>If <code>__embed_text__</code> is not available (e.g., for debugging), the process safely falls back to the column <strong><code>__clean__</code></strong>.</p>
</section>
<section id="what-happens-during-embedding" class="level3">
<h3 class="anchored" data-anchor-id="what-happens-during-embedding">‚öôÔ∏è What Happens During Embedding?</h3>
<ol type="1">
<li><p><strong>Text selection</strong><br>
The notebook chooses the correct column (<code>__embed_text__</code> or <code>__clean__</code>) and converts it into a list of raw text strings.</p></li>
<li><p><strong>Loading SPECTER2</strong><br>
We load the model and tokenizer from the checkpoint:<br>
<code>allenai/specter2_aug2023refresh_base</code>.</p></li>
<li><p><strong>GPU acceleration (if available)</strong><br>
If Colab detects a CUDA-enabled GPU, the model runs significantly faster.</p></li>
<li><p><strong>Batch tokenization</strong><br>
Texts are tokenized with padding and truncation (max length 512), and processed in batches for memory efficiency.</p></li>
<li><p><strong>Mean pooling</strong><br>
For each document, token embeddings are averaged across all valid tokens to obtain one fixed-length vector.</p></li>
<li><p><strong>L2 normalization</strong><br>
Each embedding is normalized so that vector magnitude does not affect BERTopic clustering or similarity calculations.</p></li>
<li><p><strong>Final embedding matrix</strong><br>
All document vectors are stacked into one NumPy array called <strong><code>embeddings</code></strong>.</p></li>
</ol>
</section>
<section id="output-of-this-step" class="level3">
<h3 class="anchored" data-anchor-id="output-of-this-step">üì¶ Output of This Step</h3>
<p>The final output is:</p>
<ul>
<li><strong><code>embeddings</code></strong> ‚Üí a matrix of shape <code>(num_documents, embedding_dimension)</code><br>
(usually <code>(N, 768)</code> for SPECTER2 Base)</li>
</ul>
<p>This embedding matrix is the core numerical representation of your text and will be used directly in Section 3 for topic modelling.</p>
<div id="56OMiZuvbn_6" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate SPECTER2 embeddings from __embed_text__</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, AutoModel</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>MODEL_NAME <span class="op">=</span> <span class="st">"allenai/specter2_aug2023refresh_base"</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) Pick the text column (prefer __embed_text__)</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>text_col <span class="op">=</span> <span class="st">"__embed_text__"</span> <span class="cf">if</span> <span class="st">"__embed_text__"</span> <span class="kw">in</span> df.columns <span class="cf">else</span> <span class="st">"__clean__"</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> df[text_col].fillna(<span class="st">""</span>).astype(<span class="bu">str</span>).tolist()</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üìÑ Number of documents to embed: </span><span class="sc">{</span><span class="bu">len</span>(texts)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üìù Using text column: </span><span class="sc">{</span>text_col<span class="sc">!r}</span><span class="ss">"</span>)</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üß† Model: </span><span class="sc">{</span>MODEL_NAME<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) Device setup (GPU if available)</span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üíª Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) Load tokenizer and model</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(MODEL_NAME)</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModel.from_pretrained(MODEL_NAME).to(device)</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a><span class="co"># 4) Helper: mean pooling + L2-normalization</span></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> encode_specter2(texts, batch_size<span class="op">=</span><span class="dv">16</span>):</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>    all_embeddings <span class="op">=</span> []</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.inference_mode():</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> tqdm(<span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(texts), batch_size), desc<span class="op">=</span><span class="st">"Encoding"</span>):</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>            batch_texts <span class="op">=</span> texts[i:i <span class="op">+</span> batch_size]</span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>            enc <span class="op">=</span> tokenizer(</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>                batch_texts,</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>                padding<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>                truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>                max_length<span class="op">=</span><span class="dv">512</span>,</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>                return_tensors<span class="op">=</span><span class="st">"pt"</span></span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>            ).to(device)</span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(<span class="op">**</span>enc)</span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>            last_hidden <span class="op">=</span> outputs.last_hidden_state          <span class="co"># [batch, seq_len, hidden]</span></span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>            attn_mask <span class="op">=</span> enc[<span class="st">"attention_mask"</span>].unsqueeze(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># [batch, seq_len, 1]</span></span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Mean pooling over non-masked tokens</span></span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a>            summed <span class="op">=</span> (last_hidden <span class="op">*</span> attn_mask).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>            counts <span class="op">=</span> attn_mask.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>).clamp(<span class="bu">min</span><span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a>            mean_pooled <span class="op">=</span> (summed <span class="op">/</span> counts).cpu().numpy()</span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a>            <span class="co"># L2 normalize each vector</span></span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a>            norms <span class="op">=</span> np.linalg.norm(mean_pooled, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a>            mean_pooled <span class="op">=</span> mean_pooled <span class="op">/</span> np.clip(norms, <span class="fl">1e-8</span>, <span class="va">None</span>)</span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a>            all_embeddings.append(mean_pooled)</span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.vstack(all_embeddings)</span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a><span class="co"># 5) Run encoding</span></span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> encode_specter2(texts, batch_size<span class="op">=</span>BATCH_SIZE)</span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚úÖ Embeddings computed."</span>)</span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   Shape:"</span>, embeddings.shape)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
</section>
<section id="save-embeddings-for-reuse-optional" class="level2">
<h2 class="anchored" data-anchor-id="save-embeddings-for-reuse-optional">2.4) Save Embeddings for Reuse (Optional)</h2>
<p>Computing SPECTER2 embeddings can be time-consuming, especially on large datasets or when running on CPU.</p>
<p>To avoid recomputing embeddings every time we run the notebook, we can optionally <strong>save the embedding matrix</strong> and a simple <strong>index map</strong> that links DataFrame rows back to embedding rows.</p>
<p>This allows us to:</p>
<ul>
<li>load embeddings instantly on future runs<br>
</li>
<li>skip the entire embedding step<br>
</li>
<li>ensure BERTopic and TDA always use the same embedding vectors</li>
</ul>
<p>Saving is <strong>disabled by default</strong>.<br>
You can enable it later by removing the comment markers.</p>
<div id="6UTz4vWxpmmz" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 2.4 (Optional) Save embeddings + index map</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Uncomment when needed:</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co"># SAVE_PATH = f"{PROJECT_DIR}/specter2_embeddings.npy"</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="co"># INDEX_PATH = f"{PROJECT_DIR}/embedding_index_map.csv"</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="co"># # Save the embeddings</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="co"># np.save(SAVE_PATH, embeddings)</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="co"># # Save a simple index map (row_index links back to df rows)</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a><span class="co"># df[["id"]].assign(row_index=np.arange(len(df))).to_csv(INDEX_PATH, index=False)</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"üíæ Saved embeddings to: {SAVE_PATH}")</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"üìÑ Saved index map to: {INDEX_PATH}")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<hr>
</section>
<section id="conclusion-1" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-1">2.5) Conclusion</h2>
<p>In this section, we transformed the cleaned bibliographic text into high-quality <strong>semantic embeddings</strong> using the SPECTER2 model from AllenAI. These embeddings capture the conceptual meaning of each document and form the core numerical representation that BERTopic and TDA will operate on in the next section.</p>
<section id="what-we-accomplished-1" class="level3">
<h3 class="anchored" data-anchor-id="what-we-accomplished-1">‚úî What we accomplished</h3>
<ol type="1">
<li><strong>Standardized criminology and AI terminology</strong>
<ul>
<li>Using custom regex patterns, we normalized acronyms and variants (e.g., SAT ‚Üí situational action theory, AI ‚Üí artificial intelligence).</li>
<li>Ensured consistent conceptual language across the corpus.</li>
</ul></li>
<li><strong>Built embedding-ready text (<code>__embed_text__</code>)</strong>
<ul>
<li>Derived from <code>__clean__</code></li>
<li>Preserved natural language</li>
<li>Applied canonical phrase normalization</li>
<li>Provided a stable input for the transformer model</li>
</ul></li>
<li><strong>Generated SPECTER2 embeddings</strong>
<ul>
<li>Loaded <code>allenai/specter2_aug2023refresh_base</code></li>
<li>Tokenized and encoded documents in batches</li>
<li>Applied mean-pooling over token embeddings</li>
<li>L2-normalized each vector for stable clustering</li>
<li>Produced a dense semantic vector matrix called <code>embeddings</code></li>
</ul></li>
<li><strong>Prepared for reuse (optional saving)</strong>
<ul>
<li>Added an optional (commented) step to save the embedding matrix and index map so future runs can skip the embedding process entirely.</li>
</ul></li>
</ol>
</section>
<section id="outputs-produced-in-section-2" class="level3">
<h3 class="anchored" data-anchor-id="outputs-produced-in-section-2">üì¶ Outputs produced in Section 2</h3>
<ul>
<li><code>__embed_text__</code> ‚Äî embedding-ready natural language text<br>
</li>
<li><code>embeddings</code> ‚Äî SPECTER2 semantic vectors (NumPy array)<br>
</li>
<li>(Optional) <code>specter2_embeddings.npy</code> ‚Äî saved embedding file<br>
</li>
<li>(Optional) <code>embedding_index_map.csv</code> ‚Äî mapping between DataFrame rows and embedding rows</li>
</ul>
</section>
<section id="whats-next-1" class="level3">
<h3 class="anchored" data-anchor-id="whats-next-1">üöÄ What‚Äôs next?</h3>
<p>With the semantic vectors computed, we now move to:</p>
<p><strong>Section 3: Topic Modelling (BERTopic)</strong></p>
<p>In this next section we will:</p>
<ul>
<li>create the vectorizer text (<code>__vectorizer_text__</code>)</li>
<li>initialize BERTopic with precomputed embeddings</li>
<li>generate topic clusters</li>
<li>inspect topic quality and keywords</li>
<li>prepare topic tables for interpretation</li>
</ul>
<p>The embeddings from Section 2 will now act as the foundation for all topic discovery and downstream analysis.</p>
<hr>
</section>
</section>
</section>
<section id="section-3-topic-modelling-bertopic" class="level1">
<h1>Section 3: Topic Modelling (BERTopic)</h1>
<p>In this section, we use <strong>BERTopic</strong> to discover topics from our documents. BERTopic combines:</p>
<ul>
<li><strong>transformer embeddings</strong> (from Section 2)<br>
</li>
<li><strong>a bag-of-words representation</strong> (C-TF-IDF)</li>
</ul>
<p>Therefore, we need a <strong>separate text field</strong> that is optimized for the vectorizer, not for the embedding model.</p>
<hr>
<section id="build-vectorizer-text-__vectorizer_text__" class="level2">
<h2 class="anchored" data-anchor-id="build-vectorizer-text-__vectorizer_text__">3.1) Build Vectorizer Text (<code>__vectorizer_text__</code>)</h2>
<p>For topic modelling, BERTopic uses a CountVectorizer-like representation to build C-TF-IDF topic-word distributions. This representation has different needs compared to SPECTER2 embeddings.</p>
<p>We construct a new text field:</p>
<p><code>__vectorizer_text__</code></p>
<p>from <code>__clean__</code> with the following steps:</p>
<ol type="1">
<li><strong>Remove the literal <code>[SEP]</code> tokens</strong>
<ul>
<li><p>Replace <code>[SEP]</code> with a sentence boundary:</p>
<pre><code>.</code></pre></li>
<li><p>This keeps the idea of separate sections but avoids treating <code>[SEP]</code> as a token.</p></li>
</ul></li>
<li><strong>Normalize concepts with underscores</strong>
<ul>
<li>Apply <code>normalize_concepts(..., style="underscores")</code></li>
<li>Examples:
<ul>
<li><code>situational action theory</code> ‚Üí <code>situational_action_theory</code></li>
<li><code>routine activity theory</code> ‚Üí <code>routine_activity_theory</code></li>
<li><code>artificial intelligence</code> ‚Üí <code>artificial_intelligence</code></li>
</ul></li>
<li>This makes multi-word concepts act as <strong>single tokens</strong> in the vectorizer.</li>
</ul></li>
<li><strong>Protect important phrases</strong>
<ul>
<li>Optionally, we can wrap or preserve specific phrases so that the vectorizer does not break them apart.</li>
<li>This is done using a helper function <code>protect_phrases()</code>.</li>
</ul></li>
</ol>
<p>The result is a text field that is:</p>
<ul>
<li>still readable<br>
</li>
<li>tokenized in a way that preserves key criminology/AI concepts<br>
</li>
<li>optimized for CountVectorizer / C-TF-IDF in BERTopic</li>
</ul>
<p>BERTopic will later use:</p>
<ul>
<li><code>__vectorizer_text__</code> for its internal topic-word representations<br>
</li>
<li><code>embeddings</code> (from Section 2) for its document-level clustering</li>
</ul>
<div id="Zz21AztfsVSo" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 3.1 Build vectorizer text for BERTopic from __clean__</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co">#    - remove [SEP] tokens (turn into sentence boundary)</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co">#    - normalize concepts with underscores (single-token phrases)</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co">#    - optional phrase protection hook</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> protect_phrases(text: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Optional hook to further protect important phrases.</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Currently returns text unchanged, but you can extend this later</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="co">    if you want to enforce extra rules on top of underscore concepts.</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(text, <span class="bu">str</span>):</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">""</span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"__vectorizer_text__"</span>] <span class="op">=</span> (</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">"__clean__"</span>]</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>      <span class="co"># 1) Replace [SEP] with a sentence boundary</span></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>      .<span class="bu">str</span>.replace(<span class="vs">r"</span><span class="dv">\s</span><span class="op">*</span><span class="ch">\[</span><span class="vs">SEP</span><span class="ch">\]</span><span class="dv">\s</span><span class="op">*</span><span class="vs">"</span>, <span class="st">". "</span>, regex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>      <span class="co"># 2) Normalize concepts to underscore form (for vectorizer tokens)</span></span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>      .<span class="bu">apply</span>(<span class="kw">lambda</span> s: normalize_concepts(s, style<span class="op">=</span><span class="st">"underscores"</span>))</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>      <span class="co"># 3) Optional phrase-protection hook</span></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>      .<span class="bu">apply</span>(protect_phrases)</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚úÖ Created __vectorizer_text__ for BERTopic."</span>)</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="pWrbKx_y7mWC" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>display(df[[<span class="st">"__clean__"</span>, <span class="st">"__vectorizer_text__"</span>]].head(<span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<section id="a-explore-tfidf-of-non-english-stopwords" class="level3">
<h3 class="anchored" data-anchor-id="a-explore-tfidf-of-non-english-stopwords">3.1a) Explore TF‚ÄìIDF of Non-English Stopwords</h3>
<p>Before defining custom stopwords and boilerplate terms, we first explore which words are most common and most rare in our vectorizer text.</p>
<p>In this step, we:</p>
<ol type="1">
<li>Use <code>TfidfVectorizer</code> on <code>__vectorizer_text__</code></li>
<li>Remove only <strong>standard English stopwords</strong> (sklearn)</li>
<li>Keep underscore-protected tokens (e.g., <code>situational_action_theory</code>)</li>
<li>Compute:
<ul>
<li>the total TF‚ÄìIDF weight per term across the corpus</li>
<li>the document frequency (how many documents contain each term)</li>
</ul></li>
<li>Inspect:
<ul>
<li>the <strong>most influential terms</strong> (highest summed TF‚ÄìIDF)</li>
<li>the <strong>least influential but still occurring terms</strong></li>
</ul></li>
</ol>
<p>This helps us decide which additional academic or domain-specific words might be good candidates for custom stopword/boilerplate removal in the next step (3.1b).</p>
<div id="0flCBRQBNyqM" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 3.1a TF‚ÄìIDF Exploration of Non-English Stopwords Terms</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>tfidf_vectorizer <span class="op">=</span> TfidfVectorizer(</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    stop_words<span class="op">=</span><span class="st">"english"</span>,            <span class="co"># ‚úî built-in stopwords</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    token_pattern<span class="op">=</span><span class="vs">r"</span><span class="fu">(?u)</span><span class="dv">\b\w</span><span class="op">+</span><span class="dv">\b</span><span class="vs">"</span>,    <span class="co"># keep underscore tokens</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    lowercase<span class="op">=</span><span class="va">True</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>X_tfidf <span class="op">=</span> tfidf_vectorizer.fit_transform(</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">"__vectorizer_text__"</span>].fillna(<span class="st">""</span>).astype(<span class="bu">str</span>).tolist()</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>terms <span class="op">=</span> np.array(tfidf_vectorizer.get_feature_names_out())</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Total TF‚ÄìIDF weight per term</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>tfidf_sum <span class="op">=</span> np.asarray(X_tfidf.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)).ravel()</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a><span class="co"># How many docs contain each term</span></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>doc_freq <span class="op">=</span> np.asarray((X_tfidf <span class="op">&gt;</span> <span class="dv">0</span>).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)).ravel()</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>tfidf_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">"term"</span>: terms,</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">"tfidf_sum"</span>: tfidf_sum,</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">"doc_freq"</span>: doc_freq</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>top_terms <span class="op">=</span> (</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>    tfidf_df.sort_values(<span class="st">"tfidf_sum"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>    .head(<span class="dv">30</span>)</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>rare_terms <span class="op">=</span> (</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>    tfidf_df[tfidf_df[<span class="st">"doc_freq"</span>].between(<span class="dv">2</span>, <span class="dv">5</span>)]</span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>    .sort_values(<span class="st">"tfidf_sum"</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>    .head(<span class="dv">30</span>)</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"üîù Top 30 terms by total TF‚ÄìIDF weight (non-English-stopwords):"</span>)</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a>display(top_terms)</span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üß© Rare terms (doc_freq between 2 and 5):"</span>)</span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>display(rare_terms)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="uj4-lXVOPnqt" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 3.1a-b Visualize Common vs Rare TF‚ÄìIDF Terms</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Safety check</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"tfidf_df"</span> <span class="kw">not</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"tfidf_df not found. Run the TF‚ÄìIDF cell before this visualization cell."</span>)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) Top common / high-impact terms</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>top_terms <span class="op">=</span> (</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    tfidf_df.sort_values(<span class="st">"tfidf_sum"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    .head(<span class="dv">20</span>)</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) Rare-but-present terms (doc_freq between 2 and 5, lowest TF‚ÄìIDF sum)</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>rare_terms <span class="op">=</span> (</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>    tfidf_df[tfidf_df[<span class="st">"doc_freq"</span>].between(<span class="dv">2</span>, <span class="dv">5</span>)]</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>    .sort_values(<span class="st">"tfidf_sum"</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>    .head(<span class="dv">20</span>)</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Plot 1: Common / High TF‚ÄìIDF terms ---</span></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>sns.barplot(</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>top_terms,</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"tfidf_sum"</span>,</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span><span class="st">"term"</span></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Top 20 Terms by Total TF‚ÄìIDF Weight"</span>)</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Total TF‚ÄìIDF (sum over documents)"</span>)</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Term"</span>)</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Plot 2: Rare Terms (Low TF‚ÄìIDF, Appearing in 2‚Äì5 Documents) ---</span></span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>sns.barplot(</span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>rare_terms,</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"tfidf_sum"</span>,</span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span><span class="st">"term"</span></span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Rare Terms (Doc Freq 2‚Äì5) with Lowest TF‚ÄìIDF"</span>)</span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Total TF‚ÄìIDF (sum over documents)"</span>)</span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Term"</span>)</span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚úÖ Plots generated: common vs rare TF‚ÄìIDF terms."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="how-to-use-tfidf-insights-before-proceeding-to-step-3.1b" class="level3">
<h3 class="anchored" data-anchor-id="how-to-use-tfidf-insights-before-proceeding-to-step-3.1b">How to Use TF‚ÄìIDF Insights Before Proceeding to Step 3.1b</h3>
<p>The TF‚ÄìIDF exploration (Step 3.1a) gives us a data-driven view of which terms appear frequently and which appear rarely across the corpus.<br>
This information is useful for refining our stopword and boilerplate lists before running BERTopic.</p>
<p>Here is how to interpret the results and decide what to update:</p>
<hr>
<section id="high-tfidf-terms-most-influential" class="level4">
<h4 class="anchored" data-anchor-id="high-tfidf-terms-most-influential">üîù 1. High TF‚ÄìIDF Terms (Most Influential)</h4>
<p>These words dominate the corpus and strongly affect C-TF-IDF topic formation.</p>
<p>Look at the <strong>Top Terms plot</strong> and ask:</p>
<ul>
<li>Are there <em>generic</em> or <em>non-criminology</em> terms appearing at the top? Examples might include:
<ul>
<li>‚Äúsystem‚Äù, ‚Äúmodel‚Äù, ‚Äútechnology‚Äù</li>
<li>‚Äúapproach‚Äù, ‚Äúinformation‚Äù, ‚Äúmethod‚Äù</li>
</ul></li>
<li>If these words are not meaningful for distinguishing criminogenic topics, consider adding them to the <strong>DOMAIN_STOPWORDS</strong> list.</li>
</ul>
<p>Avoid adding: - core criminology concepts (e.g., ‚Äúoffender‚Äù, ‚Äúcrime‚Äù, ‚Äúrisk‚Äù) - protected underscore phrases (e.g., <code>routine_activity_theory</code>)</p>
<hr>
</section>
<section id="rare-terms-doc-frequency-25" class="level4">
<h4 class="anchored" data-anchor-id="rare-terms-doc-frequency-25">üß© 2. Rare Terms (Doc Frequency 2‚Äì5)</h4>
<p>These are low-impact words, often due to: - typos or spelling variants<br>
- overly specific terminology<br>
- peripheral concepts</p>
<p>We <strong>do not need to add these to stopwords</strong>, because they occur too rarely to influence topic formation.<br>
This plot is mainly for diagnostic purposes (spotting strange tokens).</p>
<hr>
</section>
<section id="adjusting-the-stopword-lists" class="level4">
<h4 class="anchored" data-anchor-id="adjusting-the-stopword-lists">üßπ 3. Adjusting the Stopword Lists</h4>
<p>Based on the TF‚ÄìIDF review, update:</p>
<ol type="1">
<li><strong>ACADEMIC_STOPWORDS</strong>
<ul>
<li>Keep lemma forms only (e.g., <code>study</code> not <code>studies</code>)<br>
</li>
<li>Add/remove academic boilerplate depending on your dataset</li>
</ul></li>
<li><strong>DOMAIN_STOPWORDS</strong>
<ul>
<li>Add only <em>non-criminology</em> generic technical terms<br>
</li>
<li>Never add core criminology terms (e.g., ‚Äúcrime‚Äù, ‚Äúoffender‚Äù)</li>
</ul></li>
<li><strong>BASE_STOPWORDS</strong>
<ul>
<li>Use the default sklearn English stopwords (already included)</li>
</ul></li>
</ol>
<p>Any changes here will directly influence how BERTopic constructs topics.</p>
<hr>
</section>
<section id="when-you-are-satisfied" class="level4">
<h4 class="anchored" data-anchor-id="when-you-are-satisfied">üéØ When You Are Satisfied</h4>
<p>Once you have reviewed the TF‚ÄìIDF plots and adjusted your stopword lists, you can safely proceed to:</p>
</section>
</section>
<section id="b-stopwords-boilerplate-setup-lemma-friendly" class="level3">
<h3 class="anchored" data-anchor-id="b-stopwords-boilerplate-setup-lemma-friendly">üëâ <strong>3.1b Stopwords + Boilerplate Setup (Lemma-Friendly)</strong></h3>
<p>This ensures that your topic modelling pipeline is built on clean, interpretable, and domain-appropriate text.</p>
</section>
<section id="b-define-stopwords-and-boilerplate-terms-lemma-friendly" class="level3">
<h3 class="anchored" data-anchor-id="b-define-stopwords-and-boilerplate-terms-lemma-friendly">3.1b) Define Stopwords and Boilerplate Terms (Lemma-Friendly)</h3>
<p>Using the insights from the TF‚ÄìIDF exploration, we now define the stopword sets that will be used by BERTopic‚Äôs CountVectorizer.</p>
<p>At this stage, we only <strong>prepare</strong> the stopword lists. No text is modified yet.</p>
<p>Our stopword lists come from three components:</p>
<ol type="1">
<li><p><strong>English Stopwords (sklearn)</strong><br>
These remove common grammatical words such as ‚Äúthe‚Äù, ‚Äúand‚Äù, ‚Äúfor‚Äù. They do not carry topic-relevant meaning.</p></li>
<li><p><strong>Academic / Boilerplate Stopwords</strong><br>
These include high-frequency academic terms (e.g., ‚Äústudy‚Äù, ‚Äúresearch‚Äù) that frequently appear in abstracts but do not define criminogenic themes.<br>
These are stored in <strong>lemma form</strong>, because we will lemmatize the text before vectorization.</p></li>
<li><p><strong>Domain Stopwords (Non-criminology)</strong><br>
These include generic technical words (e.g., ‚Äúsystem‚Äù, ‚Äúmodel‚Äù) that may be overly influential but not meaningful for topic separation. Based on TF‚ÄìIDF, you can expand or reduce this list.</p></li>
</ol>
<p>‚ö† <strong>Important</strong>:<br>
We do <em>not</em> remove criminology core terms such as ‚Äúcrime‚Äù, ‚Äúoffender‚Äù, or ‚Äúcriminal‚Äù, because these are essential for topic interpretation.</p>
<p>All three groups are merged into a single <code>FINAL_STOPWORDS</code> set.<br>
This set will be passed directly into BERTopic‚Äôs CountVectorizer in Step 3.3.</p>
<div id="nZWW86y8H2Ze" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 3.1b Stopwords + Boilerplate Setup (lemma-friendly)</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> ENGLISH_STOP_WORDS</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) Base English stopwords (sklearn)</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>BASE_STOPWORDS <span class="op">=</span> <span class="bu">set</span>(ENGLISH_STOP_WORDS)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) Academic / boilerplate stopwords (lemma form only)</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>ACADEMIC_STOPWORDS <span class="op">=</span> {</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"study"</span>, <span class="st">"paper"</span>, <span class="st">"research"</span>, <span class="st">"method"</span>, <span class="st">"analysis"</span>,</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"result"</span>, <span class="st">"finding"</span>, <span class="st">"implication"</span>, <span class="st">"purpose"</span>,</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"objective"</span>, <span class="st">"author"</span>, <span class="st">"introduction"</span>, <span class="st">"discussion"</span>,</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"conclusion"</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) Domain stopwords (generic technical terms - lemma form only)</span></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">NOTE</span><span class="co">: Do NOT include criminology core terms like "crime", "offender"</span></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>DOMAIN_STOPWORDS <span class="op">=</span> {</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">"system"</span>,</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">"information"</span>,</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">"model"</span>,</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"approach"</span>,</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"technology"</span></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 4) Merge all stopwords</span></span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>FINAL_STOPWORDS <span class="op">=</span> (</span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>    BASE_STOPWORDS</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>    .union(ACADEMIC_STOPWORDS)</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>    .union(DOMAIN_STOPWORDS)</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üìù Total stopwords in FINAL_STOPWORDS: </span><span class="sc">{</span><span class="bu">len</span>(FINAL_STOPWORDS)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üìå Academic stopwords (lemma): </span><span class="sc">{</span><span class="bu">sorted</span>(<span class="bu">list</span>(ACADEMIC_STOPWORDS))[:<span class="dv">10</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üìå Domain stopwords (lemma): </span><span class="sc">{</span><span class="bu">sorted</span>(<span class="bu">list</span>(DOMAIN_STOPWORDS))<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="c-lemmatization-for-__vectorizer_text__-with-underscore-protection" class="level3">
<h3 class="anchored" data-anchor-id="c-lemmatization-for-__vectorizer_text__-with-underscore-protection">3.1c) Lemmatization for <code>__vectorizer_text__</code> (with Underscore Protection)</h3>
<p>To improve topic quality and ensure our stopword lists work correctly, we lemmatize the text used by BERTopic‚Äôs CountVectorizer.</p>
<p>Lemmatization reduces word variants to their base form:</p>
<ul>
<li>‚Äúmodels‚Äù ‚Üí ‚Äúmodel‚Äù<br>
</li>
<li>‚Äútechnologies‚Äù ‚Üí ‚Äútechnology‚Äù<br>
</li>
<li>‚Äústudies‚Äù ‚Üí ‚Äústudy‚Äù<br>
</li>
<li>‚Äúfindings‚Äù ‚Üí ‚Äúfinding‚Äù</li>
</ul>
<p>This step ensures that: - our lemma-based stopwords (e.g., ‚Äúmodel‚Äù, ‚Äústudy‚Äù) correctly match<br>
- BERTopic receives a cleaner, more consistent token space<br>
- topic keywords become sharper and less noisy</p>
<p>We <strong>do NOT</strong> lemmatize the embedding text (<code>__embed_text__</code>), because transformer models like SPECTER2 rely on natural grammar.</p>
<p>We also <strong>preserve underscore-protected multiword concepts</strong>, such as:</p>
<ul>
<li><code>routine_activity_theory</code></li>
<li><code>low_self_control</code></li>
<li><code>risk_need_responsivity</code></li>
</ul>
<p>These terms must remain intact as single tokens because they represent core criminological constructs.</p>
<div id="pb3Lbk9wUMEr" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 3.1c Lemmatization for __vectorizer_text__ (with tqdm progress bar)</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load spaCy English model (disable parser/ner for speed)</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Run this once if not installed:</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co"># !python -m spacy download en_core_web_sm</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> spacy.load(<span class="st">"en_core_web_sm"</span>, disable<span class="op">=</span>[<span class="st">"parser"</span>, <span class="st">"ner"</span>])</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lemmatize_token(tok):</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Lemmatize a single token unless underscore-protected."""</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">"_"</span> <span class="kw">in</span> tok:</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> tok  <span class="co"># preserve protected phrases</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>    doc <span class="op">=</span> nlp(tok)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> doc[<span class="dv">0</span>].lemma_</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lemmatize_vectorizer_text(text):</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Lemmatize a full __vectorizer_text__ string."""</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(text, <span class="bu">str</span>):</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">""</span></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> text.split()</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">" "</span>.join(lemmatize_token(t) <span class="cf">for</span> t <span class="kw">in</span> tokens)</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply with tqdm progress bar</span></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"__vectorizer_text__"</span>] <span class="op">=</span> [</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>    lemmatize_vectorizer_text(t)</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> tqdm(df[<span class="st">"__vectorizer_text__"</span>].astype(<span class="bu">str</span>), desc<span class="op">=</span><span class="st">"Lemmatizing __vectorizer_text__"</span>)</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"üî§ Lemmatization complete for __vectorizer_text__"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="WZxC9lk0VRVv" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>display(df[[<span class="st">"__clean__"</span>, <span class="st">"__vectorizer_text__"</span>]].head(<span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="d-inspect-stopword-boilerplate-removal-preview-only" class="level3">
<h3 class="anchored" data-anchor-id="d-inspect-stopword-boilerplate-removal-preview-only">3.1d) Inspect Stopword + Boilerplate Removal (Preview Only)</h3>
<p>Before passing <code>FINAL_STOPWORDS</code> into BERTopic, we create a small diagnostic preview showing how stopword and boilerplate removal would affect the lemmatized <code>__vectorizer_text__</code>.</p>
<p>For a sample of documents, we display:</p>
<ul>
<li>the original <code>__vectorizer_text__</code></li>
<li>a cleaned preview with stopwords removed</li>
<li>the list of tokens that were removed</li>
</ul>
<p>This helps verify that: - important criminology concepts are not being removed - academic boilerplate and generic technical terms are being removed as intended</p>
<div id="zH2_KiBqZSaW" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect Stopword + Boilerplate Removal (Preview Only)</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_stopwords_for_preview(text, stopwords):</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Return (kept_tokens, removed_tokens) for inspection only."""</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(text, <span class="bu">str</span>):</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [], []</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> text.split()</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    kept <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> tokens <span class="cf">if</span> t.lower() <span class="kw">not</span> <span class="kw">in</span> stopwords]</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    removed <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> tokens <span class="cf">if</span> t.lower() <span class="kw">in</span> stopwords]</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> kept, removed</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> []</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect first 3 rows (adjust if you want)</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, row <span class="kw">in</span> df.head(<span class="dv">3</span>).iterrows():</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    original <span class="op">=</span> row[<span class="st">"__vectorizer_text__"</span>]</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    kept, removed <span class="op">=</span> remove_stopwords_for_preview(original, FINAL_STOPWORDS)</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>    rows.append({</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"id"</span>: row.get(<span class="st">"id"</span>, i),</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"original_vectorizer_text"</span>: original,</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">"cleaned_preview"</span>: <span class="st">" "</span>.join(kept),</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">"removed_tokens"</span>: removed</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>preview_df <span class="op">=</span> pd.DataFrame(rows)</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"üîé Preview of stopword + boilerplate removal (first 20 rows):"</span>)</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="BXl-_Vq6ZXlZ" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>display(preview_df)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="nnoE9n_1biO4" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 3.1d (Full Dataset) ‚Äì Global Analysis of Removed Tokens</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_removed_tokens_full(text, stopwords):</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Return list of removed tokens for a full row."""</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(text, <span class="bu">str</span>):</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> text.split()</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [t.lower() <span class="cf">for</span> t <span class="kw">in</span> tokens <span class="cf">if</span> t.lower() <span class="kw">in</span> stopwords]</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>all_removed_full <span class="op">=</span> []</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate over ALL rows in the dataframe</span></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> txt <span class="kw">in</span> df[<span class="st">"__vectorizer_text__"</span>].astype(<span class="bu">str</span>):</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>    all_removed_full.extend(get_removed_tokens_full(txt, FINAL_STOPWORDS))</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üì¶ Total removed tokens across corpus (including English stopwords): </span><span class="sc">{</span><span class="bu">len</span>(all_removed_full)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Focus on non-English stopwords (i.e., custom academic + domain stopwords)</span></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> ENGLISH_STOP_WORDS</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>EN_STOPWORDS <span class="op">=</span> <span class="bu">set</span>(ENGLISH_STOP_WORDS)</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>non_english_removed <span class="op">=</span> [tok <span class="cf">for</span> tok <span class="kw">in</span> all_removed_full <span class="cf">if</span> tok <span class="kw">not</span> <span class="kw">in</span> EN_STOPWORDS]</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üì¶ Removed non-English stopwords (academic + domain etc.): </span><span class="sc">{</span><span class="bu">len</span>(non_english_removed)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Frequency count</span></span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a>removed_counter_full <span class="op">=</span> Counter(non_english_removed)</span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>top_removed_full <span class="op">=</span> removed_counter_full.most_common(<span class="dv">20</span>)  <span class="co"># top 20</span></span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> top_removed_full:</span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ö†Ô∏è No non-English stopwords removed across the corpus."</span>)</span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a>    tokens, counts <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>top_removed_full)</span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Barplot: Top removed non-English stopwords (full dataset)</span></span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb37-42"><a href="#cb37-42" aria-hidden="true" tabindex="-1"></a>    sns.barplot(x<span class="op">=</span><span class="bu">list</span>(counts), y<span class="op">=</span><span class="bu">list</span>(tokens))</span>
<span id="cb37-43"><a href="#cb37-43" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Top 20 Removed Non-English Stopwords"</span>)</span>
<span id="cb37-44"><a href="#cb37-44" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Frequency"</span>)</span>
<span id="cb37-45"><a href="#cb37-45" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Removed Token"</span>)</span>
<span id="cb37-46"><a href="#cb37-46" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb37-47"><a href="#cb37-47" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb37-48"><a href="#cb37-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-49"><a href="#cb37-49" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"üîç Top removed non-English stopwords (full corpus):"</span>)</span>
<span id="cb37-50"><a href="#cb37-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tok, cnt <span class="kw">in</span> top_removed_full:</span>
<span id="cb37-51"><a href="#cb37-51" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>tok<span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span>cnt<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="e-inspect-underscore-protected-tokens-in-__vectorizer_text__" class="level3">
<h3 class="anchored" data-anchor-id="e-inspect-underscore-protected-tokens-in-__vectorizer_text__">3.1e) Inspect Underscore-Protected Tokens in <code>__vectorizer_text__</code></h3>
<p>To verify that our concept normalization and underscore protection are working correctly, we inspect tokens that contain underscores in <code>__vectorizer_text__</code>.</p>
<p>These underscore tokens typically represent multiword criminology or AI concepts such as:</p>
<ul>
<li><code>routine_activity_theory</code></li>
<li><code>situational_action_theory</code></li>
<li><code>artificial_intelligence</code></li>
<li><code>risk_need_responsivity</code></li>
</ul>
<p>We list a sample of documents that contain such tokens and show the actual underscore terms. This helps confirm that important concepts are being preserved as single tokens for BERTopic.</p>
<div id="eH62_E0PcXGq" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 3.1e Inspect underscore-protected tokens in __vectorizer_text__</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> wordcloud <span class="im">import</span> WordCloud</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_underscore_tokens(text):</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Extract tokens with underscores from a string."""</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(text, <span class="bu">str</span>):</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> re.findall(<span class="vs">r"</span><span class="dv">\b</span><span class="pp">[a-zA-Z0-9]</span><span class="op">+</span>(?:<span class="vs">_</span><span class="pp">[a-zA-Z0-9]</span><span class="op">+</span>)<span class="op">+</span><span class="dv">\b</span><span class="vs">"</span>, text)</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract all underscore tokens into a list</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>all_underscore_tokens <span class="op">=</span> []</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"__underscore_hits__"</span>] <span class="op">=</span> df[<span class="st">"__vectorizer_text__"</span>].<span class="bu">apply</span>(</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: extract_underscore_tokens(x)</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Flatten all underscore tokens from the full dataset</span></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> lst <span class="kw">in</span> df[<span class="st">"__underscore_hits__"</span>]:</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(lst, <span class="bu">list</span>):</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>        all_underscore_tokens.extend(lst)</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>num_docs <span class="op">=</span> df[<span class="st">"__underscore_hits__"</span>].astype(<span class="bu">bool</span>).<span class="bu">sum</span>()</span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üìå Documents containing underscore-protected tokens: </span><span class="sc">{</span>num_docs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üì¶ Total underscore tokens across corpus: </span><span class="sc">{</span><span class="bu">len</span>(all_underscore_tokens)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Show examples</span></span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üîç Example rows with underscore tokens:"</span>)</span>
<span id="cb38-34"><a href="#cb38-34" aria-hidden="true" tabindex="-1"></a>display(</span>
<span id="cb38-35"><a href="#cb38-35" aria-hidden="true" tabindex="-1"></a>    df[df[<span class="st">"__underscore_hits__"</span>].astype(<span class="bu">bool</span>)]</span>
<span id="cb38-36"><a href="#cb38-36" aria-hidden="true" tabindex="-1"></a>      [[<span class="st">"id"</span>, <span class="st">"unique_id"</span>, <span class="st">"__underscore_hits__"</span>, <span class="st">"__vectorizer_text__"</span>]]</span>
<span id="cb38-37"><a href="#cb38-37" aria-hidden="true" tabindex="-1"></a>      .head(<span class="dv">2</span>)</span>
<span id="cb38-38"><a href="#cb38-38" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-39"><a href="#cb38-39" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="SaqtWbMIdC7_" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization 1: Barplot of Top Underscore Concepts</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>freq <span class="op">=</span> Counter(all_underscore_tokens)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>top_underscore <span class="op">=</span> freq.most_common(<span class="dv">20</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> top_underscore:</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    tokens, counts <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>top_underscore)</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    sns.barplot(x<span class="op">=</span><span class="bu">list</span>(counts), y<span class="op">=</span><span class="bu">list</span>(tokens))</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Top 20 Underscore-Protected Concepts"</span>)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Frequency"</span>)</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Concept"</span>)</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üîç Top underscore concepts:"</span>)</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t, c <span class="kw">in</span> top_underscore:</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>t<span class="sc">:&lt;40}</span><span class="ss"> </span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ö†Ô∏è No underscore tokens found."</span>)</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="f-conclusion" class="level3">
<h3 class="anchored" data-anchor-id="f-conclusion">3.1f) Conclusion</h3>
<p>In this section, we transformed our cleaned text into a format optimized for BERTopic‚Äôs C-TF-IDF topic modelling pipeline. This involved several carefully structured preprocessing steps to ensure high-quality, interpretable topics.</p>
<section id="key-steps-completed" class="level4">
<h4 class="anchored" data-anchor-id="key-steps-completed">üîß Key Steps Completed</h4>
<ol type="1">
<li><strong>Built <code>__vectorizer_text__</code></strong>
<ul>
<li>Started from the lightly cleaned <code>__clean__</code> column<br>
</li>
<li>Standardized sentence boundaries<br>
</li>
<li>Normalized multi-word criminology/AI concepts into underscore-protected tokens (e.g., <code>routine_activity_theory</code>)<br>
</li>
<li>Ensured these conceptual tokens behave as single units in topic modelling</li>
</ul></li>
<li><strong>Explored TF‚ÄìIDF Distributions (<code>3.1a</code>)</strong>
<ul>
<li>Computed corpus-wide TF‚ÄìIDF scores (excluding English stopwords)<br>
</li>
<li>Identified high-impact and rare terms<br>
</li>
<li>Used these insights to guide our stopword and boilerplate decisions</li>
</ul></li>
<li><strong>Defined Lemma-Friendly Stopwords (<code>3.1b</code>)</strong>
<ul>
<li>Combined English stopwords, academic boilerplate, and generic domain terms<br>
</li>
<li>Excluded all criminology-core words such as ‚Äúcrime‚Äù, ‚Äúoffender‚Äù, ‚Äúdelinquency‚Äù, etc.<br>
</li>
<li>Designed the stopword sets to align with upcoming lemmatization</li>
</ul></li>
<li><strong>Lemmatized <code>__vectorizer_text__</code> (<code>3.1c</code>)</strong>
<ul>
<li>Reduced tokens to their lemma form<br>
</li>
<li>Preserved underscore-protected criminological concepts<br>
</li>
<li>Ensured accurate matching with our lemma-based stopword lists</li>
</ul></li>
<li><strong>Inspected Stopword Removal (<code>3.1d</code>)</strong>
<ul>
<li>Previewed how stopwords affect text<br>
</li>
<li>Verified that only generic academic/domain terms were removed<br>
</li>
<li>Confirmed that key criminology concepts remained untouched<br>
</li>
<li>Visualized the most frequently removed non-English stopwords across the full dataset</li>
</ul></li>
<li><strong>Inspected Underscore-Protected Tokens (<code>3.1e</code>)</strong>
<ul>
<li>Extracted and reviewed all conceptual multi-word tokens<br>
</li>
<li>Verified the presence of core criminogenic constructs<br>
</li>
<li>Visualized the most common protected concepts to ensure proper phrase normalization</li>
</ul></li>
</ol>
</section>
<section id="why-this-matters-1" class="level4">
<h4 class="anchored" data-anchor-id="why-this-matters-1">üß† Why This Matters</h4>
<p>This multi-step preparation ensures that:</p>
<ul>
<li>BERTopic receives clean, semantically meaningful documents<br>
</li>
<li>High-frequency noise and academic boilerplate do not overwhelm topics<br>
</li>
<li>Conceptual criminology constructs remain intact<br>
</li>
<li>Topic clusters will be sharper, more coherent, and more interpretable<br>
</li>
<li>The pipeline is fully aligned with your methodological requirements for the review article</li>
</ul>
<p>With these steps complete, our text is now fully prepared for BERTopic‚Äôs embedding alignment and clustering process.</p>
<hr>
</section>
</section>
<section id="next-step-3.2-prepare-documents-check-embedding-alignment" class="level3">
<h3 class="anchored" data-anchor-id="next-step-3.2-prepare-documents-check-embedding-alignment">‚ñ∂Ô∏è Next Step: <strong>3.2 Prepare Documents &amp; Check Embedding Alignment</strong></h3>
<p>We now convert the processed vectorizer text into a <code>docs</code> list and validate alignment with the embedding matrix generated in Section 2.</p>
</section>
</section>
<section id="prepare-documents-and-validate-embedding-alignment" class="level2">
<h2 class="anchored" data-anchor-id="prepare-documents-and-validate-embedding-alignment">3.2) Prepare Documents and Validate Embedding Alignment</h2>
<p>BERTopic requires two perfectly aligned inputs:</p>
<ol type="1">
<li><strong>Documents (<code>docs</code>)</strong>
<ul>
<li>These are the lemmatized + cleaned strings from <code>__vectorizer_text__</code>.<br>
</li>
<li>They are used by BERTopic‚Äôs CountVectorizer to build the C-TF-IDF representation of topics.</li>
</ul></li>
<li><strong>Embeddings (<code>embeddings</code>)</strong>
<ul>
<li>These were generated previously in Section 2 using the SPECTER2 embedding model (<code>__embed_text__</code>).</li>
<li>Each embedding vector must correspond <em>exactly</em> to the same row in <code>docs</code>.</li>
</ul></li>
</ol>
<p>This step performs: - conversion of <code>__vectorizer_text__</code> into a document list<br>
- validation that the number of embeddings matches the number of documents<br>
- a hard safety check to prevent misalignment errors in BERTopic</p>
<p>If a mismatch is detected, we stop the pipeline immediately.</p>
<div id="OWBDdqIk-CH9" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 3.2 Prepare documents and embeddings for BERTopic</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Documents for BERTopic's CountVectorizer</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> df[<span class="st">"__vectorizer_text__"</span>].fillna(<span class="st">""</span>).astype(<span class="bu">str</span>).tolist()</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of documents</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>n_docs <span class="op">=</span> <span class="bu">len</span>(docs)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üìÑ Documents for BERTopic: </span><span class="sc">{</span>n_docs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Embedding alignment check</span></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>embedding_rows <span class="op">=</span> embeddings.shape[<span class="dv">0</span>]</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>embedding_dim <span class="op">=</span> embeddings.shape[<span class="dv">1</span>]</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> embedding_rows <span class="op">!=</span> n_docs:</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"‚ùå Misalignment detected:</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"   ‚Ü≥ embeddings rows = </span><span class="sc">{</span>embedding_rows<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"   ‚Ü≥ docs count      = </span><span class="sc">{</span>n_docs<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"</span><span class="ch">\n</span><span class="st">These MUST be identical before running BERTopic.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Check filtering steps in Section 1 for any dropped rows."</span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"‚úÖ Embeddings aligned: </span><span class="sc">{</span>embedding_rows<span class="sc">}</span><span class="ss"> vectors match </span><span class="sc">{</span>n_docs<span class="sc">}</span><span class="ss"> docs"</span>)</span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üî¢ Embedding dimension: </span><span class="sc">{</span>embedding_dim<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<section id="b-document-embedding-sanity-check" class="level3">
<h3 class="anchored" data-anchor-id="b-document-embedding-sanity-check">3.2b) Document &amp; Embedding Sanity Check</h3>
<p>Before running BERTopic, we perform a quick diagnostic check on both the lemmatized documents (<code>docs</code>) and their corresponding SPECTER2 embeddings.</p>
<p>This helps us detect:</p>
<ul>
<li>empty or near-empty documents<br>
</li>
<li>extremely short texts that may cause unstable clustering<br>
</li>
<li>unusual embedding vectors (e.g., zero vectors or extremely low norms)<br>
</li>
<li>alignment issues between text length and embedding magnitude</li>
</ul>
<p>These checks ensure that BERTopic receives clean, consistent inputs and helps prevent silent failures or low-quality topic formation.</p>
<div id="L_vk3kljemmJ" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 3.2b Sanity Check: Document Text &amp; Embedding Health</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert docs to Series for easy processing</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>docs_series <span class="op">=</span> pd.Series(docs)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Check document lengths</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>doc_lengths <span class="op">=</span> docs_series.<span class="bu">str</span>.split().<span class="bu">apply</span>(<span class="bu">len</span>)</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"üìè Document Length Statistics:"</span>)</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(doc_lengths.describe())</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Show extreme short docs (length &lt; 5)</span></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>short_docs_idx <span class="op">=</span> doc_lengths[doc_lengths <span class="op">&lt;</span> <span class="dv">5</span>].index.tolist()</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">‚ö†Ô∏è Documents with fewer than 5 tokens: </span><span class="sc">{</span><span class="bu">len</span>(short_docs_idx)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> short_docs_idx:</span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>    display(df.loc[short_docs_idx, [<span class="st">"id"</span>, <span class="st">"__vectorizer_text__"</span>, <span class="st">"__clean__"</span>]].head(<span class="dv">10</span>))</span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Embedding vector norms (to detect abnormal vectors)</span></span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a>embedding_norms <span class="op">=</span> np.linalg.norm(embeddings, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb41-25"><a href="#cb41-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-26"><a href="#cb41-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üìê Embedding Norm Statistics:"</span>)</span>
<span id="cb41-27"><a href="#cb41-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.Series(embedding_norms).describe())</span>
<span id="cb41-28"><a href="#cb41-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-29"><a href="#cb41-29" aria-hidden="true" tabindex="-1"></a>zero_vec_idx <span class="op">=</span> np.where(embedding_norms <span class="op">==</span> <span class="dv">0</span>)[<span class="dv">0</span>]</span>
<span id="cb41-30"><a href="#cb41-30" aria-hidden="true" tabindex="-1"></a>tiny_vec_idx <span class="op">=</span> np.where(embedding_norms <span class="op">&lt;</span> <span class="fl">1e-6</span>)[<span class="dv">0</span>]</span>
<span id="cb41-31"><a href="#cb41-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-32"><a href="#cb41-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">‚ö†Ô∏è Zero embedding vectors: </span><span class="sc">{</span><span class="bu">len</span>(zero_vec_idx)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb41-33"><a href="#cb41-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"‚ö†Ô∏è Nearly-zero embedding vectors (&lt;1e-6): </span><span class="sc">{</span><span class="bu">len</span>(tiny_vec_idx)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb41-34"><a href="#cb41-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-35"><a href="#cb41-35" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">len</span>(zero_vec_idx) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb41-36"><a href="#cb41-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üîç Example rows with zero embeddings:"</span>)</span>
<span id="cb41-37"><a href="#cb41-37" aria-hidden="true" tabindex="-1"></a>    display(df.loc[zero_vec_idx, [<span class="st">"id"</span>, <span class="st">"__embed_text__"</span>]].head())</span>
<span id="cb41-38"><a href="#cb41-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-39"><a href="#cb41-39" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Correlation between doc length and embedding norm (optional insight)</span></span>
<span id="cb41-40"><a href="#cb41-40" aria-hidden="true" tabindex="-1"></a>corr <span class="op">=</span> np.corrcoef(doc_lengths, embedding_norms)[<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb41-41"><a href="#cb41-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">üîó Correlation between document length and embedding norm: </span><span class="sc">{</span>corr<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
</section>
<section id="bertopic" class="level2">
<h2 class="anchored" data-anchor-id="bertopic">3.3) BERTopic</h2>
<section id="a-imports-helper-functions" class="level3">
<h3 class="anchored" data-anchor-id="a-imports-helper-functions">3.3a) Imports &amp; Helper Functions</h3>
<div id="5PxsWlPHm5Qm" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports &amp; Helper Functions</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> umap.umap_ <span class="im">as</span> umap</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> hdbscan</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bertopic <span class="im">import</span> BERTopic</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models.coherencemodel <span class="im">import</span> CoherenceModel</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.corpora <span class="im">import</span> Dictionary</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np, pandas <span class="im">as</span> pd</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------ Helpers ------------</span></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> topic_top_words(model: BERTopic, top_n: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10</span>):</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>    info <span class="op">=</span> model.get_topic_info()</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>    tids <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> info.Topic <span class="cf">if</span> t <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {t: [w <span class="cf">for</span> w, _ <span class="kw">in</span> model.get_topic(t)[:top_n]] <span class="cf">for</span> t <span class="kw">in</span> tids}</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> topic_diversity(tw: <span class="bu">dict</span>) <span class="op">-&gt;</span> <span class="bu">float</span>:</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>    allw <span class="op">=</span> [w <span class="cf">for</span> ws <span class="kw">in</span> tw.values() <span class="cf">for</span> w <span class="kw">in</span> ws]</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fl">100.0</span> <span class="op">*</span> (<span class="bu">len</span>(<span class="bu">set</span>(allw)) <span class="op">/</span> <span class="bu">max</span>(<span class="dv">1</span>, <span class="bu">len</span>(allw)))</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> c_npmi_from_texts(tw: <span class="bu">dict</span>, texts: <span class="bu">list</span>) <span class="op">-&gt;</span> <span class="bu">float</span>:</span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> tw:  <span class="co"># no topics</span></span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">-</span><span class="fl">1.0</span></span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>    tokenized_docs <span class="op">=</span> [t.split() <span class="cf">for</span> t <span class="kw">in</span> texts]</span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>    dictionary <span class="op">=</span> Dictionary(tokenized_docs)</span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a>    cm <span class="op">=</span> CoherenceModel(</span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a>        topics<span class="op">=</span><span class="bu">list</span>(tw.values()),</span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a>        texts<span class="op">=</span>tokenized_docs,</span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a>        dictionary<span class="op">=</span>dictionary,</span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a>        coherence<span class="op">=</span><span class="st">'c_npmi'</span></span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(cm.get_coherence())</span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate(model: BERTopic, docs: <span class="bu">list</span>, top_n<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a>    info <span class="op">=</span> model.get_topic_info()</span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a>    has_noise <span class="op">=</span> (<span class="op">-</span><span class="dv">1</span> <span class="kw">in</span> info.Topic.values) <span class="cf">if</span> <span class="bu">hasattr</span>(info, <span class="st">"Topic"</span>) <span class="cf">else</span> <span class="va">False</span></span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a>    noise_count <span class="op">=</span> <span class="bu">int</span>(info[info.Topic <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>][<span class="st">'Count'</span>]) <span class="cf">if</span> has_noise <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a>    n_topics <span class="op">=</span> <span class="bu">int</span>((info.Topic <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>).<span class="bu">sum</span>())</span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> n_topics <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">"n_topics"</span>: <span class="dv">0</span>, <span class="st">"noise_frac"</span>: <span class="fl">1.0</span>, <span class="st">"diversity"</span>: <span class="fl">0.0</span>, <span class="st">"c_npmi"</span>: <span class="op">-</span><span class="fl">1.0</span>}</span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a>    noise_frac <span class="op">=</span> noise_count <span class="op">/</span> <span class="bu">max</span>(<span class="dv">1</span>, <span class="bu">len</span>(docs))</span>
<span id="cb42-44"><a href="#cb42-44" aria-hidden="true" tabindex="-1"></a>    tw <span class="op">=</span> topic_top_words(model, top_n)</span>
<span id="cb42-45"><a href="#cb42-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb42-46"><a href="#cb42-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">"n_topics"</span>: n_topics,</span>
<span id="cb42-47"><a href="#cb42-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">"noise_frac"</span>: noise_frac,</span>
<span id="cb42-48"><a href="#cb42-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">"diversity"</span>: topic_diversity(tw),</span>
<span id="cb42-49"><a href="#cb42-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">"c_npmi"</span>: c_npmi_from_texts(tw, docs),</span>
<span id="cb42-50"><a href="#cb42-50" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb42-51"><a href="#cb42-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-52"><a href="#cb42-52" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_model(umap_params, hdb_params, vectorizer_params, min_topic_size, stop_words<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb42-53"><a href="#cb42-53" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb42-54"><a href="#cb42-54" aria-hidden="true" tabindex="-1"></a><span class="co">    Build BERTopic model using custom UMAP, HDBSCAN, and CountVectorizer.</span></span>
<span id="cb42-55"><a href="#cb42-55" aria-hidden="true" tabindex="-1"></a><span class="co">    - Preserves underscored tokens</span></span>
<span id="cb42-56"><a href="#cb42-56" aria-hidden="true" tabindex="-1"></a><span class="co">    - Accepts merged FINAL_STOPWORDS</span></span>
<span id="cb42-57"><a href="#cb42-57" aria-hidden="true" tabindex="-1"></a><span class="co">    - Embeddings will be passed manually at fit_transform()</span></span>
<span id="cb42-58"><a href="#cb42-58" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb42-59"><a href="#cb42-59" aria-hidden="true" tabindex="-1"></a>    umap_model <span class="op">=</span> umap.UMAP(<span class="op">**</span>umap_params)</span>
<span id="cb42-60"><a href="#cb42-60" aria-hidden="true" tabindex="-1"></a>    hdbscan_model <span class="op">=</span> hdbscan.HDBSCAN(<span class="op">**</span>hdb_params)</span>
<span id="cb42-61"><a href="#cb42-61" aria-hidden="true" tabindex="-1"></a>    vectorizer_model <span class="op">=</span> CountVectorizer(</span>
<span id="cb42-62"><a href="#cb42-62" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>vectorizer_params,</span>
<span id="cb42-63"><a href="#cb42-63" aria-hidden="true" tabindex="-1"></a>        stop_words<span class="op">=</span>stop_words,</span>
<span id="cb42-64"><a href="#cb42-64" aria-hidden="true" tabindex="-1"></a>        token_pattern<span class="op">=</span><span class="vs">r"</span><span class="fu">(?u)</span><span class="dv">\b\w</span><span class="op">+</span><span class="dv">\b</span><span class="vs">"</span>  <span class="co"># keep underscored tokens intact</span></span>
<span id="cb42-65"><a href="#cb42-65" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb42-66"><a href="#cb42-66" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> BERTopic(</span>
<span id="cb42-67"><a href="#cb42-67" aria-hidden="true" tabindex="-1"></a>        embedding_model<span class="op">=</span><span class="va">None</span>,          <span class="co"># we pass embeddings manually</span></span>
<span id="cb42-68"><a href="#cb42-68" aria-hidden="true" tabindex="-1"></a>        umap_model<span class="op">=</span>umap_model,</span>
<span id="cb42-69"><a href="#cb42-69" aria-hidden="true" tabindex="-1"></a>        hdbscan_model<span class="op">=</span>hdbscan_model,</span>
<span id="cb42-70"><a href="#cb42-70" aria-hidden="true" tabindex="-1"></a>        vectorizer_model<span class="op">=</span>vectorizer_model,</span>
<span id="cb42-71"><a href="#cb42-71" aria-hidden="true" tabindex="-1"></a>        min_topic_size<span class="op">=</span>min_topic_size,</span>
<span id="cb42-72"><a href="#cb42-72" aria-hidden="true" tabindex="-1"></a>        calculate_probabilities<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb42-73"><a href="#cb42-73" aria-hidden="true" tabindex="-1"></a>        verbose<span class="op">=</span><span class="va">False</span></span>
<span id="cb42-74"><a href="#cb42-74" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb42-75"><a href="#cb42-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="b-parameter-grid-for-bertopic-auto-tuning" class="level3">
<h3 class="anchored" data-anchor-id="b-parameter-grid-for-bertopic-auto-tuning">3.3b) Parameter grid for BERTopic auto-tuning</h3>
<div id="fzz7rCxRg0GU" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameter grid for BERTopic auto-tuning</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="co"># IMPORTANT: use vectorizer-ready text (after boilerplate removal + optional lemmatization)</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> df[<span class="st">"__vectorizer_text__"</span>].tolist()</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>desired_K <span class="op">=</span> <span class="dv">60</span>          <span class="co"># soft target for #topics</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>min_topics_allowed <span class="op">=</span> <span class="dv">6</span>  <span class="co"># skip degenerate runs</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> []</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------- UMAP --------------------</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n_neighbors <span class="kw">in</span> [<span class="dv">10</span>, <span class="dv">15</span>]:</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> min_dist <span class="kw">in</span> [<span class="fl">0.05</span>, <span class="fl">0.1</span>]:</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> n_components <span class="kw">in</span> [<span class="dv">10</span>, <span class="dv">15</span>]:</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>            <span class="co"># -------------------- HDBSCAN --------------------</span></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> min_cluster_size <span class="kw">in</span> [<span class="dv">8</span>, <span class="dv">10</span>]:</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> min_samples <span class="kw">in</span> [<span class="dv">1</span>, <span class="dv">2</span>]:</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># -------------------- BERTopic min topic size --------------------</span></span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">for</span> min_topic_size <span class="kw">in</span> [<span class="dv">5</span>, <span class="dv">8</span>]:</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># -------------------- Merge tolerance (epsilon) --------------------</span></span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">for</span> eps <span class="kw">in</span> [<span class="fl">0.00</span>, <span class="fl">0.05</span>]:</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>                            param_grid.append({</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"umap"</span>: {</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"n_neighbors"</span>: n_neighbors,</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"n_components"</span>: n_components,</span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"min_dist"</span>: min_dist,</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"metric"</span>: <span class="st">"cosine"</span>,</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"random_state"</span>: SEED,</span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>                                },</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"hdb"</span>: {</span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"min_cluster_size"</span>: min_cluster_size,</span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"min_samples"</span>: min_samples,</span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"metric"</span>: <span class="st">"euclidean"</span>,</span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"cluster_selection_method"</span>: <span class="st">"eom"</span>,</span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"cluster_selection_epsilon"</span>: eps,</span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"prediction_data"</span>: <span class="va">True</span>,</span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a>                                },</span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"vec"</span>: {</span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"ngram_range"</span>: (<span class="dv">1</span>, <span class="dv">2</span>),</span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"min_df"</span>: <span class="dv">2</span>,</span>
<span id="cb43-44"><a href="#cb43-44" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"max_df"</span>: <span class="fl">1.0</span>,</span>
<span id="cb43-45"><a href="#cb43-45" aria-hidden="true" tabindex="-1"></a>                                    <span class="co"># </span><span class="al">NOTE</span><span class="co">: stopwords are passed via build_model(..., stop_words=FINAL_STOPWORDS)</span></span>
<span id="cb43-46"><a href="#cb43-46" aria-hidden="true" tabindex="-1"></a>                                    <span class="co"># We do NOT set stop_words here to avoid duplication.</span></span>
<span id="cb43-47"><a href="#cb43-47" aria-hidden="true" tabindex="-1"></a>                                },</span>
<span id="cb43-48"><a href="#cb43-48" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"min_topic_size"</span>: min_topic_size,</span>
<span id="cb43-49"><a href="#cb43-49" aria-hidden="true" tabindex="-1"></a>                            })</span>
<span id="cb43-50"><a href="#cb43-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-51"><a href="#cb43-51" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(param_grid)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="H7XfyA58dS-Q" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameter grid for BERTopic auto-tuning</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="co"># IMPORTANT: use vectorizer-ready text (after boilerplate removal + optional lemmatization)</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> df[<span class="st">"__vectorizer_text__"</span>].tolist()</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>desired_K <span class="op">=</span> <span class="dv">60</span>          <span class="co"># soft target for #topics</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>min_topics_allowed <span class="op">=</span> <span class="dv">6</span>  <span class="co"># skip degenerate runs</span></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> []</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------- UMAP --------------------</span></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n_neighbors <span class="kw">in</span> [<span class="dv">10</span>]:</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> min_dist <span class="kw">in</span> [<span class="fl">0.05</span>]:</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> n_components <span class="kw">in</span> [<span class="dv">10</span>]:</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>            <span class="co"># -------------------- HDBSCAN --------------------</span></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> min_cluster_size <span class="kw">in</span> [<span class="dv">8</span>, <span class="dv">10</span>]:</span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> min_samples <span class="kw">in</span> [<span class="dv">1</span>]:</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># -------------------- BERTopic min topic size --------------------</span></span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">for</span> min_topic_size <span class="kw">in</span> [<span class="dv">5</span>, <span class="dv">8</span>]:</span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># -------------------- Merge tolerance (epsilon) --------------------</span></span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">for</span> eps <span class="kw">in</span> [<span class="fl">0.00</span>, <span class="fl">0.05</span>]:</span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>                            param_grid.append({</span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"umap"</span>: {</span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"n_neighbors"</span>: n_neighbors,</span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"n_components"</span>: n_components,</span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"min_dist"</span>: min_dist,</span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"metric"</span>: <span class="st">"cosine"</span>,</span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"random_state"</span>: SEED,</span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a>                                },</span>
<span id="cb44-33"><a href="#cb44-33" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"hdb"</span>: {</span>
<span id="cb44-34"><a href="#cb44-34" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"min_cluster_size"</span>: min_cluster_size,</span>
<span id="cb44-35"><a href="#cb44-35" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"min_samples"</span>: min_samples,</span>
<span id="cb44-36"><a href="#cb44-36" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"metric"</span>: <span class="st">"euclidean"</span>,</span>
<span id="cb44-37"><a href="#cb44-37" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"cluster_selection_method"</span>: <span class="st">"eom"</span>,</span>
<span id="cb44-38"><a href="#cb44-38" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"cluster_selection_epsilon"</span>: eps,</span>
<span id="cb44-39"><a href="#cb44-39" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"prediction_data"</span>: <span class="va">True</span>,</span>
<span id="cb44-40"><a href="#cb44-40" aria-hidden="true" tabindex="-1"></a>                                },</span>
<span id="cb44-41"><a href="#cb44-41" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"vec"</span>: {</span>
<span id="cb44-42"><a href="#cb44-42" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"ngram_range"</span>: (<span class="dv">1</span>, <span class="dv">2</span>),</span>
<span id="cb44-43"><a href="#cb44-43" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"min_df"</span>: <span class="dv">2</span>,</span>
<span id="cb44-44"><a href="#cb44-44" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">"max_df"</span>: <span class="fl">1.0</span>,</span>
<span id="cb44-45"><a href="#cb44-45" aria-hidden="true" tabindex="-1"></a>                                    <span class="co"># </span><span class="al">NOTE</span><span class="co">: stopwords are passed via build_model(..., stop_words=FINAL_STOPWORDS)</span></span>
<span id="cb44-46"><a href="#cb44-46" aria-hidden="true" tabindex="-1"></a>                                    <span class="co"># We do NOT set stop_words here to avoid duplication.</span></span>
<span id="cb44-47"><a href="#cb44-47" aria-hidden="true" tabindex="-1"></a>                                },</span>
<span id="cb44-48"><a href="#cb44-48" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"min_topic_size"</span>: min_topic_size,</span>
<span id="cb44-49"><a href="#cb44-49" aria-hidden="true" tabindex="-1"></a>                            })</span>
<span id="cb44-50"><a href="#cb44-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-51"><a href="#cb44-51" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(param_grid)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="c-grid-search-scoring" class="level3">
<h3 class="anchored" data-anchor-id="c-grid-search-scoring">3.3c) Grid Search &amp; Scoring</h3>
<div id="rMaC_JaWnJgm" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid Search &amp; Scoring (with Topic ‚àí1 band preference)</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>best <span class="op">=</span> {<span class="st">"score"</span>: <span class="op">-</span><span class="dv">1</span>}</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Topic ‚àí1 target band (noise fraction)</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>target_low, target_high <span class="op">=</span> <span class="fl">0.10</span>, <span class="fl">0.15</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>target_mid <span class="op">=</span> <span class="fl">0.125</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>best_inband <span class="op">=</span> <span class="va">None</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, p <span class="kw">in</span> <span class="bu">enumerate</span>(param_grid, <span class="dv">1</span>):</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"</span><span class="ch">\n</span><span class="ss">[</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(param_grid)<span class="sc">}</span><span class="ss">] "</span></span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"UMAP(n_neighbors=</span><span class="sc">{</span>p[<span class="st">'umap'</span>][<span class="st">'n_neighbors'</span>]<span class="sc">}</span><span class="ss">, min_dist=</span><span class="sc">{</span>p[<span class="st">'umap'</span>][<span class="st">'min_dist'</span>]<span class="sc">}</span><span class="ss">, n_comp=</span><span class="sc">{</span>p[<span class="st">'umap'</span>][<span class="st">'n_components'</span>]<span class="sc">}</span><span class="ss">) | "</span></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"HDB(min_clust=</span><span class="sc">{</span>p[<span class="st">'hdb'</span>][<span class="st">'min_cluster_size'</span>]<span class="sc">}</span><span class="ss">, min_samp=</span><span class="sc">{</span>p[<span class="st">'hdb'</span>][<span class="st">'min_samples'</span>]<span class="sc">}</span><span class="ss">, eps=</span><span class="sc">{</span>p[<span class="st">'hdb'</span>][<span class="st">'cluster_selection_epsilon'</span>]<span class="sc">}</span><span class="ss">) | "</span></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"min_topic_size=</span><span class="sc">{</span>p[<span class="st">'min_topic_size'</span>]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Build model; pass merged stopwords (keeps underscored tokens via helper's token_pattern)</span></span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> build_model(</span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a>        umap_params<span class="op">=</span>p[<span class="st">"umap"</span>],</span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a>        hdb_params<span class="op">=</span>p[<span class="st">"hdb"</span>],</span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>        vectorizer_params<span class="op">=</span>p[<span class="st">"vec"</span>],</span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>        min_topic_size<span class="op">=</span>p[<span class="st">"min_topic_size"</span>],</span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a>        stop_words<span class="op">=</span><span class="bu">list</span>(FINAL_STOPWORDS) <span class="co"># &lt;-- from your earlier boilerplate/stopword cell</span></span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit with precomputed embeddings and vectorizer-ready docs</span></span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a>    topics_try, probs_try <span class="op">=</span> m.fit_transform(docs, embeddings<span class="op">=</span>embeddings)</span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a>    met <span class="op">=</span> evaluate(m, docs, top_n<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-35"><a href="#cb45-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Skip if too few topics</span></span>
<span id="cb45-36"><a href="#cb45-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> met[<span class="st">"n_topics"</span>] <span class="op">&lt;</span> min_topics_allowed:</span>
<span id="cb45-37"><a href="#cb45-37" aria-hidden="true" tabindex="-1"></a>        results.append({<span class="st">"i"</span>: i, <span class="st">"params"</span>: p, <span class="op">**</span>met, <span class="st">"score"</span>: <span class="op">-</span><span class="fl">1.0</span>})</span>
<span id="cb45-38"><a href="#cb45-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb45-39"><a href="#cb45-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-40"><a href="#cb45-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Composite score</span></span>
<span id="cb45-41"><a href="#cb45-41" aria-hidden="true" tabindex="-1"></a>    noise_pen <span class="op">=</span> <span class="bu">max</span>(<span class="fl">0.0</span>, met[<span class="st">"noise_frac"</span>] <span class="op">-</span> <span class="fl">0.30</span>)  <span class="co"># allow up to 30% noise before penalizing</span></span>
<span id="cb45-42"><a href="#cb45-42" aria-hidden="true" tabindex="-1"></a>    target_bonus <span class="op">=</span> <span class="fl">1.0</span> <span class="op">-</span> <span class="bu">min</span>(<span class="fl">1.0</span>, <span class="bu">abs</span>(met[<span class="st">"n_topics"</span>] <span class="op">-</span> desired_K) <span class="op">/</span> <span class="bu">max</span>(<span class="dv">1</span>, desired_K))  <span class="co"># 0..1</span></span>
<span id="cb45-43"><a href="#cb45-43" aria-hidden="true" tabindex="-1"></a>    base_score <span class="op">=</span> (</span>
<span id="cb45-44"><a href="#cb45-44" aria-hidden="true" tabindex="-1"></a>        (<span class="fl">1.0</span> <span class="op">*</span> <span class="bu">max</span>(<span class="dv">0</span>, met[<span class="st">"c_npmi"</span>])) <span class="op">+</span></span>
<span id="cb45-45"><a href="#cb45-45" aria-hidden="true" tabindex="-1"></a>        (<span class="fl">0.7</span> <span class="op">*</span> (met[<span class="st">"diversity"</span>] <span class="op">/</span> <span class="fl">100.0</span>)) <span class="op">-</span></span>
<span id="cb45-46"><a href="#cb45-46" aria-hidden="true" tabindex="-1"></a>        (<span class="fl">0.8</span> <span class="op">*</span> noise_pen) <span class="op">+</span></span>
<span id="cb45-47"><a href="#cb45-47" aria-hidden="true" tabindex="-1"></a>        (<span class="fl">0.5</span> <span class="op">*</span> target_bonus)</span>
<span id="cb45-48"><a href="#cb45-48" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb45-49"><a href="#cb45-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-50"><a href="#cb45-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Soft preference for noise in 10‚Äì15%</span></span>
<span id="cb45-51"><a href="#cb45-51" aria-hidden="true" tabindex="-1"></a>    noise_band_pen <span class="op">=</span> <span class="bu">min</span>(<span class="fl">1.0</span>, <span class="bu">abs</span>(met[<span class="st">"noise_frac"</span>] <span class="op">-</span> target_mid) <span class="op">/</span> target_mid)  <span class="co"># 0..1</span></span>
<span id="cb45-52"><a href="#cb45-52" aria-hidden="true" tabindex="-1"></a>    score <span class="op">=</span> base_score <span class="op">-</span> <span class="fl">0.25</span> <span class="op">*</span> noise_band_pen</span>
<span id="cb45-53"><a href="#cb45-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-54"><a href="#cb45-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Record</span></span>
<span id="cb45-55"><a href="#cb45-55" aria-hidden="true" tabindex="-1"></a>    results.append({<span class="st">"i"</span>: i, <span class="st">"params"</span>: p, <span class="op">**</span>met, <span class="st">"score"</span>: score})</span>
<span id="cb45-56"><a href="#cb45-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-57"><a href="#cb45-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Track best overall</span></span>
<span id="cb45-58"><a href="#cb45-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> score <span class="op">&gt;</span> best[<span class="st">"score"</span>]:</span>
<span id="cb45-59"><a href="#cb45-59" aria-hidden="true" tabindex="-1"></a>        best <span class="op">=</span> {</span>
<span id="cb45-60"><a href="#cb45-60" aria-hidden="true" tabindex="-1"></a>            <span class="st">"score"</span>: score, <span class="st">"model"</span>: m, <span class="st">"topics"</span>: topics_try, <span class="st">"probs"</span>: probs_try,</span>
<span id="cb45-61"><a href="#cb45-61" aria-hidden="true" tabindex="-1"></a>            <span class="st">"params"</span>: p, <span class="st">"metrics"</span>: met</span>
<span id="cb45-62"><a href="#cb45-62" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb45-63"><a href="#cb45-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-64"><a href="#cb45-64" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Track best inside the Topic ‚àí1 band</span></span>
<span id="cb45-65"><a href="#cb45-65" aria-hidden="true" tabindex="-1"></a>    in_band <span class="op">=</span> (target_low <span class="op">&lt;=</span> met[<span class="st">"noise_frac"</span>] <span class="op">&lt;=</span> target_high)</span>
<span id="cb45-66"><a href="#cb45-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> in_band <span class="kw">and</span> (best_inband <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> score <span class="op">&gt;</span> best_inband[<span class="st">"score"</span>]):</span>
<span id="cb45-67"><a href="#cb45-67" aria-hidden="true" tabindex="-1"></a>        best_inband <span class="op">=</span> {</span>
<span id="cb45-68"><a href="#cb45-68" aria-hidden="true" tabindex="-1"></a>            <span class="st">"score"</span>: score, <span class="st">"model"</span>: m, <span class="st">"topics"</span>: topics_try, <span class="st">"probs"</span>: probs_try,</span>
<span id="cb45-69"><a href="#cb45-69" aria-hidden="true" tabindex="-1"></a>            <span class="st">"params"</span>: p, <span class="st">"metrics"</span>: met</span>
<span id="cb45-70"><a href="#cb45-70" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb45-71"><a href="#cb45-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-72"><a href="#cb45-72" aria-hidden="true" tabindex="-1"></a><span class="co"># Prefer in-band result if available</span></span>
<span id="cb45-73"><a href="#cb45-73" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_inband <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb45-74"><a href="#cb45-74" aria-hidden="true" tabindex="-1"></a>    best <span class="op">=</span> best_inband</span>
<span id="cb45-75"><a href="#cb45-75" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">‚úÖ Selected best configuration INSIDE the Topic ‚àí1 target band (10‚Äì15%)."</span>)</span>
<span id="cb45-76"><a href="#cb45-76" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb45-77"><a href="#cb45-77" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">‚ÑπÔ∏è No configuration landed inside the Topic ‚àí1 band; kept best overall by score."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="d-composite-scoring-formula-for-topic-model-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="d-composite-scoring-formula-for-topic-model-evaluation">3.3d) Composite Scoring Formula for Topic Model Evaluation</h3>
<div id="cr-Er4mZ8zcu" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Composite Scoring Formula for Topic Model Evaluation</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The final score used for model selection is a weighted hybrid metric:</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="co">#   score = base_score - 0.25 * noise_band_pen</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="co">#   base_score = (1.0 * coherence)                  # topic semantic coherence (c_npmi)</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="co">#               + (0.7 * (diversity / 100))         # encourages distinct topic vocabularies</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="co">#               - (0.8 * noise_pen)                 # penalizes high proportion of Topic ‚àí1</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="co">#               + (0.5 * target_bonus)              # rewards closeness to desired topic count (K)</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a><span class="co">#   noise_pen = max(0, noise_frac - 0.30)</span></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a><span class="co">#       ‚Üí allows up to 30% unclustered documents before penalizing</span></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a><span class="co">#   target_bonus = 1 - min(1, abs(n_topics - desired_K) / desired_K)</span></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a><span class="co">#       ‚Üí ranges [0,1]; higher when closer to desired topic count</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a><span class="co">#   noise_band_pen = min(1, abs(noise_frac - 0.125) / 0.125)</span></span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a><span class="co">#       ‚Üí softly prefers Topic ‚àí1 fraction near 10‚Äì15% (empirically stable models)</span></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a><span class="co"># üìö References / Rationale:</span></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a><span class="co"># - Lau, J., Newman, D., &amp; Baldwin, T. (2014).</span></span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a><span class="co">#   Machine Reading Tea Leaves: Automatically Evaluating Topic Coherence and Topic Model Quality.</span></span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a><span class="co">#   *EACL 2014.*</span></span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a><span class="co"># - R√∂der, M., Both, A., &amp; Hinneburg, A. (2015).</span></span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a><span class="co">#   Exploring the Space of Topic Coherence Measures.</span></span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a><span class="co">#   *WSDM 2015.* https://doi.org/10.1145/2684822.2685324</span></span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a><span class="co"># - Grootendorst, M. (2022).</span></span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a><span class="co">#   BERTopic: Neural topic modeling with a class-based TF-IDF procedure.</span></span>
<span id="cb46-35"><a href="#cb46-35" aria-hidden="true" tabindex="-1"></a><span class="co">#   *arXiv:2203.05794.*  (esp. discussion of topic diversity &amp; topic ‚àí1 trade-off)</span></span>
<span id="cb46-36"><a href="#cb46-36" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb46-37"><a href="#cb46-37" aria-hidden="true" tabindex="-1"></a><span class="co"># These papers motivate combining coherence, diversity, and noise-control</span></span>
<span id="cb46-38"><a href="#cb46-38" aria-hidden="true" tabindex="-1"></a><span class="co"># to balance interpretability and stability in topic model selection.</span></span>
<span id="cb46-39"><a href="#cb46-39" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="Ld0W722c77iB" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect grid-search results BEFORE leaf refinement</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>total_runs <span class="op">=</span> <span class="bu">len</span>(results)  <span class="co"># or len(param_grid)</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>res_df <span class="op">=</span> (</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>    pd.DataFrame(results)</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>    .sort_values(<span class="st">"score"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"‚úÖ Grid search completed with </span><span class="sc">{</span>total_runs<span class="sc">}</span><span class="ss"> configurations.</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a><span class="co"># unpack a few params for readability</span></span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>res_df[<span class="st">"umap_n_neighbors"</span>] <span class="op">=</span> res_df[<span class="st">"params"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> p: p[<span class="st">"umap"</span>][<span class="st">"n_neighbors"</span>])</span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>res_df[<span class="st">"hdb_min_cluster"</span>]  <span class="op">=</span> res_df[<span class="st">"params"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> p: p[<span class="st">"hdb"</span>][<span class="st">"min_cluster_size"</span>])</span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a>res_df[<span class="st">"hdb_min_samples"</span>]  <span class="op">=</span> res_df[<span class="st">"params"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> p: p[<span class="st">"hdb"</span>][<span class="st">"min_samples"</span>])</span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a>res_df[<span class="st">"hdb_eps"</span>]          <span class="op">=</span> res_df[<span class="st">"params"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> p: p[<span class="st">"hdb"</span>].get(<span class="st">"cluster_selection_epsilon"</span>, <span class="fl">0.0</span>))</span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a><span class="co"># nice run-id</span></span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a>res_df[<span class="st">"run_id"</span>] <span class="op">=</span> res_df[<span class="st">"i"</span>].astype(<span class="bu">str</span>) <span class="op">+</span> <span class="ss">f"/</span><span class="sc">{</span>total_runs<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"üîé Top 10 configurations from grid search (EOM only):"</span>)</span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a>display(</span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a>    res_df[[</span>
<span id="cb47-28"><a href="#cb47-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">"run_id"</span>,</span>
<span id="cb47-29"><a href="#cb47-29" aria-hidden="true" tabindex="-1"></a>        <span class="st">"n_topics"</span>,</span>
<span id="cb47-30"><a href="#cb47-30" aria-hidden="true" tabindex="-1"></a>        <span class="st">"noise_frac"</span>,</span>
<span id="cb47-31"><a href="#cb47-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">"diversity"</span>,</span>
<span id="cb47-32"><a href="#cb47-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">"c_npmi"</span>,</span>
<span id="cb47-33"><a href="#cb47-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">"score"</span>,</span>
<span id="cb47-34"><a href="#cb47-34" aria-hidden="true" tabindex="-1"></a>        <span class="st">"umap_n_neighbors"</span>,</span>
<span id="cb47-35"><a href="#cb47-35" aria-hidden="true" tabindex="-1"></a>        <span class="st">"hdb_min_cluster"</span>,</span>
<span id="cb47-36"><a href="#cb47-36" aria-hidden="true" tabindex="-1"></a>        <span class="st">"hdb_min_samples"</span>,</span>
<span id="cb47-37"><a href="#cb47-37" aria-hidden="true" tabindex="-1"></a>        <span class="st">"hdb_eps"</span>,</span>
<span id="cb47-38"><a href="#cb47-38" aria-hidden="true" tabindex="-1"></a>    ]].head(<span class="dv">10</span>)</span>
<span id="cb47-39"><a href="#cb47-39" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb47-40"><a href="#cb47-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-41"><a href="#cb47-41" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb47-42"><a href="#cb47-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Highlight current best model (EOM)</span></span>
<span id="cb47-43"><a href="#cb47-43" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb47-44"><a href="#cb47-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üèÜ CURRENT BEST MODEL (EOM)"</span>)</span>
<span id="cb47-45"><a href="#cb47-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"</span>)</span>
<span id="cb47-46"><a href="#cb47-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"‚Ä¢ Topics discovered : </span><span class="sc">{</span>best[<span class="st">'metrics'</span>][<span class="st">'n_topics'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb47-47"><a href="#cb47-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"‚Ä¢ Noise fraction    : </span><span class="sc">{</span>best[<span class="st">'metrics'</span>][<span class="st">'noise_frac'</span>]<span class="sc">:.2%}</span><span class="ss">"</span>)</span>
<span id="cb47-48"><a href="#cb47-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"‚Ä¢ Diversity         : </span><span class="sc">{</span>best[<span class="st">'metrics'</span>][<span class="st">'diversity'</span>]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb47-49"><a href="#cb47-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"‚Ä¢ c_npmi (coherence): </span><span class="sc">{</span>best[<span class="st">'metrics'</span>][<span class="st">'c_npmi'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb47-50"><a href="#cb47-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-51"><a href="#cb47-51" aria-hidden="true" tabindex="-1"></a>umap_n       <span class="op">=</span> best[<span class="st">"params"</span>][<span class="st">"umap"</span>][<span class="st">"n_neighbors"</span>]</span>
<span id="cb47-52"><a href="#cb47-52" aria-hidden="true" tabindex="-1"></a>hdb_minclust <span class="op">=</span> best[<span class="st">"params"</span>][<span class="st">"hdb"</span>][<span class="st">"min_cluster_size"</span>]</span>
<span id="cb47-53"><a href="#cb47-53" aria-hidden="true" tabindex="-1"></a>hdb_minsamp  <span class="op">=</span> best[<span class="st">"params"</span>][<span class="st">"hdb"</span>][<span class="st">"min_samples"</span>]</span>
<span id="cb47-54"><a href="#cb47-54" aria-hidden="true" tabindex="-1"></a>hdb_eps      <span class="op">=</span> best[<span class="st">"params"</span>][<span class="st">"hdb"</span>].get(<span class="st">"cluster_selection_epsilon"</span>, <span class="fl">0.0</span>)</span>
<span id="cb47-55"><a href="#cb47-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-56"><a href="#cb47-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"‚Ä¢ Params (UMAP/HDB) : n_neighbors=</span><span class="sc">{</span>umap_n<span class="sc">}</span><span class="ss">, "</span></span>
<span id="cb47-57"><a href="#cb47-57" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f"min_cluster_size=</span><span class="sc">{</span>hdb_minclust<span class="sc">}</span><span class="ss">, min_samples=</span><span class="sc">{</span>hdb_minsamp<span class="sc">}</span><span class="ss">, eps=</span><span class="sc">{</span>hdb_eps<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb47-58"><a href="#cb47-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-59"><a href="#cb47-59" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb47-60"><a href="#cb47-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Should you run leaf-mode refinement?</span></span>
<span id="cb47-61"><a href="#cb47-61" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb47-62"><a href="#cb47-62" aria-hidden="true" tabindex="-1"></a>RUN_LEAF <span class="op">=</span> <span class="va">False</span>  <span class="co"># üëà set to True manually if you want to run 7.4</span></span>
<span id="cb47-63"><a href="#cb47-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-64"><a href="#cb47-64" aria-hidden="true" tabindex="-1"></a>under_topic <span class="op">=</span> best[<span class="st">"metrics"</span>][<span class="st">"n_topics"</span>] <span class="op">&lt;</span> <span class="fl">0.8</span> <span class="op">*</span> desired_K</span>
<span id="cb47-65"><a href="#cb47-65" aria-hidden="true" tabindex="-1"></a>low_noise   <span class="op">=</span> best[<span class="st">"metrics"</span>][<span class="st">"noise_frac"</span>] <span class="op">&lt;</span> <span class="fl">0.20</span></span>
<span id="cb47-66"><a href="#cb47-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-67"><a href="#cb47-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üí° DECISION GUIDANCE"</span>)</span>
<span id="cb47-68"><a href="#cb47-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"</span>)</span>
<span id="cb47-69"><a href="#cb47-69" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> under_topic:</span>
<span id="cb47-70"><a href="#cb47-70" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚öôÔ∏è  Topic count is below 80</span><span class="sc">% o</span><span class="st">f target ‚Üí leaf could help refine more subtopics."</span>)</span>
<span id="cb47-71"><a href="#cb47-71" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb47-72"><a href="#cb47-72" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚úÖ  Topic count is close to your desired K ‚Äî leaf refinement optional."</span>)</span>
<span id="cb47-73"><a href="#cb47-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-74"><a href="#cb47-74" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> low_noise:</span>
<span id="cb47-75"><a href="#cb47-75" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚öôÔ∏è  Noise is modest (&lt;20%) ‚Üí safe to try leaf for finer splits."</span>)</span>
<span id="cb47-76"><a href="#cb47-76" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb47-77"><a href="#cb47-77" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ö†Ô∏è  Noise is slightly above 20% ‚Üí leaf may over-split and add more noise."</span>)</span>
<span id="cb47-78"><a href="#cb47-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-79"><a href="#cb47-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üëâ Set RUN_LEAF = True in the next cell if you decide to run leaf refinement."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="raWg0Oq64XN2" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize how we chose the best model</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure res_df exists (from 7.3b)</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="co"># and best / desired_K exist</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>total_runs <span class="op">=</span> <span class="bu">len</span>(res_df)</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a><span class="co"># (1) Score vs #topics  ‚Üí which topic counts perform better?</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].scatter(res_df[<span class="st">"n_topics"</span>], res_df[<span class="st">"score"</span>], alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].axvline(desired_K, color<span class="op">=</span><span class="st">"red"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>, label<span class="op">=</span><span class="ss">f"target K = </span><span class="sc">{</span>desired_K<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a><span class="co"># highlight chosen best</span></span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a>best_ntop <span class="op">=</span> best[<span class="st">"metrics"</span>][<span class="st">"n_topics"</span>]</span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a>best_score <span class="op">=</span> best[<span class="st">"score"</span>]</span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].scatter([best_ntop], [best_score], color<span class="op">=</span><span class="st">"red"</span>, s<span class="op">=</span><span class="dv">80</span>, marker<span class="op">=</span><span class="st">"x"</span>, label<span class="op">=</span><span class="st">"chosen model"</span>)</span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="st">"# topics"</span>)</span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_ylabel(<span class="st">"composite score"</span>)</span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_title(<span class="st">"Score vs #topics"</span>)</span>
<span id="cb48-26"><a href="#cb48-26" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].legend()</span>
<span id="cb48-27"><a href="#cb48-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-28"><a href="#cb48-28" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb48-29"><a href="#cb48-29" aria-hidden="true" tabindex="-1"></a><span class="co"># (2) Noise vs #topics  ‚Üí we wanted Topic ‚àí1 in a band</span></span>
<span id="cb48-30"><a href="#cb48-30" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------------------------------------</span></span>
<span id="cb48-31"><a href="#cb48-31" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].scatter(res_df[<span class="st">"n_topics"</span>], res_df[<span class="st">"noise_frac"</span>], alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb48-32"><a href="#cb48-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-33"><a href="#cb48-33" aria-hidden="true" tabindex="-1"></a><span class="co"># show preferred noise band (your 0.10‚Äì0.15 / 0.10‚Äì0.20 idea)</span></span>
<span id="cb48-34"><a href="#cb48-34" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].axhspan(<span class="fl">0.10</span>, <span class="fl">0.15</span>, color<span class="op">=</span><span class="st">"green"</span>, alpha<span class="op">=</span><span class="fl">0.12</span>, label<span class="op">=</span><span class="st">"preferred 10‚Äì15%"</span>)</span>
<span id="cb48-35"><a href="#cb48-35" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].axhspan(<span class="fl">0.15</span>, <span class="fl">0.20</span>, color<span class="op">=</span><span class="st">"yellow"</span>, alpha<span class="op">=</span><span class="fl">0.08</span>, label<span class="op">=</span><span class="st">"ok up to 20%"</span>)</span>
<span id="cb48-36"><a href="#cb48-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-37"><a href="#cb48-37" aria-hidden="true" tabindex="-1"></a><span class="co"># highlight chosen best</span></span>
<span id="cb48-38"><a href="#cb48-38" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].scatter([best_ntop], [best[<span class="st">"metrics"</span>][<span class="st">"noise_frac"</span>]], color<span class="op">=</span><span class="st">"red"</span>, s<span class="op">=</span><span class="dv">80</span>, marker<span class="op">=</span><span class="st">"x"</span>)</span>
<span id="cb48-39"><a href="#cb48-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-40"><a href="#cb48-40" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="st">"# topics"</span>)</span>
<span id="cb48-41"><a href="#cb48-41" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_ylabel(<span class="st">"noise fraction (Topic -1)"</span>)</span>
<span id="cb48-42"><a href="#cb48-42" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_title(<span class="st">"Noise vs #topics"</span>)</span>
<span id="cb48-43"><a href="#cb48-43" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].legend()</span>
<span id="cb48-44"><a href="#cb48-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-45"><a href="#cb48-45" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb48-46"><a href="#cb48-46" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="e-optional-leaf-mode-refinement-near-best-eom" class="level3">
<h3 class="anchored" data-anchor-id="e-optional-leaf-mode-refinement-near-best-eom">3.3e) (Optional) Leaf-mode refinement near best EOM</h3>
<div id="1A4_2qhXfXU2" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="co"># (Optional) Leaf-mode refinement near best EOM</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> RUN_LEAF:</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ÑπÔ∏è Skipping leaf refinement (RUN_LEAF=False)."</span>)</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ------------- your existing leaf code -------------</span></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Leaf refinement] Starting from current best (eom)."</span>)</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>    start_noise <span class="op">=</span> best[<span class="st">"metrics"</span>][<span class="st">"noise_frac"</span>]</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>    start_cnpmi <span class="op">=</span> best[<span class="st">"metrics"</span>][<span class="st">"c_npmi"</span>]</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>    start_div   <span class="op">=</span> best[<span class="st">"metrics"</span>][<span class="st">"diversity"</span>]</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>    start_score <span class="op">=</span> best[<span class="st">"score"</span>]</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Acceptance constraints (tune if you like)</span></span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>    MAX_NOISE   <span class="op">=</span> <span class="fl">0.25</span>        <span class="co"># don't accept leaf if Topic -1 &gt; 25%</span></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>    MIN_COH     <span class="op">=</span> <span class="bu">max</span>(<span class="fl">0.0</span>, (start_cnpmi <span class="cf">if</span> start_cnpmi <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="dv">0</span>) <span class="op">-</span> <span class="fl">0.02</span>)   <span class="co"># coherence must be within 0.02</span></span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>    MIN_SCORE   <span class="op">=</span> start_score <span class="op">-</span> <span class="fl">0.05</span>   <span class="co"># allow tiny tolerance</span></span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>    TARGET_LOW, TARGET_HIGH <span class="op">=</span> <span class="fl">0.10</span>, <span class="fl">0.20</span>  <span class="co"># we still prefer to stay in/near the band</span></span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>    base_p   <span class="op">=</span> best[<span class="st">"params"</span>]</span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a>    curr_nn  <span class="op">=</span> base_p[<span class="st">"umap"</span>][<span class="st">"n_neighbors"</span>]</span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a>    curr_mcs <span class="op">=</span> base_p[<span class="st">"hdb"</span>][<span class="st">"min_cluster_size"</span>]</span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>    curr_ms  <span class="op">=</span> base_p[<span class="st">"hdb"</span>][<span class="st">"min_samples"</span>]</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a>    curr_eps <span class="op">=</span> base_p[<span class="st">"hdb"</span>].get(<span class="st">"cluster_selection_epsilon"</span>, <span class="fl">0.0</span>)</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Build a tiny local neighborhood for 'leaf'</span></span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a>    cands <span class="op">=</span> []</span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a>    mcs_opts <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">set</span>([<span class="bu">max</span>(<span class="dv">2</span>, curr_mcs <span class="op">-</span> <span class="dv">2</span>), curr_mcs <span class="op">-</span> <span class="dv">1</span>, curr_mcs, curr_mcs <span class="op">+</span> <span class="dv">1</span>, curr_mcs <span class="op">+</span> <span class="dv">2</span>]))</span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a>    ms_opts  <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">set</span>([<span class="bu">max</span>(<span class="dv">1</span>, curr_ms <span class="op">-</span> <span class="dv">1</span>), curr_ms, curr_ms <span class="op">+</span> <span class="dv">1</span>]))</span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a>    eps_opts <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">set</span>([<span class="fl">0.0</span>, <span class="bu">min</span>(<span class="fl">0.02</span>, <span class="bu">max</span>(<span class="fl">0.0</span>, curr_eps)), <span class="fl">0.05</span>]))  <span class="co"># small merging tolerance</span></span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a>    nn_opts  <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">set</span>([<span class="bu">max</span>(<span class="dv">5</span>, curr_nn <span class="op">-</span> <span class="dv">5</span>), curr_nn, curr_nn <span class="op">+</span> <span class="dv">5</span>])) <span class="co"># small UMAP n_neighbors wiggle</span></span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> mcs <span class="kw">in</span> mcs_opts:</span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> ms <span class="kw">in</span> ms_opts:</span>
<span id="cb49-35"><a href="#cb49-35" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> eps <span class="kw">in</span> eps_opts:</span>
<span id="cb49-36"><a href="#cb49-36" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> nn <span class="kw">in</span> nn_opts:</span>
<span id="cb49-37"><a href="#cb49-37" aria-hidden="true" tabindex="-1"></a>                    p_leaf <span class="op">=</span> {</span>
<span id="cb49-38"><a href="#cb49-38" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"umap"</span>: {<span class="op">**</span>base_p[<span class="st">"umap"</span>], <span class="st">"n_neighbors"</span>: nn},</span>
<span id="cb49-39"><a href="#cb49-39" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"hdb"</span>:  {</span>
<span id="cb49-40"><a href="#cb49-40" aria-hidden="true" tabindex="-1"></a>                            <span class="op">**</span>base_p[<span class="st">"hdb"</span>],</span>
<span id="cb49-41"><a href="#cb49-41" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"cluster_selection_method"</span>: <span class="st">"leaf"</span>,          <span class="co"># switch to leaf</span></span>
<span id="cb49-42"><a href="#cb49-42" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"min_cluster_size"</span>: mcs,</span>
<span id="cb49-43"><a href="#cb49-43" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"min_samples"</span>: ms,</span>
<span id="cb49-44"><a href="#cb49-44" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"cluster_selection_epsilon"</span>: eps,</span>
<span id="cb49-45"><a href="#cb49-45" aria-hidden="true" tabindex="-1"></a>                        },</span>
<span id="cb49-46"><a href="#cb49-46" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"vec"</span>:  base_p[<span class="st">"vec"</span>],</span>
<span id="cb49-47"><a href="#cb49-47" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"min_topic_size"</span>: base_p[<span class="st">"min_topic_size"</span>],</span>
<span id="cb49-48"><a href="#cb49-48" aria-hidden="true" tabindex="-1"></a>                    }</span>
<span id="cb49-49"><a href="#cb49-49" aria-hidden="true" tabindex="-1"></a>                    cands.append(p_leaf)</span>
<span id="cb49-50"><a href="#cb49-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-51"><a href="#cb49-51" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> refit_and_eval(params):</span>
<span id="cb49-52"><a href="#cb49-52" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> build_model(params[<span class="st">"umap"</span>], params[<span class="st">"hdb"</span>], params[<span class="st">"vec"</span>], params[<span class="st">"min_topic_size"</span>])</span>
<span id="cb49-53"><a href="#cb49-53" aria-hidden="true" tabindex="-1"></a>        t_try, pr_try <span class="op">=</span> m.fit_transform(docs, embeddings<span class="op">=</span>embeddings)</span>
<span id="cb49-54"><a href="#cb49-54" aria-hidden="true" tabindex="-1"></a>        met <span class="op">=</span> evaluate(m, docs, top_n<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb49-55"><a href="#cb49-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-56"><a href="#cb49-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># rebuild the same composite score you used (with noise band preference)</span></span>
<span id="cb49-57"><a href="#cb49-57" aria-hidden="true" tabindex="-1"></a>        noise_pen <span class="op">=</span> <span class="bu">max</span>(<span class="fl">0.0</span>, met[<span class="st">"noise_frac"</span>] <span class="op">-</span> <span class="fl">0.30</span>)</span>
<span id="cb49-58"><a href="#cb49-58" aria-hidden="true" tabindex="-1"></a>        target_bonus <span class="op">=</span> <span class="fl">1.0</span> <span class="op">-</span> <span class="bu">min</span>(<span class="fl">1.0</span>, <span class="bu">abs</span>(met[<span class="st">"n_topics"</span>] <span class="op">-</span> desired_K) <span class="op">/</span> <span class="bu">max</span>(<span class="dv">1</span>, desired_K))</span>
<span id="cb49-59"><a href="#cb49-59" aria-hidden="true" tabindex="-1"></a>        base_score <span class="op">=</span> (</span>
<span id="cb49-60"><a href="#cb49-60" aria-hidden="true" tabindex="-1"></a>            (<span class="fl">1.0</span> <span class="op">*</span> <span class="bu">max</span>(<span class="dv">0</span>, met[<span class="st">"c_npmi"</span>]))</span>
<span id="cb49-61"><a href="#cb49-61" aria-hidden="true" tabindex="-1"></a>            <span class="op">+</span> (<span class="fl">0.7</span> <span class="op">*</span> (met[<span class="st">"diversity"</span>] <span class="op">/</span> <span class="fl">100.0</span>))</span>
<span id="cb49-62"><a href="#cb49-62" aria-hidden="true" tabindex="-1"></a>            <span class="op">-</span> (<span class="fl">0.8</span> <span class="op">*</span> noise_pen)</span>
<span id="cb49-63"><a href="#cb49-63" aria-hidden="true" tabindex="-1"></a>            <span class="op">+</span> (<span class="fl">0.5</span> <span class="op">*</span> target_bonus)</span>
<span id="cb49-64"><a href="#cb49-64" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb49-65"><a href="#cb49-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-66"><a href="#cb49-66" aria-hidden="true" tabindex="-1"></a>        target_mid <span class="op">=</span> <span class="fl">0.15</span> <span class="cf">if</span> (TARGET_LOW, TARGET_HIGH) <span class="op">==</span> (<span class="fl">0.10</span>, <span class="fl">0.20</span>) <span class="cf">else</span> (TARGET_LOW <span class="op">+</span> TARGET_HIGH) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb49-67"><a href="#cb49-67" aria-hidden="true" tabindex="-1"></a>        noise_band_pen <span class="op">=</span> <span class="bu">min</span>(<span class="fl">1.0</span>, <span class="bu">abs</span>(met[<span class="st">"noise_frac"</span>] <span class="op">-</span> target_mid) <span class="op">/</span> target_mid)</span>
<span id="cb49-68"><a href="#cb49-68" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> base_score <span class="op">-</span> <span class="fl">0.25</span> <span class="op">*</span> noise_band_pen</span>
<span id="cb49-69"><a href="#cb49-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> m, t_try, pr_try, met, score</span>
<span id="cb49-70"><a href="#cb49-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-71"><a href="#cb49-71" aria-hidden="true" tabindex="-1"></a>    best_leaf <span class="op">=</span> <span class="va">None</span></span>
<span id="cb49-72"><a href="#cb49-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> cands:</span>
<span id="cb49-73"><a href="#cb49-73" aria-hidden="true" tabindex="-1"></a>        m, t_try, pr_try, met, score <span class="op">=</span> refit_and_eval(p)</span>
<span id="cb49-74"><a href="#cb49-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-75"><a href="#cb49-75" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Hard constraints first</span></span>
<span id="cb49-76"><a href="#cb49-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> met[<span class="st">"noise_frac"</span>] <span class="op">&gt;</span> MAX_NOISE:</span>
<span id="cb49-77"><a href="#cb49-77" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb49-78"><a href="#cb49-78" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> met[<span class="st">"c_npmi"</span>] <span class="op">&lt;</span> MIN_COH:</span>
<span id="cb49-79"><a href="#cb49-79" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb49-80"><a href="#cb49-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> score <span class="op">&lt;</span> MIN_SCORE:</span>
<span id="cb49-81"><a href="#cb49-81" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb49-82"><a href="#cb49-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-83"><a href="#cb49-83" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prefer in-band noise if possible</span></span>
<span id="cb49-84"><a href="#cb49-84" aria-hidden="true" tabindex="-1"></a>        in_band <span class="op">=</span> (TARGET_LOW <span class="op">&lt;=</span> met[<span class="st">"noise_frac"</span>] <span class="op">&lt;=</span> TARGET_HIGH)</span>
<span id="cb49-85"><a href="#cb49-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-86"><a href="#cb49-86" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> best_leaf <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb49-87"><a href="#cb49-87" aria-hidden="true" tabindex="-1"></a>            best_leaf <span class="op">=</span> {</span>
<span id="cb49-88"><a href="#cb49-88" aria-hidden="true" tabindex="-1"></a>                <span class="st">"model"</span>: m,</span>
<span id="cb49-89"><a href="#cb49-89" aria-hidden="true" tabindex="-1"></a>                <span class="st">"topics"</span>: t_try,</span>
<span id="cb49-90"><a href="#cb49-90" aria-hidden="true" tabindex="-1"></a>                <span class="st">"probs"</span>: pr_try,</span>
<span id="cb49-91"><a href="#cb49-91" aria-hidden="true" tabindex="-1"></a>                <span class="st">"params"</span>: p,</span>
<span id="cb49-92"><a href="#cb49-92" aria-hidden="true" tabindex="-1"></a>                <span class="st">"metrics"</span>: met,</span>
<span id="cb49-93"><a href="#cb49-93" aria-hidden="true" tabindex="-1"></a>                <span class="st">"score"</span>: score,</span>
<span id="cb49-94"><a href="#cb49-94" aria-hidden="true" tabindex="-1"></a>                <span class="st">"in_band"</span>: in_band,</span>
<span id="cb49-95"><a href="#cb49-95" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb49-96"><a href="#cb49-96" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb49-97"><a href="#cb49-97" aria-hidden="true" tabindex="-1"></a>            <span class="co"># rank: in-band first, then higher score</span></span>
<span id="cb49-98"><a href="#cb49-98" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> (in_band <span class="kw">and</span> <span class="kw">not</span> best_leaf[<span class="st">"in_band"</span>]) <span class="kw">or</span> (</span>
<span id="cb49-99"><a href="#cb49-99" aria-hidden="true" tabindex="-1"></a>                in_band <span class="op">==</span> best_leaf[<span class="st">"in_band"</span>] <span class="kw">and</span> score <span class="op">&gt;</span> best_leaf[<span class="st">"score"</span>]</span>
<span id="cb49-100"><a href="#cb49-100" aria-hidden="true" tabindex="-1"></a>            ):</span>
<span id="cb49-101"><a href="#cb49-101" aria-hidden="true" tabindex="-1"></a>                best_leaf <span class="op">=</span> {</span>
<span id="cb49-102"><a href="#cb49-102" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"model"</span>: m,</span>
<span id="cb49-103"><a href="#cb49-103" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"topics"</span>: t_try,</span>
<span id="cb49-104"><a href="#cb49-104" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"probs"</span>: pr_try,</span>
<span id="cb49-105"><a href="#cb49-105" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"params"</span>: p,</span>
<span id="cb49-106"><a href="#cb49-106" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"metrics"</span>: met,</span>
<span id="cb49-107"><a href="#cb49-107" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"score"</span>: score,</span>
<span id="cb49-108"><a href="#cb49-108" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"in_band"</span>: in_band,</span>
<span id="cb49-109"><a href="#cb49-109" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb49-110"><a href="#cb49-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-111"><a href="#cb49-111" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> best_leaf <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb49-112"><a href="#cb49-112" aria-hidden="true" tabindex="-1"></a>        <span class="co"># adopt only if it's meaningfully competitive</span></span>
<span id="cb49-113"><a href="#cb49-113" aria-hidden="true" tabindex="-1"></a>        topic_model <span class="op">=</span> best_leaf[<span class="st">"model"</span>]</span>
<span id="cb49-114"><a href="#cb49-114" aria-hidden="true" tabindex="-1"></a>        topics      <span class="op">=</span> best_leaf[<span class="st">"topics"</span>]</span>
<span id="cb49-115"><a href="#cb49-115" aria-hidden="true" tabindex="-1"></a>        probs       <span class="op">=</span> best_leaf[<span class="st">"probs"</span>]</span>
<span id="cb49-116"><a href="#cb49-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-117"><a href="#cb49-117" aria-hidden="true" tabindex="-1"></a>        best[<span class="st">"model"</span>]   <span class="op">=</span> topic_model</span>
<span id="cb49-118"><a href="#cb49-118" aria-hidden="true" tabindex="-1"></a>        best[<span class="st">"topics"</span>]  <span class="op">=</span> topics</span>
<span id="cb49-119"><a href="#cb49-119" aria-hidden="true" tabindex="-1"></a>        best[<span class="st">"probs"</span>]   <span class="op">=</span> probs</span>
<span id="cb49-120"><a href="#cb49-120" aria-hidden="true" tabindex="-1"></a>        best[<span class="st">"params"</span>]  <span class="op">=</span> best_leaf[<span class="st">"params"</span>]</span>
<span id="cb49-121"><a href="#cb49-121" aria-hidden="true" tabindex="-1"></a>        best[<span class="st">"metrics"</span>] <span class="op">=</span> best_leaf[<span class="st">"metrics"</span>]</span>
<span id="cb49-122"><a href="#cb49-122" aria-hidden="true" tabindex="-1"></a>        best[<span class="st">"score"</span>]   <span class="op">=</span> best_leaf[<span class="st">"score"</span>]</span>
<span id="cb49-123"><a href="#cb49-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-124"><a href="#cb49-124" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(</span>
<span id="cb49-125"><a href="#cb49-125" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"‚úÖ Adopted 'leaf' refinement. "</span></span>
<span id="cb49-126"><a href="#cb49-126" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Noise: </span><span class="sc">{</span>best[<span class="st">'metrics'</span>][<span class="st">'noise_frac'</span>]<span class="sc">:.2%}</span><span class="ss">, "</span></span>
<span id="cb49-127"><a href="#cb49-127" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"c_npmi: </span><span class="sc">{</span>best[<span class="st">'metrics'</span>][<span class="st">'c_npmi'</span>]<span class="sc">:.3f}</span><span class="ss">, "</span></span>
<span id="cb49-128"><a href="#cb49-128" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"score: </span><span class="sc">{</span>best[<span class="st">'score'</span>]<span class="sc">:.3f}</span><span class="ss">"</span></span>
<span id="cb49-129"><a href="#cb49-129" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb49-130"><a href="#cb49-130" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb49-131"><a href="#cb49-131" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"‚ÑπÔ∏è No 'leaf' candidate met the constraints; kept the 'eom' model."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="-CwPFw_GeQL4" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Adopt the Best Model for Downstream Use</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Select the winning model (either best EOM or refined leaf)</span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>topic_model <span class="op">=</span> best[<span class="st">"model"</span>]</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>topics      <span class="op">=</span> best[<span class="st">"topics"</span>]</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>probs       <span class="op">=</span> best[<span class="st">"probs"</span>]</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚úÖ Adopted best model for downstream analysis."</span>)</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   ‚Üí Topics discovered : </span><span class="sc">{</span>best[<span class="st">'metrics'</span>][<span class="st">'n_topics'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   ‚Üí Noise fraction    : </span><span class="sc">{</span>best[<span class="st">'metrics'</span>][<span class="st">'noise_frac'</span>]<span class="sc">:.2%}</span><span class="ss">"</span>)</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   ‚Üí Coherence (c_npmi): </span><span class="sc">{</span>best[<span class="st">'metrics'</span>][<span class="st">'c_npmi'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="99PVgyFoynzA" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="co"># View Topics from the Adopted Model</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>topic_info <span class="op">=</span> topic_model.get_topic_info()</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üìä Found </span><span class="sc">{</span><span class="bu">len</span>(topic_info) <span class="op">-</span> <span class="dv">1</span><span class="sc">}</span><span class="ss"> topics (excluding noise)."</span>)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   Top 10 topics by size:"</span>)</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>display(topic_info.head(<span class="dv">10</span>))</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect top words for the largest topic (Topic 0)</span></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üîç Top words for Topic 0:"</span>)</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(topic_model.get_topic(<span class="dv">0</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="__-e3qvkzQgK" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Build ALIASES automatically from your CONCEPT_PATTERNS</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set active model for this section</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>active_model <span class="op">=</span> topic_model</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) Build ALIASES from existing CONCEPT_PATTERNS</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>ALIASES <span class="op">=</span> {}</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"CONCEPT_PATTERNS"</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> pat, canon <span class="kw">in</span> CONCEPT_PATTERNS:</span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>        canon_l <span class="op">=</span> canon.lower()</span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># map concatenated and underscored variants -&gt; long form</span></span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>        ALIASES[canon_l.replace(<span class="st">" "</span>, <span class="st">""</span>)] <span class="op">=</span> canon_l                 <span class="co"># e.g., "situationalactiontheory"</span></span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>        ALIASES[canon_l.replace(<span class="st">" "</span>, <span class="st">"_"</span>)] <span class="op">=</span> canon_l                <span class="co"># e.g., "situational_action_theory"</span></span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># extract any acronyms from the regex (e.g., sat, rat, gst...)</span></span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (Simple heuristic to catch 2-8 letter words inside regex boundaries)</span></span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> a <span class="kw">in</span> re.findall(<span class="vs">r"</span><span class="ch">\\</span><span class="vs">b</span><span class="kw">(</span><span class="pp">[a-z]</span><span class="op">{2,8}</span><span class="kw">)</span><span class="ch">\\</span><span class="vs">b"</span>, pat, flags<span class="op">=</span>re.I):</span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a>            ALIASES[a.lower()] <span class="op">=</span> canon_l</span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"‚úÖ Built </span><span class="sc">{</span><span class="bu">len</span>(ALIASES)<span class="sc">}</span><span class="ss"> aliases from CONCEPT_PATTERNS."</span>)</span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ö†Ô∏è CONCEPT_PATTERNS not found in memory. Aliases will be empty."</span>)</span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Minimal topic label cleaner (uses ALIASES, no phrase stitching)</span></span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> normalize_token(tok: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a>    t_raw <span class="op">=</span> (tok <span class="kw">or</span> <span class="st">""</span>).strip()</span>
<span id="cb52-30"><a href="#cb52-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> t_raw:</span>
<span id="cb52-31"><a href="#cb52-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">""</span></span>
<span id="cb52-32"><a href="#cb52-32" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> t_raw.lower()</span>
<span id="cb52-33"><a href="#cb52-33" aria-hidden="true" tabindex="-1"></a>    t_nounder <span class="op">=</span> t.replace(<span class="st">"_"</span>, <span class="st">""</span>)</span>
<span id="cb52-34"><a href="#cb52-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># alias lookup by (1) raw token, (2) no-underscore token</span></span>
<span id="cb52-35"><a href="#cb52-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> t <span class="kw">in</span> ALIASES:</span>
<span id="cb52-36"><a href="#cb52-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ALIASES[t]</span>
<span id="cb52-37"><a href="#cb52-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> t_nounder <span class="kw">in</span> ALIASES:</span>
<span id="cb52-38"><a href="#cb52-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ALIASES[t_nounder]</span>
<span id="cb52-39"><a href="#cb52-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if underscored multiword, make it spaced</span></span>
<span id="cb52-40"><a href="#cb52-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">"_"</span> <span class="kw">in</span> t:</span>
<span id="cb52-41"><a href="#cb52-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> t.replace(<span class="st">"_"</span>, <span class="st">" "</span>)</span>
<span id="cb52-42"><a href="#cb52-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> t</span>
<span id="cb52-43"><a href="#cb52-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-44"><a href="#cb52-44" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_topic_label(words):</span>
<span id="cb52-45"><a href="#cb52-45" aria-hidden="true" tabindex="-1"></a>    seen, out <span class="op">=</span> <span class="bu">set</span>(), []</span>
<span id="cb52-46"><a href="#cb52-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> w <span class="kw">in</span> words:</span>
<span id="cb52-47"><a href="#cb52-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(w, <span class="bu">str</span>) <span class="kw">or</span> <span class="kw">not</span> w.strip():</span>
<span id="cb52-48"><a href="#cb52-48" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb52-49"><a href="#cb52-49" aria-hidden="true" tabindex="-1"></a>        norm <span class="op">=</span> normalize_token(w)</span>
<span id="cb52-50"><a href="#cb52-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> norm <span class="kw">and</span> norm <span class="kw">not</span> <span class="kw">in</span> seen:</span>
<span id="cb52-51"><a href="#cb52-51" aria-hidden="true" tabindex="-1"></a>            seen.add(norm)</span>
<span id="cb52-52"><a href="#cb52-52" aria-hidden="true" tabindex="-1"></a>            out.append(norm)</span>
<span id="cb52-53"><a href="#cb52-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">" / "</span>.join(w.title() <span class="cf">for</span> w <span class="kw">in</span> out)</span>
<span id="cb52-54"><a href="#cb52-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-55"><a href="#cb52-55" aria-hidden="true" tabindex="-1"></a><span class="co"># apply to your active model</span></span>
<span id="cb52-56"><a href="#cb52-56" aria-hidden="true" tabindex="-1"></a>topic_labels <span class="op">=</span> {}</span>
<span id="cb52-57"><a href="#cb52-57" aria-hidden="true" tabindex="-1"></a>ti <span class="op">=</span> active_model.get_topic_info()</span>
<span id="cb52-58"><a href="#cb52-58" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> ti.Topic[ti.Topic <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb52-59"><a href="#cb52-59" aria-hidden="true" tabindex="-1"></a>    top_words <span class="op">=</span> [w <span class="cf">for</span> w, _ <span class="kw">in</span> active_model.get_topic(t)[:<span class="dv">5</span>]]</span>
<span id="cb52-60"><a href="#cb52-60" aria-hidden="true" tabindex="-1"></a>    topic_labels[t] <span class="op">=</span> clean_topic_label(top_words)</span>
<span id="cb52-61"><a href="#cb52-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-62"><a href="#cb52-62" aria-hidden="true" tabindex="-1"></a>active_model.set_topic_labels(topic_labels)</span>
<span id="cb52-63"><a href="#cb52-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"‚úÖ Applied </span><span class="sc">{</span><span class="bu">len</span>(topic_labels)<span class="sc">}</span><span class="ss"> cleaned labels from CONCEPT_PATTERNS."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="TmhRHzLYzxnq" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="co"># View Topics with Cleaned Labels</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>info_clean <span class="op">=</span> active_model.get_topic_info()</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Map the computed labels from the previous step</span></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>info_clean[<span class="st">"Cleaned_Label"</span>] <span class="op">=</span> info_clean[<span class="st">"Topic"</span>].<span class="bu">map</span>(topic_labels)</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Show top 15 topics (excluding noise if preferred, here showing all)</span></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚ú® Topics with cleaned labels:"</span>)</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>display(info_clean[[<span class="st">"Topic"</span>, <span class="st">"Count"</span>, <span class="st">"Cleaned_Label"</span>, <span class="st">"Name"</span>]].head(<span class="dv">15</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="7460e763" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="co"># AI Topic Labeling (OpenAI)</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict, Union, List</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Define the Labeling Function</span></span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> label_topic_openai(topic_id, model, df_docs, text_col<span class="op">=</span><span class="st">"__clean__"</span>):</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Generates a short label and rationale for a topic using OpenAI."""</span></span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> topic_id <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Uncategorized"</span>, <span class="st">"Noise topic containing diverse documents."</span></span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get top keywords</span></span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>    keywords <span class="op">=</span> [w <span class="cf">for</span> w, _ <span class="kw">in</span> model.get_topic(topic_id)[:<span class="dv">10</span>]]</span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get representative documents</span></span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a>    rep_docs <span class="op">=</span> df_docs.loc[df_docs[<span class="st">'topic_id'</span>] <span class="op">==</span> topic_id, text_col].head(<span class="dv">3</span>).tolist()</span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a>    docs_text <span class="op">=</span> <span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>.join([d[:<span class="dv">500</span>] <span class="op">+</span> <span class="st">"..."</span> <span class="cf">for</span> d <span class="kw">in</span> rep_docs]) <span class="co"># Truncate for context window</span></span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f"""</span></span>
<span id="cb54-24"><a href="#cb54-24" aria-hidden="true" tabindex="-1"></a><span class="ss">    You are a domain expert. Label this topic based on its keywords and documents.</span></span>
<span id="cb54-25"><a href="#cb54-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-26"><a href="#cb54-26" aria-hidden="true" tabindex="-1"></a><span class="ss">    Keywords: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(keywords)<span class="sc">}</span></span>
<span id="cb54-27"><a href="#cb54-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-28"><a href="#cb54-28" aria-hidden="true" tabindex="-1"></a><span class="ss">    Documents:</span></span>
<span id="cb54-29"><a href="#cb54-29" aria-hidden="true" tabindex="-1"></a><span class="ss">    </span><span class="sc">{</span>docs_text<span class="sc">}</span></span>
<span id="cb54-30"><a href="#cb54-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-31"><a href="#cb54-31" aria-hidden="true" tabindex="-1"></a><span class="ss">    Return a JSON with:</span></span>
<span id="cb54-32"><a href="#cb54-32" aria-hidden="true" tabindex="-1"></a><span class="ss">    - "label": A short, descriptive topic name (max 5-7 words).</span></span>
<span id="cb54-33"><a href="#cb54-33" aria-hidden="true" tabindex="-1"></a><span class="ss">    - "rationale": A 1-sentence explanation.</span></span>
<span id="cb54-34"><a href="#cb54-34" aria-hidden="true" tabindex="-1"></a><span class="ss">    """</span></span>
<span id="cb54-35"><a href="#cb54-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-36"><a href="#cb54-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb54-37"><a href="#cb54-37" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb54-38"><a href="#cb54-38" aria-hidden="true" tabindex="-1"></a>            model<span class="op">=</span><span class="st">"gpt-4o"</span>,</span>
<span id="cb54-39"><a href="#cb54-39" aria-hidden="true" tabindex="-1"></a>            messages<span class="op">=</span>[{<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: prompt}],</span>
<span id="cb54-40"><a href="#cb54-40" aria-hidden="true" tabindex="-1"></a>            temperature<span class="op">=</span><span class="fl">0.0</span>,</span>
<span id="cb54-41"><a href="#cb54-41" aria-hidden="true" tabindex="-1"></a>            response_format<span class="op">=</span>{<span class="st">"type"</span>: <span class="st">"json_object"</span>}</span>
<span id="cb54-42"><a href="#cb54-42" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb54-43"><a href="#cb54-43" aria-hidden="true" tabindex="-1"></a>        content <span class="op">=</span> json.loads(response.choices[<span class="dv">0</span>].message.content)</span>
<span id="cb54-44"><a href="#cb54-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> content.get(<span class="st">"label"</span>, <span class="ss">f"Topic </span><span class="sc">{</span>topic_id<span class="sc">}</span><span class="ss">"</span>), content.get(<span class="st">"rationale"</span>, <span class="st">""</span>)</span>
<span id="cb54-45"><a href="#cb54-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb54-46"><a href="#cb54-46" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error labeling Topic </span><span class="sc">{</span>topic_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb54-47"><a href="#cb54-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="ss">f"Topic </span><span class="sc">{</span>topic_id<span class="sc">}</span><span class="ss">"</span>, <span class="st">"Error generating label"</span></span>
<span id="cb54-48"><a href="#cb54-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-49"><a href="#cb54-49" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Run Batch Labeling</span></span>
<span id="cb54-50"><a href="#cb54-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ü§ñ Starting AI Labeling..."</span>)</span>
<span id="cb54-51"><a href="#cb54-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-52"><a href="#cb54-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure topic IDs are present in dataframe</span></span>
<span id="cb54-53"><a href="#cb54-53" aria-hidden="true" tabindex="-1"></a>df_topics_run <span class="op">=</span> df.copy()</span>
<span id="cb54-54"><a href="#cb54-54" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"topic_id"</span> <span class="kw">not</span> <span class="kw">in</span> df_topics_run.columns:</span>
<span id="cb54-55"><a href="#cb54-55" aria-hidden="true" tabindex="-1"></a>    df_topics_run[<span class="st">"topic_id"</span>] <span class="op">=</span> topics</span>
<span id="cb54-56"><a href="#cb54-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-57"><a href="#cb54-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Get list of topics (excluding noise)</span></span>
<span id="cb54-58"><a href="#cb54-58" aria-hidden="true" tabindex="-1"></a>topic_info <span class="op">=</span> topic_model.get_topic_info()</span>
<span id="cb54-59"><a href="#cb54-59" aria-hidden="true" tabindex="-1"></a>target_topics <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> topic_info[<span class="st">'Topic'</span>] <span class="cf">if</span> t <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb54-60"><a href="#cb54-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-61"><a href="#cb54-61" aria-hidden="true" tabindex="-1"></a>ai_results <span class="op">=</span> []</span>
<span id="cb54-62"><a href="#cb54-62" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tid <span class="kw">in</span> tqdm(target_topics, desc<span class="op">=</span><span class="st">"Labeling Topics"</span>):</span>
<span id="cb54-63"><a href="#cb54-63" aria-hidden="true" tabindex="-1"></a>    lbl, rat <span class="op">=</span> label_topic_openai(tid, topic_model, df_topics_run)</span>
<span id="cb54-64"><a href="#cb54-64" aria-hidden="true" tabindex="-1"></a>    ai_results.append({<span class="st">"topic_id"</span>: tid, <span class="st">"ai_label"</span>: lbl, <span class="st">"ai_rationale"</span>: rat})</span>
<span id="cb54-65"><a href="#cb54-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-66"><a href="#cb54-66" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Save Results</span></span>
<span id="cb54-67"><a href="#cb54-67" aria-hidden="true" tabindex="-1"></a>labels_df <span class="op">=</span> pd.DataFrame(ai_results)</span>
<span id="cb54-68"><a href="#cb54-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">‚úÖ Labeled </span><span class="sc">{</span><span class="bu">len</span>(labels_df)<span class="sc">}</span><span class="ss"> topics."</span>)</span>
<span id="cb54-69"><a href="#cb54-69" aria-hidden="true" tabindex="-1"></a>display(labels_df.head(<span class="dv">10</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="089f326c" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="co"># View AI-Labeled Topics with Counts</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get base topic info (Counts, etc.)</span></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>info <span class="op">=</span> topic_model.get_topic_info()</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if labels_df exists from the previous step</span></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"labels_df"</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prepare for merge</span></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>    info_view <span class="op">=</span> info.copy()</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>    info_view[<span class="st">"Topic"</span>] <span class="op">=</span> info_view[<span class="st">"Topic"</span>].astype(<span class="bu">int</span>)</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>    labels_df[<span class="st">"topic_id"</span>] <span class="op">=</span> labels_df[<span class="st">"topic_id"</span>].astype(<span class="bu">int</span>)</span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Merge AI labels into the main topic info</span></span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a>    info_view <span class="op">=</span> info_view.merge(labels_df, left_on<span class="op">=</span><span class="st">"Topic"</span>, right_on<span class="op">=</span><span class="st">"topic_id"</span>, how<span class="op">=</span><span class="st">"left"</span>)</span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fill NaNs for Noise (Topic -1) if not labeled</span></span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a>    info_view[<span class="st">"ai_label"</span>] <span class="op">=</span> info_view[<span class="st">"ai_label"</span>].fillna(<span class="st">"Uncategorized / Noise"</span>)</span>
<span id="cb55-20"><a href="#cb55-20" aria-hidden="true" tabindex="-1"></a>    info_view[<span class="st">"ai_rationale"</span>] <span class="op">=</span> info_view[<span class="st">"ai_rationale"</span>].fillna(<span class="st">"-"</span>)</span>
<span id="cb55-21"><a href="#cb55-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-22"><a href="#cb55-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display Top 20 Topics</span></span>
<span id="cb55-23"><a href="#cb55-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ú® Top 20 Topics with AI Labels:"</span>)</span>
<span id="cb55-24"><a href="#cb55-24" aria-hidden="true" tabindex="-1"></a>    display(info_view[[<span class="st">"Topic"</span>, <span class="st">"Count"</span>, <span class="st">"ai_label"</span>, <span class="st">"ai_rationale"</span>]].head(<span class="dv">20</span>))</span>
<span id="cb55-25"><a href="#cb55-25" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb55-26"><a href="#cb55-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ö†Ô∏è 'labels_df' not found. Please run the AI labeling cell above first."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
</section>
</section>
<section id="section-4-topic-interpretation" class="level1">
<h1>Section 4: Topic Interpretation</h1>
<section id="est-tagging" class="level2">
<h2 class="anchored" data-anchor-id="est-tagging">3.1) EST Tagging</h2>
<div id="gXc0V0vYhObT" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 0) Compile EST patterns ‚Üí regex</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _to_regex_list(tokens):</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>    rx <span class="op">=</span> []</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> tokens:</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>        pat <span class="op">=</span> re.escape(t).replace(<span class="st">"</span><span class="ch">\\</span><span class="st">*"</span>, <span class="vs">r"</span><span class="pp">[a-z_]</span><span class="op">*</span><span class="vs">"</span>)  <span class="co"># wildcard support like impulsiv*</span></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>        rx.append(re.<span class="bu">compile</span>(<span class="vs">rf"</span><span class="dv">\b</span><span class="sc">{</span>pat<span class="sc">}</span><span class="dv">\b</span><span class="vs">"</span>, flags<span class="op">=</span>re.IGNORECASE))</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rx</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="st">"EST_PATTERNS"</span> <span class="kw">in</span> <span class="bu">globals</span>(), <span class="st">"Define EST_PATTERNS first."</span></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>EST_REGEX <span class="op">=</span> {k: _to_regex_list(v) <span class="cf">for</span> k, v <span class="kw">in</span> EST_PATTERNS.items()}</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚úÖ EST patterns compiled:"</span>, {k: <span class="bu">len</span>(v) <span class="cf">for</span> k, v <span class="kw">in</span> EST_REGEX.items()})</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="58abbcd8" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Define EST_PATTERNS for Ecological Systems Theory Tagging</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>EST_PATTERNS <span class="op">=</span> {</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Micro"</span>: [</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Individual traits, psychology, biology, risk</span></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"impulsiv*"</span>, <span class="st">"self_control"</span>, <span class="st">"moral*"</span>, <span class="st">"cognit*"</span>, <span class="st">"psycholog*"</span>, <span class="st">"personality"</span>,</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"mental_health"</span>, <span class="st">"mental_illness"</span>, <span class="st">"trauma"</span>, <span class="st">"ptsd"</span>, <span class="st">"tbi"</span>, <span class="st">"brain_injury"</span>,</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"substance_use"</span>, <span class="st">"drug_use"</span>, <span class="st">"alcohol"</span>, <span class="st">"addict*"</span>, <span class="st">"genetic*"</span>, <span class="st">"biologic*"</span>,</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"neuro*"</span>, <span class="st">"individual"</span>, <span class="st">"offender"</span>, <span class="st">"victim*"</span>, <span class="st">"attitude"</span>, <span class="st">"belief"</span>,</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"decision"</span>, <span class="st">"choice"</span>, <span class="st">"routine_activity"</span>, <span class="st">"risk_perception"</span>, <span class="st">"fear_of_crime"</span>,</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"criminal_thinking"</span>, <span class="st">"criminogenic_thinking"</span>, <span class="st">"propensity"</span>, <span class="st">"self_efficacy"</span></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Meso"</span>: [</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Community, institutions, immediate social groups</span></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"family"</span>, <span class="st">"parent*"</span>, <span class="st">"peer*"</span>, <span class="st">"gang"</span>, <span class="st">"school"</span>, <span class="st">"teacher"</span>, <span class="st">"classroom"</span>,</span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"workplace"</span>, <span class="st">"employ*"</span>, <span class="st">"neighbor*"</span>, <span class="st">"neighbour*"</span>, <span class="st">"community"</span>, <span class="st">"local"</span>,</span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">"prison"</span>, <span class="st">"jail"</span>, <span class="st">"correction*"</span>, <span class="st">"probation"</span>, <span class="st">"parole"</span>, <span class="st">"police"</span>, <span class="st">"polic*"</span>,</span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">"court"</span>, <span class="st">"justice_system"</span>, <span class="st">"rehabilitation"</span>, <span class="st">"program"</span>, <span class="st">"treatment"</span>,</span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"service"</span>, <span class="st">"agency"</span>, <span class="st">"organization"</span>, <span class="st">"institution"</span>, <span class="st">"case_management"</span>,</span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"social_network"</span>, <span class="st">"relationship"</span>, <span class="st">"interaction"</span>, <span class="st">"group_home"</span>, <span class="st">"shelter"</span></span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Macro"</span>: [</span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Societal, structural, cultural, policy</span></span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">"policy"</span>, <span class="st">"policies"</span>, <span class="st">"law"</span>, <span class="st">"legal"</span>, <span class="st">"legislat*"</span>, <span class="st">"govern*"</span>, <span class="st">"state"</span>,</span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">"nation*"</span>, <span class="st">"internation*"</span>, <span class="st">"global"</span>, <span class="st">"society"</span>, <span class="st">"societal"</span>, <span class="st">"structur*"</span>,</span>
<span id="cb57-27"><a href="#cb57-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">"econom*"</span>, <span class="st">"inequality"</span>, <span class="st">"poverty"</span>, <span class="st">"disadvantage"</span>, <span class="st">"deprivation"</span>,</span>
<span id="cb57-28"><a href="#cb57-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">"segregation"</span>, <span class="st">"discriminat*"</span>, <span class="st">"racis*"</span>, <span class="st">"culture"</span>, <span class="st">"cultural"</span>, <span class="st">"norm*"</span>,</span>
<span id="cb57-29"><a href="#cb57-29" aria-hidden="true" tabindex="-1"></a>        <span class="st">"capitalis*"</span>, <span class="st">"neoliberal*"</span>, <span class="st">"politic*"</span>, <span class="st">"democracy"</span>, <span class="st">"welfare"</span>,</span>
<span id="cb57-30"><a href="#cb57-30" aria-hidden="true" tabindex="-1"></a>        <span class="st">"migration"</span>, <span class="st">"immigration"</span>, <span class="st">"urban"</span>, <span class="st">"rural"</span>, <span class="st">"environment*"</span>, <span class="st">"geograph*"</span>,</span>
<span id="cb57-31"><a href="#cb57-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">"spatial"</span>, <span class="st">"hot_spot"</span>, <span class="st">"trend"</span>, <span class="st">"rate"</span>, <span class="st">"statistic*"</span>, <span class="st">"epidemiolog*"</span></span>
<span id="cb57-32"><a href="#cb57-32" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb57-33"><a href="#cb57-33" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb57-34"><a href="#cb57-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-35"><a href="#cb57-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚úÖ Defined EST_PATTERNS for Micro, Meso, and Macro layers."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="999cb88d" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 4.1 Run Full EST Tagging Pipeline (Consolidated)</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict, Counter</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Check patterns</span></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"EST_PATTERNS"</span> <span class="kw">not</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"‚ö†Ô∏è EST_PATTERNS not found. Please run the 'Define EST_PATTERNS' cell first."</span>)</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Compile Regex</span></span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚öôÔ∏è Compiling EST regex patterns..."</span>)</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>EST_REGEX <span class="op">=</span> {}</span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> level, tokens <span class="kw">in</span> EST_PATTERNS.items():</span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># escaped patterns, handling * wildcards</span></span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a>    patterns <span class="op">=</span> []</span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> tokens:</span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>        pat <span class="op">=</span> re.escape(t).replace(<span class="st">"</span><span class="ch">\\</span><span class="st">*"</span>, <span class="vs">r"</span><span class="pp">[a-z_]</span><span class="op">*</span><span class="vs">"</span>)</span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>        patterns.append(re.<span class="bu">compile</span>(<span class="vs">rf"</span><span class="dv">\b</span><span class="sc">{</span>pat<span class="sc">}</span><span class="dv">\b</span><span class="vs">"</span>, flags<span class="op">=</span>re.IGNORECASE))</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>    EST_REGEX[level] <span class="op">=</span> patterns</span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Micro: </span><span class="sc">{</span><span class="bu">len</span>(EST_REGEX[<span class="st">'Micro'</span>])<span class="sc">}</span><span class="ss">, Meso: </span><span class="sc">{</span><span class="bu">len</span>(EST_REGEX[<span class="st">'Meso'</span>])<span class="sc">}</span><span class="ss">, Macro: </span><span class="sc">{</span><span class="bu">len</span>(EST_REGEX[<span class="st">'Macro'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Tagging Function</span></span>
<span id="cb58-25"><a href="#cb58-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_est_tags(text):</span>
<span id="cb58-26"><a href="#cb58-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(text, <span class="bu">str</span>) <span class="kw">or</span> <span class="kw">not</span> text:</span>
<span id="cb58-27"><a href="#cb58-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Unclassified"</span>, {}</span>
<span id="cb58-28"><a href="#cb58-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-29"><a href="#cb58-29" aria-hidden="true" tabindex="-1"></a>    hits <span class="op">=</span> Counter()</span>
<span id="cb58-30"><a href="#cb58-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> level, regex_list <span class="kw">in</span> EST_REGEX.items():</span>
<span id="cb58-31"><a href="#cb58-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> rx <span class="kw">in</span> regex_list:</span>
<span id="cb58-32"><a href="#cb58-32" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> rx.search(text):</span>
<span id="cb58-33"><a href="#cb58-33" aria-hidden="true" tabindex="-1"></a>                hits[level] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb58-34"><a href="#cb58-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-35"><a href="#cb58-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> hits:</span>
<span id="cb58-36"><a href="#cb58-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Unclassified"</span>, <span class="bu">dict</span>(hits)</span>
<span id="cb58-37"><a href="#cb58-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-38"><a href="#cb58-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Determine Primary: Max hits, tie-break Macro &gt; Meso &gt; Micro</span></span>
<span id="cb58-39"><a href="#cb58-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sort keys by (-count, priority_index)</span></span>
<span id="cb58-40"><a href="#cb58-40" aria-hidden="true" tabindex="-1"></a>    priority <span class="op">=</span> [<span class="st">"Macro"</span>, <span class="st">"Meso"</span>, <span class="st">"Micro"</span>]</span>
<span id="cb58-41"><a href="#cb58-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-42"><a href="#cb58-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># helper to get sort key</span></span>
<span id="cb58-43"><a href="#cb58-43" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> sort_key(k):</span>
<span id="cb58-44"><a href="#cb58-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (<span class="op">-</span>hits[k], priority.index(k) <span class="cf">if</span> k <span class="kw">in</span> priority <span class="cf">else</span> <span class="dv">99</span>)</span>
<span id="cb58-45"><a href="#cb58-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-46"><a href="#cb58-46" aria-hidden="true" tabindex="-1"></a>    primary <span class="op">=</span> <span class="bu">sorted</span>(hits.keys(), key<span class="op">=</span>sort_key)[<span class="dv">0</span>]</span>
<span id="cb58-47"><a href="#cb58-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> primary, <span class="bu">dict</span>(hits)</span>
<span id="cb58-48"><a href="#cb58-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-49"><a href="#cb58-49" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Apply to Docs</span></span>
<span id="cb58-50"><a href="#cb58-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"üöÄ Tagging documents..."</span>)</span>
<span id="cb58-51"><a href="#cb58-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Use vectorizer text for best matching (lemmatized/underscored) or clean text</span></span>
<span id="cb58-52"><a href="#cb58-52" aria-hidden="true" tabindex="-1"></a>text_col <span class="op">=</span> <span class="st">"__vectorizer_text__"</span> <span class="cf">if</span> <span class="st">"__vectorizer_text__"</span> <span class="kw">in</span> df.columns <span class="cf">else</span> <span class="st">"__clean__"</span></span>
<span id="cb58-53"><a href="#cb58-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Using column: </span><span class="sc">{</span>text_col<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb58-54"><a href="#cb58-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-55"><a href="#cb58-55" aria-hidden="true" tabindex="-1"></a>est_results <span class="op">=</span> df[text_col].<span class="bu">apply</span>(get_est_tags)</span>
<span id="cb58-56"><a href="#cb58-56" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"EST_Primary"</span>] <span class="op">=</span> [x[<span class="dv">0</span>] <span class="cf">for</span> x <span class="kw">in</span> est_results]</span>
<span id="cb58-57"><a href="#cb58-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-58"><a href="#cb58-58" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Aggregate to Topics</span></span>
<span id="cb58-59"><a href="#cb58-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"üìä Aggregating to Topics..."</span>)</span>
<span id="cb58-60"><a href="#cb58-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure we have topic_id</span></span>
<span id="cb58-61"><a href="#cb58-61" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"topic_id"</span> <span class="kw">not</span> <span class="kw">in</span> df.columns:</span>
<span id="cb58-62"><a href="#cb58-62" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">"topic_id"</span>] <span class="op">=</span> topics</span>
<span id="cb58-63"><a href="#cb58-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-64"><a href="#cb58-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Create pivot table of counts</span></span>
<span id="cb58-65"><a href="#cb58-65" aria-hidden="true" tabindex="-1"></a>topic_est <span class="op">=</span> df[df[<span class="st">"topic_id"</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>].groupby(<span class="st">"topic_id"</span>)[<span class="st">"EST_Primary"</span>].value_counts().unstack(fill_value<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb58-66"><a href="#cb58-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-67"><a href="#cb58-67" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure all columns exist</span></span>
<span id="cb58-68"><a href="#cb58-68" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> [<span class="st">"Macro"</span>, <span class="st">"Meso"</span>, <span class="st">"Micro"</span>, <span class="st">"Unclassified"</span>]:</span>
<span id="cb58-69"><a href="#cb58-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> col <span class="kw">not</span> <span class="kw">in</span> topic_est.columns:</span>
<span id="cb58-70"><a href="#cb58-70" aria-hidden="true" tabindex="-1"></a>        topic_est[col] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb58-71"><a href="#cb58-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-72"><a href="#cb58-72" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate Total Docs per topic</span></span>
<span id="cb58-73"><a href="#cb58-73" aria-hidden="true" tabindex="-1"></a>topic_est[<span class="st">"Total_Docs"</span>] <span class="op">=</span> topic_est[[<span class="st">"Macro"</span>, <span class="st">"Meso"</span>, <span class="st">"Micro"</span>, <span class="st">"Unclassified"</span>]].<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb58-74"><a href="#cb58-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-75"><a href="#cb58-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate dominant EST and share</span></span>
<span id="cb58-76"><a href="#cb58-76" aria-hidden="true" tabindex="-1"></a>dominant_est <span class="op">=</span> []</span>
<span id="cb58-77"><a href="#cb58-77" aria-hidden="true" tabindex="-1"></a>est_shares <span class="op">=</span> []</span>
<span id="cb58-78"><a href="#cb58-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-79"><a href="#cb58-79" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tid <span class="kw">in</span> topic_est.index:</span>
<span id="cb58-80"><a href="#cb58-80" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> topic_est.loc[tid]</span>
<span id="cb58-81"><a href="#cb58-81" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> row[<span class="st">"Total_Docs"</span>]</span>
<span id="cb58-82"><a href="#cb58-82" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> total <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb58-83"><a href="#cb58-83" aria-hidden="true" tabindex="-1"></a>        dominant_est.append(<span class="st">"Unclassified"</span>)</span>
<span id="cb58-84"><a href="#cb58-84" aria-hidden="true" tabindex="-1"></a>        est_shares.append(<span class="fl">0.0</span>)</span>
<span id="cb58-85"><a href="#cb58-85" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb58-86"><a href="#cb58-86" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Exclude Total_Docs from max finding</span></span>
<span id="cb58-87"><a href="#cb58-87" aria-hidden="true" tabindex="-1"></a>        counts <span class="op">=</span> row[[<span class="st">"Macro"</span>, <span class="st">"Meso"</span>, <span class="st">"Micro"</span>, <span class="st">"Unclassified"</span>]]</span>
<span id="cb58-88"><a href="#cb58-88" aria-hidden="true" tabindex="-1"></a>        dom <span class="op">=</span> counts.idxmax()</span>
<span id="cb58-89"><a href="#cb58-89" aria-hidden="true" tabindex="-1"></a>        dominant_est.append(dom)</span>
<span id="cb58-90"><a href="#cb58-90" aria-hidden="true" tabindex="-1"></a>        est_shares.append(counts[dom] <span class="op">/</span> total)</span>
<span id="cb58-91"><a href="#cb58-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-92"><a href="#cb58-92" aria-hidden="true" tabindex="-1"></a>topic_est_summary <span class="op">=</span> pd.DataFrame({</span>
<span id="cb58-93"><a href="#cb58-93" aria-hidden="true" tabindex="-1"></a>    <span class="st">"topic_id"</span>: topic_est.index,</span>
<span id="cb58-94"><a href="#cb58-94" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Regex_EST_Primary"</span>: dominant_est,</span>
<span id="cb58-95"><a href="#cb58-95" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Regex_EST_Share"</span>: est_shares,</span>
<span id="cb58-96"><a href="#cb58-96" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Total_Docs"</span>: topic_est[<span class="st">"Total_Docs"</span>].values,</span>
<span id="cb58-97"><a href="#cb58-97" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Count_Macro"</span>: topic_est[<span class="st">"Macro"</span>].values,</span>
<span id="cb58-98"><a href="#cb58-98" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Count_Meso"</span>: topic_est[<span class="st">"Meso"</span>].values,</span>
<span id="cb58-99"><a href="#cb58-99" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Count_Micro"</span>: topic_est[<span class="st">"Micro"</span>].values,</span>
<span id="cb58-100"><a href="#cb58-100" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Count_Unclassified"</span>: topic_est[<span class="st">"Unclassified"</span>].values</span>
<span id="cb58-101"><a href="#cb58-101" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb58-102"><a href="#cb58-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-103"><a href="#cb58-103" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Merge with existing info</span></span>
<span id="cb58-104"><a href="#cb58-104" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge into a master summary if possible, or display separately</span></span>
<span id="cb58-105"><a href="#cb58-105" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"labels_df"</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb58-106"><a href="#cb58-106" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compare with AI</span></span>
<span id="cb58-107"><a href="#cb58-107" aria-hidden="true" tabindex="-1"></a>    comparison <span class="op">=</span> labels_df.merge(topic_est_summary, on<span class="op">=</span><span class="st">"topic_id"</span>, how<span class="op">=</span><span class="st">"left"</span>)</span>
<span id="cb58-108"><a href="#cb58-108" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üîé Topic EST Classification (AI vs Regex):"</span>)</span>
<span id="cb58-109"><a href="#cb58-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-110"><a href="#cb58-110" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define columns to show</span></span>
<span id="cb58-111"><a href="#cb58-111" aria-hidden="true" tabindex="-1"></a>    cols <span class="op">=</span> [<span class="st">"topic_id"</span>, <span class="st">"ai_label"</span>, <span class="st">"Total_Docs"</span>, <span class="st">"Regex_EST_Primary"</span>, <span class="st">"Regex_EST_Share"</span>,</span>
<span id="cb58-112"><a href="#cb58-112" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Count_Macro"</span>, <span class="st">"Count_Meso"</span>, <span class="st">"Count_Micro"</span>]</span>
<span id="cb58-113"><a href="#cb58-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-114"><a href="#cb58-114" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">"ai_ecolayer"</span> <span class="kw">in</span> comparison.columns:</span>
<span id="cb58-115"><a href="#cb58-115" aria-hidden="true" tabindex="-1"></a>        cols.insert(<span class="dv">2</span>, <span class="st">"ai_ecolayer"</span>)</span>
<span id="cb58-116"><a href="#cb58-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-117"><a href="#cb58-117" aria-hidden="true" tabindex="-1"></a>    display(comparison[cols].head(<span class="dv">15</span>))</span>
<span id="cb58-118"><a href="#cb58-118" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb58-119"><a href="#cb58-119" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üîé Topic EST Classification (Regex):"</span>)</span>
<span id="cb58-120"><a href="#cb58-120" aria-hidden="true" tabindex="-1"></a>    cols <span class="op">=</span> [<span class="st">"topic_id"</span>, <span class="st">"Total_Docs"</span>, <span class="st">"Regex_EST_Primary"</span>, <span class="st">"Regex_EST_Share"</span>,</span>
<span id="cb58-121"><a href="#cb58-121" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Count_Macro"</span>, <span class="st">"Count_Meso"</span>, <span class="st">"Count_Micro"</span>]</span>
<span id="cb58-122"><a href="#cb58-122" aria-hidden="true" tabindex="-1"></a>    display(topic_est_summary[cols].head(<span class="dv">15</span>))</span>
<span id="cb58-123"><a href="#cb58-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-124"><a href="#cb58-124" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">‚úÖ EST Tagging Complete. 'EST_Primary' column added to df."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="ai-topic-interpretation" class="level2">
<h2 class="anchored" data-anchor-id="ai-topic-interpretation">3.2) AI Topic Interpretation</h2>
<div id="v2XWEnstjxA7" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="co"># GPT Labeller (dual): Topic Name + Ecological Layer (Macro/Meso/Micro)</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="co">#   - Robust to topic_labels being dict / list / Series / DataFrame</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict, List, Union</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json, re</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bertopic <span class="im">import</span> BERTopic</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a>ECO_DEFS <span class="op">=</span> {</span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Macro"</span>: <span class="st">"Societal/structural systems: policy, economy, migration, inequality, spatial structure, law, governance."</span>,</span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Meso"</span>:  <span class="st">"Community/institutional/organizational: neighbourhoods, schools, prisons, policing, programs, services."</span>,</span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Micro"</span>: <span class="st">"Individual/interpersonal: psychology, cognition, trauma, risk, peers, family, identities."</span></span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-17"><a href="#cb59-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _guess_ecolayer_from_terms(terms: List[<span class="bu">str</span>]) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb59-18"><a href="#cb59-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fallback heuristics if API unavailable</span></span>
<span id="cb59-19"><a href="#cb59-19" aria-hidden="true" tabindex="-1"></a>    MACRO_HINTS <span class="op">=</span> {<span class="st">"policy"</span>,<span class="st">"policies"</span>,<span class="st">"law"</span>,<span class="st">"laws"</span>,<span class="st">"governance"</span>,<span class="st">"country"</span>,<span class="st">"national"</span>,<span class="st">"macro"</span>,</span>
<span id="cb59-20"><a href="#cb59-20" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"immigration"</span>,<span class="st">"welfare"</span>,<span class="st">"econom"</span>,<span class="st">"poverty"</span>,<span class="st">"segregation"</span>,<span class="st">"inequality"</span>,</span>
<span id="cb59-21"><a href="#cb59-21" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"neighbourhood"</span>,<span class="st">"neighborhood"</span>,<span class="st">"spatial"</span>,<span class="st">"city"</span>,<span class="st">"urban"</span>,<span class="st">"place"</span>,<span class="st">"street"</span>,<span class="st">"security"</span>}</span>
<span id="cb59-22"><a href="#cb59-22" aria-hidden="true" tabindex="-1"></a>    MESO_HINTS  <span class="op">=</span> {<span class="st">"institution"</span>,<span class="st">"school"</span>,<span class="st">"education"</span>,<span class="st">"classroom"</span>,<span class="st">"prison"</span>,<span class="st">"correction"</span>,<span class="st">"program"</span>,</span>
<span id="cb59-23"><a href="#cb59-23" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"rehabilitation"</span>,<span class="st">"treatment"</span>,<span class="st">"policing"</span>,<span class="st">"agency"</span>,<span class="st">"organization"</span>,<span class="st">"organisational"</span>,</span>
<span id="cb59-24"><a href="#cb59-24" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"neighbourhood"</span>,<span class="st">"neighborhood"</span>,<span class="st">"community"</span>,<span class="st">"service"</span>,<span class="st">"case management"</span>}</span>
<span id="cb59-25"><a href="#cb59-25" aria-hidden="true" tabindex="-1"></a>    MICRO_HINTS <span class="op">=</span> {<span class="st">"cognition"</span>,<span class="st">"cognitive"</span>,<span class="st">"decision"</span>,<span class="st">"impuls"</span>,<span class="st">"moral"</span>,<span class="st">"trauma"</span>,<span class="st">"ptsd"</span>,<span class="st">"tbi"</span>,<span class="st">"mental"</span>,</span>
<span id="cb59-26"><a href="#cb59-26" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"peer"</span>,<span class="st">"family"</span>,<span class="st">"identity"</span>,<span class="st">"label"</span>,<span class="st">"addiction"</span>,<span class="st">"substance"</span>,<span class="st">"offender"</span>,<span class="st">"individual"</span>,<span class="st">"attitude"</span>}</span>
<span id="cb59-27"><a href="#cb59-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-28"><a href="#cb59-28" aria-hidden="true" tabindex="-1"></a>    tset <span class="op">=</span> {t.lower() <span class="cf">for</span> t <span class="kw">in</span> terms}</span>
<span id="cb59-29"><a href="#cb59-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> score(hints): <span class="cf">return</span> <span class="bu">sum</span>(<span class="bu">any</span>(h <span class="kw">in</span> tok <span class="cf">for</span> h <span class="kw">in</span> hints) <span class="cf">for</span> tok <span class="kw">in</span> tset)</span>
<span id="cb59-30"><a href="#cb59-30" aria-hidden="true" tabindex="-1"></a>    s_macro, s_meso, s_micro <span class="op">=</span> score(MACRO_HINTS), score(MESO_HINTS), score(MICRO_HINTS)</span>
<span id="cb59-31"><a href="#cb59-31" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> <span class="bu">max</span>(s_macro, s_meso, s_micro)</span>
<span id="cb59-32"><a href="#cb59-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> m <span class="op">==</span> <span class="dv">0</span>: <span class="cf">return</span> <span class="st">"Macro"</span>  <span class="co"># conservative default</span></span>
<span id="cb59-33"><a href="#cb59-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [<span class="st">"Macro"</span>,<span class="st">"Meso"</span>,<span class="st">"Micro"</span>][[s_macro, s_meso, s_micro].index(m)]</span>
<span id="cb59-34"><a href="#cb59-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-35"><a href="#cb59-35" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _coerce_labels_map(topic_labels: Union[<span class="va">None</span>, Dict[<span class="bu">int</span>,<span class="bu">str</span>], List[<span class="bu">str</span>], pd.Series, pd.DataFrame], model: BERTopic) <span class="op">-&gt;</span> Dict[<span class="bu">int</span>, <span class="bu">str</span>]:</span>
<span id="cb59-36"><a href="#cb59-36" aria-hidden="true" tabindex="-1"></a>    info <span class="op">=</span> model.get_topic_info()</span>
<span id="cb59-37"><a href="#cb59-37" aria-hidden="true" tabindex="-1"></a>    base <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(info[<span class="st">"Topic"</span>].astype(<span class="bu">int</span>), info[<span class="st">"Name"</span>].astype(<span class="bu">str</span>)))</span>
<span id="cb59-38"><a href="#cb59-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-39"><a href="#cb59-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> topic_labels <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb59-40"><a href="#cb59-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> base</span>
<span id="cb59-41"><a href="#cb59-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(topic_labels, <span class="bu">dict</span>):</span>
<span id="cb59-42"><a href="#cb59-42" aria-hidden="true" tabindex="-1"></a>        base.update({<span class="bu">int</span>(k): <span class="bu">str</span>(v) <span class="cf">for</span> k, v <span class="kw">in</span> topic_labels.items()})</span>
<span id="cb59-43"><a href="#cb59-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> base</span>
<span id="cb59-44"><a href="#cb59-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(topic_labels, (<span class="bu">list</span>, pd.Series, np.ndarray)):</span>
<span id="cb59-45"><a href="#cb59-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># enumerate fallback</span></span>
<span id="cb59-46"><a href="#cb59-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(topic_labels):</span>
<span id="cb59-47"><a href="#cb59-47" aria-hidden="true" tabindex="-1"></a>            base[<span class="bu">int</span>(i)] <span class="op">=</span> <span class="bu">str</span>(v)</span>
<span id="cb59-48"><a href="#cb59-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> base</span>
<span id="cb59-49"><a href="#cb59-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> base</span>
<span id="cb59-50"><a href="#cb59-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-51"><a href="#cb59-51" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gpt_label_topic_dual(</span>
<span id="cb59-52"><a href="#cb59-52" aria-hidden="true" tabindex="-1"></a>    topic_id: <span class="bu">int</span>,</span>
<span id="cb59-53"><a href="#cb59-53" aria-hidden="true" tabindex="-1"></a>    model: BERTopic,</span>
<span id="cb59-54"><a href="#cb59-54" aria-hidden="true" tabindex="-1"></a>    df_with_topics: pd.DataFrame,</span>
<span id="cb59-55"><a href="#cb59-55" aria-hidden="true" tabindex="-1"></a>    text_col: <span class="bu">str</span> <span class="op">=</span> <span class="st">"__clean__"</span>,</span>
<span id="cb59-56"><a href="#cb59-56" aria-hidden="true" tabindex="-1"></a>    k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb59-57"><a href="#cb59-57" aria-hidden="true" tabindex="-1"></a>    n_docs: <span class="bu">int</span> <span class="op">=</span> <span class="dv">3</span>,</span>
<span id="cb59-58"><a href="#cb59-58" aria-hidden="true" tabindex="-1"></a>    topic_labels: Union[<span class="va">None</span>, Dict[<span class="bu">int</span>,<span class="bu">str</span>], List[<span class="bu">str</span>], pd.Series, pd.DataFrame] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb59-59"><a href="#cb59-59" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, <span class="bu">str</span>]:</span>
<span id="cb59-60"><a href="#cb59-60" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1) Noise topic</span></span>
<span id="cb59-61"><a href="#cb59-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> topic_id <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb59-62"><a href="#cb59-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb59-63"><a href="#cb59-63" aria-hidden="true" tabindex="-1"></a>            <span class="st">"ai_label"</span>: <span class="st">"Uncategorized"</span>,</span>
<span id="cb59-64"><a href="#cb59-64" aria-hidden="true" tabindex="-1"></a>            <span class="st">"ai_ecolayer"</span>: <span class="st">"Macro"</span>,</span>
<span id="cb59-65"><a href="#cb59-65" aria-hidden="true" tabindex="-1"></a>            <span class="st">"ai_rationale"</span>: <span class="st">"Topic ‚àí1 contains documents that the model could not cluster confidently."</span></span>
<span id="cb59-66"><a href="#cb59-66" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb59-67"><a href="#cb59-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-68"><a href="#cb59-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2) Top-k terms</span></span>
<span id="cb59-69"><a href="#cb59-69" aria-hidden="true" tabindex="-1"></a>    topic_terms <span class="op">=</span> model.get_topic(topic_id) <span class="kw">or</span> []</span>
<span id="cb59-70"><a href="#cb59-70" aria-hidden="true" tabindex="-1"></a>    terms <span class="op">=</span> [w <span class="cf">for</span> w, _ <span class="kw">in</span> topic_terms[:k]]</span>
<span id="cb59-71"><a href="#cb59-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-72"><a href="#cb59-72" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3) Representative docs</span></span>
<span id="cb59-73"><a href="#cb59-73" aria-hidden="true" tabindex="-1"></a>    topic_docs <span class="op">=</span> (</span>
<span id="cb59-74"><a href="#cb59-74" aria-hidden="true" tabindex="-1"></a>        df_with_topics.loc[df_with_topics[<span class="st">"topic_id"</span>] <span class="op">==</span> topic_id, text_col]</span>
<span id="cb59-75"><a href="#cb59-75" aria-hidden="true" tabindex="-1"></a>        .dropna().astype(<span class="bu">str</span>).tolist()</span>
<span id="cb59-76"><a href="#cb59-76" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb59-77"><a href="#cb59-77" aria-hidden="true" tabindex="-1"></a>    sample_texts <span class="op">=</span> topic_docs[:n_docs]</span>
<span id="cb59-78"><a href="#cb59-78" aria-hidden="true" tabindex="-1"></a>    docs_joined <span class="op">=</span> <span class="st">"</span><span class="ch">\n\n</span><span class="st">---</span><span class="ch">\n\n</span><span class="st">"</span>.join(sample_texts)</span>
<span id="cb59-79"><a href="#cb59-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-80"><a href="#cb59-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4) Cleaned label hint</span></span>
<span id="cb59-81"><a href="#cb59-81" aria-hidden="true" tabindex="-1"></a>    labels_map <span class="op">=</span> _coerce_labels_map(topic_labels, model)</span>
<span id="cb59-82"><a href="#cb59-82" aria-hidden="true" tabindex="-1"></a>    clean_hint <span class="op">=</span> labels_map.get(<span class="bu">int</span>(topic_id), <span class="st">""</span>)</span>
<span id="cb59-83"><a href="#cb59-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-84"><a href="#cb59-84" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5) JSON-only prompt</span></span>
<span id="cb59-85"><a href="#cb59-85" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f"""</span></span>
<span id="cb59-86"><a href="#cb59-86" aria-hidden="true" tabindex="-1"></a><span class="ss">You are a criminology expert labelling topics from a BERTopic model of academic articles.</span></span>
<span id="cb59-87"><a href="#cb59-87" aria-hidden="true" tabindex="-1"></a><span class="ss">The corpus spans crime, criminology, policing, social policy, justice, and AI.</span></span>
<span id="cb59-88"><a href="#cb59-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-89"><a href="#cb59-89" aria-hidden="true" tabindex="-1"></a><span class="ss">You will receive:</span></span>
<span id="cb59-90"><a href="#cb59-90" aria-hidden="true" tabindex="-1"></a><span class="ss">- Top keywords (c-TF-IDF) for a topic</span></span>
<span id="cb59-91"><a href="#cb59-91" aria-hidden="true" tabindex="-1"></a><span class="ss">- A few representative article excerpts (cleaned title+abstract)</span></span>
<span id="cb59-92"><a href="#cb59-92" aria-hidden="true" tabindex="-1"></a><span class="ss">- An optional existing cleaned label (hint)</span></span>
<span id="cb59-93"><a href="#cb59-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-94"><a href="#cb59-94" aria-hidden="true" tabindex="-1"></a><span class="ss">TASK:</span></span>
<span id="cb59-95"><a href="#cb59-95" aria-hidden="true" tabindex="-1"></a><span class="ss">1) Propose ONE concise, specific, human-readable label for this topic (max 7 words).</span></span>
<span id="cb59-96"><a href="#cb59-96" aria-hidden="true" tabindex="-1"></a><span class="ss">2) Assign ONE ecological layer from this set exactly: ["Macro","Meso","Micro"].</span></span>
<span id="cb59-97"><a href="#cb59-97" aria-hidden="true" tabindex="-1"></a><span class="ss">   - Macro = </span><span class="sc">{</span>ECO_DEFS[<span class="st">"Macro"</span>]<span class="sc">}</span></span>
<span id="cb59-98"><a href="#cb59-98" aria-hidden="true" tabindex="-1"></a><span class="ss">   - Meso  = </span><span class="sc">{</span>ECO_DEFS[<span class="st">"Meso"</span>]<span class="sc">}</span></span>
<span id="cb59-99"><a href="#cb59-99" aria-hidden="true" tabindex="-1"></a><span class="ss">   - Micro = </span><span class="sc">{</span>ECO_DEFS[<span class="st">"Micro"</span>]<span class="sc">}</span></span>
<span id="cb59-100"><a href="#cb59-100" aria-hidden="true" tabindex="-1"></a><span class="ss">3) Provide 1‚Äì2 sentences justifying the label and ecological choice using the terms and excerpts.</span></span>
<span id="cb59-101"><a href="#cb59-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-102"><a href="#cb59-102" aria-hidden="true" tabindex="-1"></a><span class="ss">REPLY STRICTLY AS MINIFIED JSON with keys:</span></span>
<span id="cb59-103"><a href="#cb59-103" aria-hidden="true" tabindex="-1"></a><span class="ch">{{</span></span>
<span id="cb59-104"><a href="#cb59-104" aria-hidden="true" tabindex="-1"></a><span class="ss">  "ai_label": "...",</span></span>
<span id="cb59-105"><a href="#cb59-105" aria-hidden="true" tabindex="-1"></a><span class="ss">  "ai_ecolayer": "Macro|Meso|Micro",</span></span>
<span id="cb59-106"><a href="#cb59-106" aria-hidden="true" tabindex="-1"></a><span class="ss">  "ai_rationale": "..."</span></span>
<span id="cb59-107"><a href="#cb59-107" aria-hidden="true" tabindex="-1"></a><span class="ch">}}</span></span>
<span id="cb59-108"><a href="#cb59-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-109"><a href="#cb59-109" aria-hidden="true" tabindex="-1"></a><span class="ss">ExistingCleanLabelHint: "</span><span class="sc">{</span>clean_hint<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb59-110"><a href="#cb59-110" aria-hidden="true" tabindex="-1"></a><span class="ss">TopTerms: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(terms)<span class="sc">}</span></span>
<span id="cb59-111"><a href="#cb59-111" aria-hidden="true" tabindex="-1"></a><span class="ss">RepresentativeDocs:</span></span>
<span id="cb59-112"><a href="#cb59-112" aria-hidden="true" tabindex="-1"></a><span class="sc">{</span>docs_joined<span class="sc">}</span></span>
<span id="cb59-113"><a href="#cb59-113" aria-hidden="true" tabindex="-1"></a><span class="ss">"""</span>.strip()</span>
<span id="cb59-114"><a href="#cb59-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-115"><a href="#cb59-115" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 6) Call GPT (using 'client' from setup)</span></span>
<span id="cb59-116"><a href="#cb59-116" aria-hidden="true" tabindex="-1"></a>    ai_label, ai_ecolayer, ai_rationale <span class="op">=</span> <span class="va">None</span>, <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb59-117"><a href="#cb59-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-118"><a href="#cb59-118" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check for 'client' (standard) or 'openai_client' (legacy)</span></span>
<span id="cb59-119"><a href="#cb59-119" aria-hidden="true" tabindex="-1"></a>    active_client <span class="op">=</span> <span class="va">None</span></span>
<span id="cb59-120"><a href="#cb59-120" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">"client"</span> <span class="kw">in</span> <span class="bu">globals</span>() <span class="kw">and</span> client <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb59-121"><a href="#cb59-121" aria-hidden="true" tabindex="-1"></a>        active_client <span class="op">=</span> client</span>
<span id="cb59-122"><a href="#cb59-122" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">"openai_client"</span> <span class="kw">in</span> <span class="bu">globals</span>() <span class="kw">and</span> openai_client <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb59-123"><a href="#cb59-123" aria-hidden="true" tabindex="-1"></a>        active_client <span class="op">=</span> openai_client</span>
<span id="cb59-124"><a href="#cb59-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-125"><a href="#cb59-125" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> active_client:</span>
<span id="cb59-126"><a href="#cb59-126" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb59-127"><a href="#cb59-127" aria-hidden="true" tabindex="-1"></a>            resp <span class="op">=</span> active_client.chat.completions.create(</span>
<span id="cb59-128"><a href="#cb59-128" aria-hidden="true" tabindex="-1"></a>                model<span class="op">=</span><span class="st">"gpt-4o"</span>,</span>
<span id="cb59-129"><a href="#cb59-129" aria-hidden="true" tabindex="-1"></a>                messages<span class="op">=</span>[{<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: prompt}],</span>
<span id="cb59-130"><a href="#cb59-130" aria-hidden="true" tabindex="-1"></a>                temperature<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb59-131"><a href="#cb59-131" aria-hidden="true" tabindex="-1"></a>                response_format<span class="op">=</span>{<span class="st">"type"</span>: <span class="st">"json_object"</span>},</span>
<span id="cb59-132"><a href="#cb59-132" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb59-133"><a href="#cb59-133" aria-hidden="true" tabindex="-1"></a>            txt <span class="op">=</span> resp.choices[<span class="dv">0</span>].message.content.strip()</span>
<span id="cb59-134"><a href="#cb59-134" aria-hidden="true" tabindex="-1"></a>            obj <span class="op">=</span> json.loads(txt)</span>
<span id="cb59-135"><a href="#cb59-135" aria-hidden="true" tabindex="-1"></a>            ai_label     <span class="op">=</span> (obj.get(<span class="st">"ai_label"</span>) <span class="kw">or</span> <span class="st">""</span>).strip()</span>
<span id="cb59-136"><a href="#cb59-136" aria-hidden="true" tabindex="-1"></a>            ai_ecolayer  <span class="op">=</span> (obj.get(<span class="st">"ai_ecolayer"</span>) <span class="kw">or</span> <span class="st">""</span>).strip().title()</span>
<span id="cb59-137"><a href="#cb59-137" aria-hidden="true" tabindex="-1"></a>            ai_rationale <span class="op">=</span> (obj.get(<span class="st">"ai_rationale"</span>) <span class="kw">or</span> <span class="st">""</span>).strip()</span>
<span id="cb59-138"><a href="#cb59-138" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb59-139"><a href="#cb59-139" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"[warn] OpenAI error on topic </span><span class="sc">{</span>topic_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb59-140"><a href="#cb59-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-141"><a href="#cb59-141" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 7) Fallbacks</span></span>
<span id="cb59-142"><a href="#cb59-142" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ai_label:</span>
<span id="cb59-143"><a href="#cb59-143" aria-hidden="true" tabindex="-1"></a>        ai_label <span class="op">=</span> <span class="st">" / "</span>.join(terms[:<span class="dv">3</span>]).title() <span class="cf">if</span> terms <span class="cf">else</span> <span class="ss">f"Topic </span><span class="sc">{</span>topic_id<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb59-144"><a href="#cb59-144" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ai_ecolayer <span class="kw">not</span> <span class="kw">in</span> {<span class="st">"Macro"</span>,<span class="st">"Meso"</span>,<span class="st">"Micro"</span>}:</span>
<span id="cb59-145"><a href="#cb59-145" aria-hidden="true" tabindex="-1"></a>        ai_ecolayer <span class="op">=</span> _guess_ecolayer_from_terms(terms)</span>
<span id="cb59-146"><a href="#cb59-146" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ai_rationale:</span>
<span id="cb59-147"><a href="#cb59-147" aria-hidden="true" tabindex="-1"></a>        ai_rationale <span class="op">=</span> (</span>
<span id="cb59-148"><a href="#cb59-148" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Heuristic: labelled from top terms (</span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(terms[:k])<span class="sc">}</span><span class="ss">); "</span></span>
<span id="cb59-149"><a href="#cb59-149" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"ecolayer guessed as </span><span class="sc">{</span>ai_ecolayer<span class="sc">}</span><span class="ss"> based on keyword cues."</span></span>
<span id="cb59-150"><a href="#cb59-150" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb59-151"><a href="#cb59-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-152"><a href="#cb59-152" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb59-153"><a href="#cb59-153" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ai_label"</span>: ai_label,</span>
<span id="cb59-154"><a href="#cb59-154" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ai_ecolayer"</span>: ai_ecolayer,</span>
<span id="cb59-155"><a href="#cb59-155" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ai_rationale"</span>: ai_rationale</span>
<span id="cb59-156"><a href="#cb59-156" aria-hidden="true" tabindex="-1"></a>    }</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="generate-labels-for-all-non-noise-topics" class="level2">
<h2 class="anchored" data-anchor-id="generate-labels-for-all-non-noise-topics">3.3) Generate Labels for All Non-Noise Topics</h2>
<div id="_ii8MYMCjh_w" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Batch: label all real topics (excl. -1) with AI Name + Eco Layer</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ‚öôÔ∏è Fix: Use 'active_model' directly since 'best' variable is corrupted (is a string)</span></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>topic_model   <span class="op">=</span> active_model</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>df_topics_all <span class="op">=</span> df.copy()</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Attach current topic assignments if missing</span></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"topic_id"</span> <span class="kw">not</span> <span class="kw">in</span> df_topics_all.columns:</span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Using 'topics' variable from the Adoption step</span></span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>    df_topics_all[<span class="st">"topic_id"</span>] <span class="op">=</span> pd.Series(topics, index<span class="op">=</span>df.index)</span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Topic set (exclude -1)</span></span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a>info <span class="op">=</span> topic_model.get_topic_info()</span>
<span id="cb60-18"><a href="#cb60-18" aria-hidden="true" tabindex="-1"></a>topic_ids <span class="op">=</span> [<span class="bu">int</span>(tid) <span class="cf">for</span> tid <span class="kw">in</span> info.Topic <span class="cf">if</span> <span class="bu">int</span>(tid) <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb60-19"><a href="#cb60-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-20"><a href="#cb60-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Optional cleaned-label hints: pass whatever you have (dict/list/Series/DataFrame/None)</span></span>
<span id="cb60-21"><a href="#cb60-21" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb60-22"><a href="#cb60-22" aria-hidden="true" tabindex="-1"></a>    _labels_hint <span class="op">=</span> topic_labels  <span class="co"># may be dict or list ‚Äî helper will coerce</span></span>
<span id="cb60-23"><a href="#cb60-23" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">NameError</span>:</span>
<span id="cb60-24"><a href="#cb60-24" aria-hidden="true" tabindex="-1"></a>    _labels_hint <span class="op">=</span> <span class="va">None</span></span>
<span id="cb60-25"><a href="#cb60-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-26"><a href="#cb60-26" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> []</span>
<span id="cb60-27"><a href="#cb60-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tid <span class="kw">in</span> tqdm(topic_ids, desc<span class="op">=</span><span class="st">"AI labelling (Name + Ecological Layer)"</span>):</span>
<span id="cb60-28"><a href="#cb60-28" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> gpt_label_topic_dual(</span>
<span id="cb60-29"><a href="#cb60-29" aria-hidden="true" tabindex="-1"></a>        topic_id<span class="op">=</span>tid,</span>
<span id="cb60-30"><a href="#cb60-30" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>topic_model,</span>
<span id="cb60-31"><a href="#cb60-31" aria-hidden="true" tabindex="-1"></a>        df_with_topics<span class="op">=</span>df_topics_all,</span>
<span id="cb60-32"><a href="#cb60-32" aria-hidden="true" tabindex="-1"></a>        text_col<span class="op">=</span><span class="st">"__clean__"</span>,     <span class="co"># cleaned combined text</span></span>
<span id="cb60-33"><a href="#cb60-33" aria-hidden="true" tabindex="-1"></a>        k<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb60-34"><a href="#cb60-34" aria-hidden="true" tabindex="-1"></a>        n_docs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb60-35"><a href="#cb60-35" aria-hidden="true" tabindex="-1"></a>        topic_labels<span class="op">=</span>_labels_hint <span class="co"># can be dict/list/Series/DF/None</span></span>
<span id="cb60-36"><a href="#cb60-36" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb60-37"><a href="#cb60-37" aria-hidden="true" tabindex="-1"></a>    rows.append({</span>
<span id="cb60-38"><a href="#cb60-38" aria-hidden="true" tabindex="-1"></a>        <span class="st">"topic_id"</span>: tid,</span>
<span id="cb60-39"><a href="#cb60-39" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ai_label"</span>: out[<span class="st">"ai_label"</span>],</span>
<span id="cb60-40"><a href="#cb60-40" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ai_ecolayer"</span>: out[<span class="st">"ai_ecolayer"</span>],</span>
<span id="cb60-41"><a href="#cb60-41" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ai_rationale"</span>: out[<span class="st">"ai_rationale"</span>],</span>
<span id="cb60-42"><a href="#cb60-42" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb60-43"><a href="#cb60-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-44"><a href="#cb60-44" aria-hidden="true" tabindex="-1"></a>labels_df <span class="op">=</span> (</span>
<span id="cb60-45"><a href="#cb60-45" aria-hidden="true" tabindex="-1"></a>    pd.DataFrame(rows)</span>
<span id="cb60-46"><a href="#cb60-46" aria-hidden="true" tabindex="-1"></a>      .sort_values(<span class="st">"topic_id"</span>)</span>
<span id="cb60-47"><a href="#cb60-47" aria-hidden="true" tabindex="-1"></a>      .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb60-48"><a href="#cb60-48" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb60-49"><a href="#cb60-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-50"><a href="#cb60-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"‚úÖ Labeled </span><span class="sc">{</span><span class="bu">len</span>(labels_df)<span class="sc">}</span><span class="ss"> topics."</span>)</span>
<span id="cb60-51"><a href="#cb60-51" aria-hidden="true" tabindex="-1"></a>display(labels_df.head(<span class="dv">15</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="save-as-final-excel" class="level2">
<h2 class="anchored" data-anchor-id="save-as-final-excel">3.4) Save as Final Excel</h2>
<div id="ud153USxhlbB" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install xlsxwriter if not already installed</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install xlsxwriter</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="Ninvk29rffAB" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Export Comprehensive Results to Excel</span></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="co">#   ‚Ä¢ Sheet "Topics": ID, Count, Keywords, AI Label, AI Rationale, EST Layer</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   ‚Ä¢ Sheet "Docs":   Article ID, Title, Assigned Topic, EST Tag, Probability</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Prepare Topics DataFrame</span></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"üìä Preparing Topics Sheet..."</span>)</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>topics_df <span class="op">=</span> topic_model.get_topic_info().copy()</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge AI Labels if available</span></span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"labels_df"</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># labels_df has [topic_id, ai_label, ai_rationale, ai_ecolayer]</span></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>    topics_df <span class="op">=</span> topics_df.merge(labels_df, left_on<span class="op">=</span><span class="st">"Topic"</span>, right_on<span class="op">=</span><span class="st">"topic_id"</span>, how<span class="op">=</span><span class="st">"left"</span>)</span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>    topics_df.drop(columns<span class="op">=</span>[<span class="st">"topic_id"</span>], inplace<span class="op">=</span><span class="va">True</span>, errors<span class="op">=</span><span class="st">"ignore"</span>)</span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge EST Tags (from topic_est_summary) if available</span></span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"topic_est_summary"</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a>    topics_df <span class="op">=</span> topics_df.merge(</span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a>        topic_est_summary[[<span class="st">"topic_id"</span>, <span class="st">"Regex_EST_Primary"</span>, <span class="st">"Regex_EST_Share"</span>]],</span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a>        left_on<span class="op">=</span><span class="st">"Topic"</span>,</span>
<span id="cb62-23"><a href="#cb62-23" aria-hidden="true" tabindex="-1"></a>        right_on<span class="op">=</span><span class="st">"topic_id"</span>,</span>
<span id="cb62-24"><a href="#cb62-24" aria-hidden="true" tabindex="-1"></a>        how<span class="op">=</span><span class="st">"left"</span></span>
<span id="cb62-25"><a href="#cb62-25" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb62-26"><a href="#cb62-26" aria-hidden="true" tabindex="-1"></a>    topics_df.drop(columns<span class="op">=</span>[<span class="st">"topic_id"</span>], inplace<span class="op">=</span><span class="va">True</span>, errors<span class="op">=</span><span class="st">"ignore"</span>)</span>
<span id="cb62-27"><a href="#cb62-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-28"><a href="#cb62-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Clean up column names</span></span>
<span id="cb62-29"><a href="#cb62-29" aria-hidden="true" tabindex="-1"></a>topics_df.rename(columns<span class="op">=</span>{</span>
<span id="cb62-30"><a href="#cb62-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Topic"</span>: <span class="st">"Topic_ID"</span>,</span>
<span id="cb62-31"><a href="#cb62-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Count"</span>: <span class="st">"Doc_Count"</span>,</span>
<span id="cb62-32"><a href="#cb62-32" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Name"</span>: <span class="st">"Original_Name"</span>,</span>
<span id="cb62-33"><a href="#cb62-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ai_label"</span>: <span class="st">"AI_Label"</span>,</span>
<span id="cb62-34"><a href="#cb62-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ai_rationale"</span>: <span class="st">"AI_Rationale"</span>,</span>
<span id="cb62-35"><a href="#cb62-35" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ai_ecolayer"</span>: <span class="st">"AI_Eco_Layer"</span>,</span>
<span id="cb62-36"><a href="#cb62-36" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Regex_EST_Primary"</span>: <span class="st">"EST_Tag_Primary"</span>,</span>
<span id="cb62-37"><a href="#cb62-37" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Regex_EST_Share"</span>: <span class="st">"EST_Tag_Share"</span></span>
<span id="cb62-38"><a href="#cb62-38" aria-hidden="true" tabindex="-1"></a>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb62-39"><a href="#cb62-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-40"><a href="#cb62-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Reorder columns for readability</span></span>
<span id="cb62-41"><a href="#cb62-41" aria-hidden="true" tabindex="-1"></a>kb_cols <span class="op">=</span> [<span class="st">"Topic_ID"</span>, <span class="st">"Doc_Count"</span>, <span class="st">"AI_Label"</span>, <span class="st">"EST_Tag_Primary"</span>, <span class="st">"AI_Rationale"</span>, <span class="st">"Original_Name"</span>]</span>
<span id="cb62-42"><a href="#cb62-42" aria-hidden="true" tabindex="-1"></a>avail_cols <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> kb_cols <span class="cf">if</span> c <span class="kw">in</span> topics_df.columns] <span class="op">+</span> [c <span class="cf">for</span> c <span class="kw">in</span> topics_df.columns <span class="cf">if</span> c <span class="kw">not</span> <span class="kw">in</span> kb_cols]</span>
<span id="cb62-43"><a href="#cb62-43" aria-hidden="true" tabindex="-1"></a>topics_df <span class="op">=</span> topics_df[avail_cols]</span>
<span id="cb62-44"><a href="#cb62-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-45"><a href="#cb62-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-46"><a href="#cb62-46" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Prepare Documents DataFrame</span></span>
<span id="cb62-47"><a href="#cb62-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"üìÑ Preparing Documents Sheet..."</span>)</span>
<span id="cb62-48"><a href="#cb62-48" aria-hidden="true" tabindex="-1"></a>docs_export <span class="op">=</span> df.copy()</span>
<span id="cb62-49"><a href="#cb62-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-50"><a href="#cb62-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure Topic ID is attached</span></span>
<span id="cb62-51"><a href="#cb62-51" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"topic_id"</span> <span class="kw">not</span> <span class="kw">in</span> docs_export.columns:</span>
<span id="cb62-52"><a href="#cb62-52" aria-hidden="true" tabindex="-1"></a>    docs_export[<span class="st">"topic_id"</span>] <span class="op">=</span> topics</span>
<span id="cb62-53"><a href="#cb62-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-54"><a href="#cb62-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Add Topic Name/Label map</span></span>
<span id="cb62-55"><a href="#cb62-55" aria-hidden="true" tabindex="-1"></a>topic_label_map <span class="op">=</span> topics_df.set_index(<span class="st">"Topic_ID"</span>)[<span class="st">"AI_Label"</span>].to_dict() <span class="cf">if</span> <span class="st">"AI_Label"</span> <span class="kw">in</span> topics_df.columns <span class="cf">else</span> {}</span>
<span id="cb62-56"><a href="#cb62-56" aria-hidden="true" tabindex="-1"></a>docs_export[<span class="st">"Topic_Label"</span>] <span class="op">=</span> docs_export[<span class="st">"topic_id"</span>].<span class="bu">map</span>(topic_label_map).fillna(<span class="st">"Uncategorized"</span>)</span>
<span id="cb62-57"><a href="#cb62-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-58"><a href="#cb62-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Select useful columns</span></span>
<span id="cb62-59"><a href="#cb62-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust these column names based on your actual csv structure</span></span>
<span id="cb62-60"><a href="#cb62-60" aria-hidden="true" tabindex="-1"></a>candidates <span class="op">=</span> [<span class="st">"id"</span>, <span class="st">"unique_id"</span>, <span class="st">"title"</span>, <span class="st">"abstract"</span>, <span class="st">"year"</span>, <span class="st">"topic_id"</span>, <span class="st">"Topic_Label"</span>, <span class="st">"topic_prob"</span>, <span class="st">"EST_Primary"</span>, <span class="st">"__clean__"</span>]</span>
<span id="cb62-61"><a href="#cb62-61" aria-hidden="true" tabindex="-1"></a>final_cols <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> candidates <span class="cf">if</span> c <span class="kw">in</span> docs_export.columns]</span>
<span id="cb62-62"><a href="#cb62-62" aria-hidden="true" tabindex="-1"></a>docs_export <span class="op">=</span> docs_export[final_cols]</span>
<span id="cb62-63"><a href="#cb62-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-64"><a href="#cb62-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-65"><a href="#cb62-65" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Write to Excel</span></span>
<span id="cb62-66"><a href="#cb62-66" aria-hidden="true" tabindex="-1"></a>out_path <span class="op">=</span> <span class="st">"bertopic_results_comprehensive.xlsx"</span></span>
<span id="cb62-67"><a href="#cb62-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üíæ Saving to </span><span class="sc">{</span>out_path<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb62-68"><a href="#cb62-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-69"><a href="#cb62-69" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pd.ExcelWriter(out_path, engine<span class="op">=</span><span class="st">"xlsxwriter"</span>) <span class="im">as</span> writer:</span>
<span id="cb62-70"><a href="#cb62-70" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Write sheets</span></span>
<span id="cb62-71"><a href="#cb62-71" aria-hidden="true" tabindex="-1"></a>    topics_df.to_excel(writer, sheet_name<span class="op">=</span><span class="st">"Topics"</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb62-72"><a href="#cb62-72" aria-hidden="true" tabindex="-1"></a>    docs_export.to_excel(writer, sheet_name<span class="op">=</span><span class="st">"Docs"</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb62-73"><a href="#cb62-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-74"><a href="#cb62-74" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Auto-adjust column widths</span></span>
<span id="cb62-75"><a href="#cb62-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> sheetname, dframe <span class="kw">in</span> {<span class="st">"Topics"</span>: topics_df, <span class="st">"Docs"</span>: docs_export}.items():</span>
<span id="cb62-76"><a href="#cb62-76" aria-hidden="true" tabindex="-1"></a>        worksheet <span class="op">=</span> writer.sheets[sheetname]</span>
<span id="cb62-77"><a href="#cb62-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> idx, col <span class="kw">in</span> <span class="bu">enumerate</span>(dframe.columns):</span>
<span id="cb62-78"><a href="#cb62-78" aria-hidden="true" tabindex="-1"></a>            max_len <span class="op">=</span> <span class="bu">min</span>(<span class="dv">50</span>, <span class="bu">max</span>(<span class="dv">10</span>, dframe[col].astype(<span class="bu">str</span>).<span class="bu">map</span>(<span class="bu">len</span>).<span class="bu">max</span>()))</span>
<span id="cb62-79"><a href="#cb62-79" aria-hidden="true" tabindex="-1"></a>            worksheet.set_column(idx, idx, max_len)</span>
<span id="cb62-80"><a href="#cb62-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-81"><a href="#cb62-81" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"‚úÖ Export complete!"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
</section>
<section id="section-14-semantic-search" class="level1">
<h1>Section 14: Semantic Search</h1>
<p>Use the embedding model (SPECTER2) to find articles that are semantically similar to your query. This goes beyond keyword matching and finds conceptual matches.</p>
<p><strong>How it works:</strong> 1. We embed your query using the same transformer model used for the articles. 2. We calculate the cosine similarity between your query vector and all article vectors. 3. We return the top matching results.</p>
<div id="50bb30c9" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 14.1 Semantic Search Tool</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure model/tokenizer are loaded (from Section 2)</span></span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"model"</span> <span class="kw">not</span> <span class="kw">in</span> <span class="bu">globals</span>() <span class="kw">or</span> <span class="st">"tokenizer"</span> <span class="kw">not</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ö†Ô∏è Model/Tokenizer not found. Reloading SPECTER2..."</span>)</span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, AutoModel</span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>    MODEL_NAME <span class="op">=</span> <span class="st">"allenai/specter2_aug2023refresh_base"</span></span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a>    tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(MODEL_NAME)</span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> AutoModel.from_pretrained(MODEL_NAME).to(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> search_articles(query, top_k<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Finds articles semantically similar to the query string."""</span></span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> model.device</span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Embed the query</span></span>
<span id="cb63-23"><a href="#cb63-23" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> tokenizer(</span>
<span id="cb63-24"><a href="#cb63-24" aria-hidden="true" tabindex="-1"></a>        [query],</span>
<span id="cb63-25"><a href="#cb63-25" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb63-26"><a href="#cb63-26" aria-hidden="true" tabindex="-1"></a>        truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb63-27"><a href="#cb63-27" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span><span class="dv">512</span>,</span>
<span id="cb63-28"><a href="#cb63-28" aria-hidden="true" tabindex="-1"></a>        return_tensors<span class="op">=</span><span class="st">"pt"</span></span>
<span id="cb63-29"><a href="#cb63-29" aria-hidden="true" tabindex="-1"></a>    ).to(device)</span>
<span id="cb63-30"><a href="#cb63-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-31"><a href="#cb63-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb63-32"><a href="#cb63-32" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="cb63-33"><a href="#cb63-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mean pooling</span></span>
<span id="cb63-34"><a href="#cb63-34" aria-hidden="true" tabindex="-1"></a>        last_hidden <span class="op">=</span> output.last_hidden_state</span>
<span id="cb63-35"><a href="#cb63-35" aria-hidden="true" tabindex="-1"></a>        attention <span class="op">=</span> inputs[<span class="st">"attention_mask"</span>].unsqueeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb63-36"><a href="#cb63-36" aria-hidden="true" tabindex="-1"></a>        embedding <span class="op">=</span> (last_hidden <span class="op">*</span> attention).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>) <span class="op">/</span> attention.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb63-37"><a href="#cb63-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalize</span></span>
<span id="cb63-38"><a href="#cb63-38" aria-hidden="true" tabindex="-1"></a>        embedding <span class="op">=</span> embedding.cpu().numpy()</span>
<span id="cb63-39"><a href="#cb63-39" aria-hidden="true" tabindex="-1"></a>        embedding <span class="op">=</span> embedding <span class="op">/</span> np.linalg.norm(embedding, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb63-40"><a href="#cb63-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-41"><a href="#cb63-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Calculate Similarity</span></span>
<span id="cb63-42"><a href="#cb63-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 'embeddings' is the global matrix from Section 2</span></span>
<span id="cb63-43"><a href="#cb63-43" aria-hidden="true" tabindex="-1"></a>    sims <span class="op">=</span> cosine_similarity(embedding, embeddings).flatten()</span>
<span id="cb63-44"><a href="#cb63-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-45"><a href="#cb63-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Retrieve Top K</span></span>
<span id="cb63-46"><a href="#cb63-46" aria-hidden="true" tabindex="-1"></a>    top_indices <span class="op">=</span> sims.argsort()[::<span class="op">-</span><span class="dv">1</span>][:top_k]</span>
<span id="cb63-47"><a href="#cb63-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-48"><a href="#cb63-48" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb63-49"><a href="#cb63-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> top_indices:</span>
<span id="cb63-50"><a href="#cb63-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use df_topics_all if available for rich info, else df</span></span>
<span id="cb63-51"><a href="#cb63-51" aria-hidden="true" tabindex="-1"></a>        source_df <span class="op">=</span> df_topics_all <span class="cf">if</span> <span class="st">"df_topics_all"</span> <span class="kw">in</span> <span class="bu">globals</span>() <span class="cf">else</span> df</span>
<span id="cb63-52"><a href="#cb63-52" aria-hidden="true" tabindex="-1"></a>        row <span class="op">=</span> source_df.iloc[idx]</span>
<span id="cb63-53"><a href="#cb63-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-54"><a href="#cb63-54" aria-hidden="true" tabindex="-1"></a>        results.append({</span>
<span id="cb63-55"><a href="#cb63-55" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Score"</span>: <span class="ss">f"</span><span class="sc">{</span>sims[idx]<span class="sc">:.4f}</span><span class="ss">"</span>,</span>
<span id="cb63-56"><a href="#cb63-56" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Topic"</span>: <span class="ss">f"</span><span class="sc">{</span>row<span class="sc">.</span>get(<span class="st">'topic_id'</span>, <span class="st">'N/A'</span>)<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>row<span class="sc">.</span>get(<span class="st">'ai_label'</span>, <span class="st">'N/A'</span>)<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb63-57"><a href="#cb63-57" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Title"</span>: row.get(<span class="st">"title"</span>, <span class="st">"No Title"</span>),</span>
<span id="cb63-58"><a href="#cb63-58" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Abstract"</span>: <span class="bu">str</span>(row.get(<span class="st">"abstract"</span>, <span class="st">""</span>))[:<span class="dv">200</span>] <span class="op">+</span> <span class="st">"..."</span></span>
<span id="cb63-59"><a href="#cb63-59" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb63-60"><a href="#cb63-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-61"><a href="#cb63-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(results)</span>
<span id="cb63-62"><a href="#cb63-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-63"><a href="#cb63-63" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Interactive Example ---</span></span>
<span id="cb63-64"><a href="#cb63-64" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"machine learning for risk assessment"</span></span>
<span id="cb63-65"><a href="#cb63-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üîé Searching for: '</span><span class="sc">{</span>query<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb63-66"><a href="#cb63-66" aria-hidden="true" tabindex="-1"></a>display(search_articles(query, top_k<span class="op">=</span><span class="dv">5</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="section-4-topic-analysis" class="level1">
<h1>Section 4: Topic Analysis</h1>
<div id="yoOHPHUUALlw" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot: Standard BERTopic Intertopic Distance Map</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a><span class="co"># This uses the built-in visualization from BERTopic</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> active_model.visualize_topics()</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="WOrmT4HaqRGe" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="co"># c-TF-IDF weight bar chart for Top 8 Topics</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get top 8 topics (excluding noise -1)</span></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>top_topics_info <span class="op">=</span> active_model.get_topic_info()</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>top_ids <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> top_topics_info[<span class="st">'Topic'</span>] <span class="cf">if</span> t <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>][:<span class="dv">8</span>]</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> active_model.visualize_barchart(</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>    topics<span class="op">=</span>top_ids,</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>    top_n_topics<span class="op">=</span><span class="bu">len</span>(top_ids),</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>    n_words<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>    custom_labels<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span><span class="st">"Top Words &amp; c-TF-IDF Weights for Major Topics"</span></span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>fig.update_layout(</span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a>    margin<span class="op">=</span><span class="bu">dict</span>(t<span class="op">=</span><span class="dv">60</span>, b<span class="op">=</span><span class="dv">60</span>, l<span class="op">=</span><span class="dv">60</span>, r<span class="op">=</span><span class="dv">40</span>),</span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a>    height<span class="op">=</span><span class="dv">800</span>,</span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a>    showlegend<span class="op">=</span><span class="va">False</span></span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="OZkGLch7pgM-" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Focused topic similarity heatmap for Top 5 Topics</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Select Top 5 Topics (by size)</span></span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>info <span class="op">=</span> active_model.get_topic_info()</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Exclude noise (-1)</span></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>focus_topics <span class="op">=</span> info[info[<span class="st">"Topic"</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>].head(<span class="dv">5</span>)[<span class="st">"Topic"</span>].tolist()</span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üîç Analyzing similarity for Top 5 Topics: </span><span class="sc">{</span>focus_topics<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Compute Topic Centroids from Document Embeddings</span></span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a><span class="co"># (Robust method: average SPECTER2 embeddings of docs in each topic)</span></span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a>topic_vecs <span class="op">=</span> []</span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a>topic_labels_list <span class="op">=</span> []</span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-21"><a href="#cb66-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Use global label_map if available, else fallback</span></span>
<span id="cb66-22"><a href="#cb66-22" aria-hidden="true" tabindex="-1"></a>current_labels <span class="op">=</span> label_map <span class="cf">if</span> <span class="st">"label_map"</span> <span class="kw">in</span> <span class="bu">globals</span>() <span class="cf">else</span> {}</span>
<span id="cb66-23"><a href="#cb66-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-24"><a href="#cb66-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> focus_topics:</span>
<span id="cb66-25"><a href="#cb66-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find docs belonging to this topic</span></span>
<span id="cb66-26"><a href="#cb66-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># df_topics_all was created in Section 7.8</span></span>
<span id="cb66-27"><a href="#cb66-27" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> df_topics_all[df_topics_all[<span class="st">"topic_id"</span>] <span class="op">==</span> t].index</span>
<span id="cb66-28"><a href="#cb66-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-29"><a href="#cb66-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(indices) <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> <span class="st">"embeddings"</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb66-30"><a href="#cb66-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Average embedding</span></span>
<span id="cb66-31"><a href="#cb66-31" aria-hidden="true" tabindex="-1"></a>        centroid <span class="op">=</span> np.mean(embeddings[indices], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb66-32"><a href="#cb66-32" aria-hidden="true" tabindex="-1"></a>        topic_vecs.append(centroid)</span>
<span id="cb66-33"><a href="#cb66-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-34"><a href="#cb66-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Label</span></span>
<span id="cb66-35"><a href="#cb66-35" aria-hidden="true" tabindex="-1"></a>        lbl <span class="op">=</span> current_labels.get(t, <span class="ss">f"Topic </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb66-36"><a href="#cb66-36" aria-hidden="true" tabindex="-1"></a>        topic_labels_list.append(<span class="ss">f"T</span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>lbl<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb66-37"><a href="#cb66-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb66-38"><a href="#cb66-38" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"‚ö†Ô∏è No embeddings found for Topic </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb66-39"><a href="#cb66-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-40"><a href="#cb66-40" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> topic_vecs:</span>
<span id="cb66-41"><a href="#cb66-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Compute Cosine Similarity</span></span>
<span id="cb66-42"><a href="#cb66-42" aria-hidden="true" tabindex="-1"></a>    sim_matrix <span class="op">=</span> cosine_similarity(np.array(topic_vecs))</span>
<span id="cb66-43"><a href="#cb66-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-44"><a href="#cb66-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Plot Heatmap</span></span>
<span id="cb66-45"><a href="#cb66-45" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> px.imshow(</span>
<span id="cb66-46"><a href="#cb66-46" aria-hidden="true" tabindex="-1"></a>        sim_matrix,</span>
<span id="cb66-47"><a href="#cb66-47" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span>topic_labels_list,</span>
<span id="cb66-48"><a href="#cb66-48" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span>topic_labels_list,</span>
<span id="cb66-49"><a href="#cb66-49" aria-hidden="true" tabindex="-1"></a>        text_auto<span class="op">=</span><span class="st">".2f"</span>,</span>
<span id="cb66-50"><a href="#cb66-50" aria-hidden="true" tabindex="-1"></a>        color_continuous_scale<span class="op">=</span><span class="st">"Blues"</span>,</span>
<span id="cb66-51"><a href="#cb66-51" aria-hidden="true" tabindex="-1"></a>        title<span class="op">=</span><span class="st">"Semantic Similarity: Top 5 Active Topics"</span>,</span>
<span id="cb66-52"><a href="#cb66-52" aria-hidden="true" tabindex="-1"></a>        aspect<span class="op">=</span><span class="st">"auto"</span></span>
<span id="cb66-53"><a href="#cb66-53" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb66-54"><a href="#cb66-54" aria-hidden="true" tabindex="-1"></a>    fig.update_layout(margin<span class="op">=</span><span class="bu">dict</span>(l<span class="op">=</span><span class="dv">20</span>, r<span class="op">=</span><span class="dv">20</span>, t<span class="op">=</span><span class="dv">50</span>, b<span class="op">=</span><span class="dv">20</span>))</span>
<span id="cb66-55"><a href="#cb66-55" aria-hidden="true" tabindex="-1"></a>    fig.show()</span>
<span id="cb66-56"><a href="#cb66-56" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb66-57"><a href="#cb66-57" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ùå Could not compute similarity (missing embeddings or topics)."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="wE1MDnh8saFA" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> top_words(t, n<span class="op">=</span><span class="dv">15</span>):</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {w <span class="cf">for</span> w,_ <span class="kw">in</span> active_model.get_topic(t)[:n]}</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> combinations</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the same focus topics as before (Top 5)</span></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>focus_topics <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>]</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üîç Jaccard Similarity (Word Overlap) for Top Topics: </span><span class="sc">{</span>focus_topics<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> a,b <span class="kw">in</span> combinations(focus_topics, <span class="dv">2</span>):</span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>    words_a <span class="op">=</span> top_words(a)</span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>    words_b <span class="op">=</span> top_words(b)</span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Jaccard = intersection / union</span></span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>    intersection <span class="op">=</span> <span class="bu">len</span>(words_a <span class="op">&amp;</span> words_b)</span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a>    union <span class="op">=</span> <span class="bu">len</span>(words_a <span class="op">|</span> words_b)</span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a>    jacc <span class="op">=</span> intersection <span class="op">/</span> union <span class="cf">if</span> union <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print overlap</span></span>
<span id="cb67-21"><a href="#cb67-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"T</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">‚ÄìT</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">: Jaccard = </span><span class="sc">{</span>jacc<span class="sc">:.2f}</span><span class="ss"> (</span><span class="sc">{</span>intersection<span class="sc">}</span><span class="ss"> shared words)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="8DzxuSwUt3Yc" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Representative docs ‚Üí IDs for top active topics [0, 1, 2, 3]</span></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Also prints ID overlaps across topics</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Focus on Top 4 topics for inspection</span></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>focus_topics <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>TOPK <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) Choose the exact text list used when fitting BERTopic</span></span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>docs_used <span class="op">=</span> df[<span class="st">"__vectorizer_text__"</span>].fillna(<span class="st">""</span>).astype(<span class="bu">str</span>).tolist()</span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) Build a lookup: text -&gt; [indices]</span></span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a>text2idx <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb68-16"><a href="#cb68-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, txt <span class="kw">in</span> <span class="bu">enumerate</span>(docs_used):</span>
<span id="cb68-17"><a href="#cb68-17" aria-hidden="true" tabindex="-1"></a>    text2idx[txt].append(i)</span>
<span id="cb68-18"><a href="#cb68-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-19"><a href="#cb68-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) Pick a doc id column (fallback to index if none)</span></span>
<span id="cb68-20"><a href="#cb68-20" aria-hidden="true" tabindex="-1"></a>doc_id_col <span class="op">=</span> <span class="va">None</span></span>
<span id="cb68-21"><a href="#cb68-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> cand <span class="kw">in</span> [<span class="st">"unique_id"</span>, <span class="st">"id"</span>, <span class="st">"document"</span>, <span class="st">"record_id"</span>]:</span>
<span id="cb68-22"><a href="#cb68-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> cand <span class="kw">in</span> df.columns:</span>
<span id="cb68-23"><a href="#cb68-23" aria-hidden="true" tabindex="-1"></a>        doc_id_col <span class="op">=</span> cand</span>
<span id="cb68-24"><a href="#cb68-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb68-25"><a href="#cb68-25" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> doc_id_col <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb68-26"><a href="#cb68-26" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df.reset_index().rename(columns<span class="op">=</span>{<span class="st">"index"</span>: <span class="st">"doc_index"</span>})</span>
<span id="cb68-27"><a href="#cb68-27" aria-hidden="true" tabindex="-1"></a>    doc_id_col <span class="op">=</span> <span class="st">"doc_index"</span></span>
<span id="cb68-28"><a href="#cb68-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-29"><a href="#cb68-29" aria-hidden="true" tabindex="-1"></a><span class="co"># 4) Helper to get top-K representative indices for a topic</span></span>
<span id="cb68-30"><a href="#cb68-30" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rep_indices_for_topic(t, k<span class="op">=</span>TOPK):</span>
<span id="cb68-31"><a href="#cb68-31" aria-hidden="true" tabindex="-1"></a>    reps <span class="op">=</span> <span class="va">None</span></span>
<span id="cb68-32"><a href="#cb68-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(active_model, <span class="st">"get_representative_docs"</span>):</span>
<span id="cb68-33"><a href="#cb68-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb68-34"><a href="#cb68-34" aria-hidden="true" tabindex="-1"></a>            reps <span class="op">=</span> active_model.get_representative_docs(t)</span>
<span id="cb68-35"><a href="#cb68-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb68-36"><a href="#cb68-36" aria-hidden="true" tabindex="-1"></a>            reps <span class="op">=</span> <span class="va">None</span></span>
<span id="cb68-37"><a href="#cb68-37" aria-hidden="true" tabindex="-1"></a>    idxs <span class="op">=</span> []</span>
<span id="cb68-38"><a href="#cb68-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> reps:</span>
<span id="cb68-39"><a href="#cb68-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># map representative texts back to indices</span></span>
<span id="cb68-40"><a href="#cb68-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> txt <span class="kw">in</span> reps:</span>
<span id="cb68-41"><a href="#cb68-41" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> text2idx.get(txt, []):</span>
<span id="cb68-42"><a href="#cb68-42" aria-hidden="true" tabindex="-1"></a>                idxs.append(i)</span>
<span id="cb68-43"><a href="#cb68-43" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">len</span>(idxs) <span class="op">&gt;=</span> k:</span>
<span id="cb68-44"><a href="#cb68-44" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span></span>
<span id="cb68-45"><a href="#cb68-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(idxs) <span class="op">&gt;=</span> k:</span>
<span id="cb68-46"><a href="#cb68-46" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb68-47"><a href="#cb68-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fallback if mapping failed or unavailable: use top-prob docs in this topic</span></span>
<span id="cb68-48"><a href="#cb68-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> idxs:</span>
<span id="cb68-49"><a href="#cb68-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Filter for topic t</span></span>
<span id="cb68-50"><a href="#cb68-50" aria-hidden="true" tabindex="-1"></a>        t_indices <span class="op">=</span> [i <span class="cf">for</span> i, tp <span class="kw">in</span> <span class="bu">enumerate</span>(topics) <span class="cf">if</span> tp <span class="op">==</span> t]</span>
<span id="cb68-51"><a href="#cb68-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> probs <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb68-52"><a href="#cb68-52" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Sort by probability</span></span>
<span id="cb68-53"><a href="#cb68-53" aria-hidden="true" tabindex="-1"></a>            <span class="co"># probs might be 1D or 2D. If 2D, take column t if available or max</span></span>
<span id="cb68-54"><a href="#cb68-54" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(probs.shape) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb68-55"><a href="#cb68-55" aria-hidden="true" tabindex="-1"></a>                <span class="co"># 1D array of max probs</span></span>
<span id="cb68-56"><a href="#cb68-56" aria-hidden="true" tabindex="-1"></a>                <span class="co"># We need the specific prob for this topic?</span></span>
<span id="cb68-57"><a href="#cb68-57" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Usually probs is max prob. So just sort descending.</span></span>
<span id="cb68-58"><a href="#cb68-58" aria-hidden="true" tabindex="-1"></a>                <span class="co"># But we need to ensure the doc actually belongs to topic t.</span></span>
<span id="cb68-59"><a href="#cb68-59" aria-hidden="true" tabindex="-1"></a>                <span class="co"># best["probs"] is just the probability of the assigned topic.</span></span>
<span id="cb68-60"><a href="#cb68-60" aria-hidden="true" tabindex="-1"></a>                sub_probs <span class="op">=</span> [(i, probs[i]) <span class="cf">for</span> i <span class="kw">in</span> t_indices]</span>
<span id="cb68-61"><a href="#cb68-61" aria-hidden="true" tabindex="-1"></a>                sub_probs.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb68-62"><a href="#cb68-62" aria-hidden="true" tabindex="-1"></a>                idxs <span class="op">=</span> [x[<span class="dv">0</span>] <span class="cf">for</span> x <span class="kw">in</span> sub_probs[:k]]</span>
<span id="cb68-63"><a href="#cb68-63" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb68-64"><a href="#cb68-64" aria-hidden="true" tabindex="-1"></a>                <span class="co"># 2D array</span></span>
<span id="cb68-65"><a href="#cb68-65" aria-hidden="true" tabindex="-1"></a>                sub_probs <span class="op">=</span> [(i, probs[i][t]) <span class="cf">for</span> i <span class="kw">in</span> t_indices]</span>
<span id="cb68-66"><a href="#cb68-66" aria-hidden="true" tabindex="-1"></a>                sub_probs.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb68-67"><a href="#cb68-67" aria-hidden="true" tabindex="-1"></a>                idxs <span class="op">=</span> [x[<span class="dv">0</span>] <span class="cf">for</span> x <span class="kw">in</span> sub_probs[:k]]</span>
<span id="cb68-68"><a href="#cb68-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb68-69"><a href="#cb68-69" aria-hidden="true" tabindex="-1"></a>            idxs <span class="op">=</span> t_indices[:k]</span>
<span id="cb68-70"><a href="#cb68-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-71"><a href="#cb68-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> idxs</span>
<span id="cb68-72"><a href="#cb68-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-73"><a href="#cb68-73" aria-hidden="true" tabindex="-1"></a><span class="co"># 5) Collect and print IDs per topic</span></span>
<span id="cb68-74"><a href="#cb68-74" aria-hidden="true" tabindex="-1"></a>topic_to_ids <span class="op">=</span> {}</span>
<span id="cb68-75"><a href="#cb68-75" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> focus_topics:</span>
<span id="cb68-76"><a href="#cb68-76" aria-hidden="true" tabindex="-1"></a>    idxs <span class="op">=</span> rep_indices_for_topic(t, TOPK)</span>
<span id="cb68-77"><a href="#cb68-77" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get original IDs</span></span>
<span id="cb68-78"><a href="#cb68-78" aria-hidden="true" tabindex="-1"></a>    ids <span class="op">=</span> [df.iloc[i][doc_id_col] <span class="cf">for</span> i <span class="kw">in</span> idxs]</span>
<span id="cb68-79"><a href="#cb68-79" aria-hidden="true" tabindex="-1"></a>    topic_to_ids[t] <span class="op">=</span> <span class="bu">list</span>(ids)</span>
<span id="cb68-80"><a href="#cb68-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-81"><a href="#cb68-81" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get label</span></span>
<span id="cb68-82"><a href="#cb68-82" aria-hidden="true" tabindex="-1"></a>    lbl <span class="op">=</span> label_map.get(t, <span class="ss">f"Topic </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb68-83"><a href="#cb68-83" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">üìå </span><span class="sc">{</span>lbl<span class="sc">}</span><span class="ss"> (Topic </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">):"</span>)</span>
<span id="cb68-84"><a href="#cb68-84" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   ids: </span><span class="sc">{</span>ids<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb68-85"><a href="#cb68-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-86"><a href="#cb68-86" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Show snippets</span></span>
<span id="cb68-87"><a href="#cb68-87" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   üìù Snippets:"</span>)</span>
<span id="cb68-88"><a href="#cb68-88" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> idxs[:<span class="dv">2</span>]:</span>
<span id="cb68-89"><a href="#cb68-89" aria-hidden="true" tabindex="-1"></a>        snippet <span class="op">=</span> df.iloc[i][<span class="st">"title"</span>] <span class="cf">if</span> <span class="st">"title"</span> <span class="kw">in</span> df.columns <span class="cf">else</span> df.iloc[i][<span class="st">"__clean__"</span>][:<span class="dv">100</span>]</span>
<span id="cb68-90"><a href="#cb68-90" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"      - </span><span class="sc">{</span>snippet<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb68-91"><a href="#cb68-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-92"><a href="#cb68-92" aria-hidden="true" tabindex="-1"></a><span class="co"># 6) Show overlaps between topics (by IDs)</span></span>
<span id="cb68-93"><a href="#cb68-93" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> combinations</span>
<span id="cb68-94"><a href="#cb68-94" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üîó ID overlaps (representatives):"</span>)</span>
<span id="cb68-95"><a href="#cb68-95" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> a, b <span class="kw">in</span> combinations(focus_topics, <span class="dv">2</span>):</span>
<span id="cb68-96"><a href="#cb68-96" aria-hidden="true" tabindex="-1"></a>    A, B <span class="op">=</span> <span class="bu">set</span>(topic_to_ids[a]), <span class="bu">set</span>(topic_to_ids[b])</span>
<span id="cb68-97"><a href="#cb68-97" aria-hidden="true" tabindex="-1"></a>    inter <span class="op">=</span> A <span class="op">&amp;</span> B</span>
<span id="cb68-98"><a href="#cb68-98" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"T</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss"> ‚à© T</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="bu">len</span>(inter)<span class="sc">}</span><span class="ss">  </span><span class="sc">{</span><span class="bu">sorted</span>(inter)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="TpFxOcH8FD-K" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Phase 3 (Cluster = [0, 8, 32, 45]) ‚Üí assemble topic info</span></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a><span class="co"># The specific cluster of interest defined in the workflow</span></span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>cluster_topics <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">8</span>, <span class="dv">32</span>, <span class="dv">45</span>]</span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Get base stats from the active model</span></span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>ti <span class="op">=</span> active_model.get_topic_info()</span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a>cluster_stats <span class="op">=</span> ti[ti[<span class="st">"Topic"</span>].isin(cluster_topics)].copy()</span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Merge with AI Labels for interpretation</span></span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"labels_df"</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a>    cluster_stats <span class="op">=</span> cluster_stats.merge(</span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a>        labels_df[[<span class="st">"topic_id"</span>, <span class="st">"ai_label"</span>, <span class="st">"ai_rationale"</span>]],</span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a>        left_on<span class="op">=</span><span class="st">"Topic"</span>, right_on<span class="op">=</span><span class="st">"topic_id"</span>, how<span class="op">=</span><span class="st">"left"</span></span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb69-19"><a href="#cb69-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Columns to display</span></span>
<span id="cb69-20"><a href="#cb69-20" aria-hidden="true" tabindex="-1"></a>    cols <span class="op">=</span> [<span class="st">"Topic"</span>, <span class="st">"Count"</span>, <span class="st">"ai_label"</span>, <span class="st">"ai_rationale"</span>]</span>
<span id="cb69-21"><a href="#cb69-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"üîç Analysis for Cluster </span><span class="sc">{</span>cluster_topics<span class="sc">}</span><span class="ss"> (using AI Labels):"</span>)</span>
<span id="cb69-22"><a href="#cb69-22" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb69-23"><a href="#cb69-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fallback if AI labels missing</span></span>
<span id="cb69-24"><a href="#cb69-24" aria-hidden="true" tabindex="-1"></a>    cols <span class="op">=</span> [<span class="st">"Topic"</span>, <span class="st">"Count"</span>, <span class="st">"Name"</span>]</span>
<span id="cb69-25"><a href="#cb69-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"üîç Analysis for Cluster </span><span class="sc">{</span>cluster_topics<span class="sc">}</span><span class="ss"> (using Raw Names):"</span>)</span>
<span id="cb69-26"><a href="#cb69-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-27"><a href="#cb69-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Display</span></span>
<span id="cb69-28"><a href="#cb69-28" aria-hidden="true" tabindex="-1"></a>display(cluster_stats[cols])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<section id="visualization-top-terms-per-topic" class="level2">
<h2 class="anchored" data-anchor-id="visualization-top-terms-per-topic">10) Visualization ‚Äî Top Terms per Topic</h2>
<div id="3b0f8fec" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_top_terms(model: BERTopic, topic_id: <span class="bu">int</span>, top_n: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10</span>):</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get top terms from BERTopic</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>    terms <span class="op">=</span> model.get_topic(topic_id)[:top_n]</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> terms:</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"No terms for topic </span><span class="sc">{</span>topic_id<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> [w <span class="cf">for</span> w, _ <span class="kw">in</span> terms]</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> [<span class="bu">float</span>(wt) <span class="cf">for</span> _, wt <span class="kw">in</span> terms]</span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># default title</span></span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>    title_txt <span class="op">=</span> <span class="ss">f"Topic </span><span class="sc">{</span>topic_id<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># try to show AI label if we have it</span></span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">"labels_df"</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb70-18"><a href="#cb70-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># in our latest flow the column name is ai_label</span></span>
<span id="cb70-19"><a href="#cb70-19" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> labels_df.set_index(<span class="st">"topic_id"</span>)[<span class="st">"ai_label"</span>].to_dict()</span>
<span id="cb70-20"><a href="#cb70-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> topic_id <span class="kw">in</span> m <span class="kw">and</span> <span class="bu">isinstance</span>(m[topic_id], <span class="bu">str</span>) <span class="kw">and</span> m[topic_id]:</span>
<span id="cb70-21"><a href="#cb70-21" aria-hidden="true" tabindex="-1"></a>            title_txt <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>title_txt<span class="sc">}</span><span class="ss"> ‚Äî </span><span class="sc">{</span>m[topic_id]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb70-22"><a href="#cb70-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-23"><a href="#cb70-23" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb70-24"><a href="#cb70-24" aria-hidden="true" tabindex="-1"></a>    plt.bar(<span class="bu">range</span>(<span class="bu">len</span>(words)), weights)</span>
<span id="cb70-25"><a href="#cb70-25" aria-hidden="true" tabindex="-1"></a>    plt.xticks(<span class="bu">range</span>(<span class="bu">len</span>(words)), words, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">"right"</span>)</span>
<span id="cb70-26"><a href="#cb70-26" aria-hidden="true" tabindex="-1"></a>    plt.title(title_txt)</span>
<span id="cb70-27"><a href="#cb70-27" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"c-TF-IDF weight"</span>)</span>
<span id="cb70-28"><a href="#cb70-28" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb70-29"><a href="#cb70-29" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb70-30"><a href="#cb70-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-31"><a href="#cb70-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-32"><a href="#cb70-32" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb70-33"><a href="#cb70-33" aria-hidden="true" tabindex="-1"></a><span class="co"># pick topics to plot</span></span>
<span id="cb70-34"><a href="#cb70-34" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb70-35"><a href="#cb70-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-36"><a href="#cb70-36" aria-hidden="true" tabindex="-1"></a><span class="co"># prefer AI-labelled topics</span></span>
<span id="cb70-37"><a href="#cb70-37" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"labels_df"</span> <span class="kw">in</span> <span class="bu">globals</span>() <span class="kw">and</span> <span class="kw">not</span> labels_df.empty:</span>
<span id="cb70-38"><a href="#cb70-38" aria-hidden="true" tabindex="-1"></a>    topic_list <span class="op">=</span> labels_df[<span class="st">"topic_id"</span>].tolist()[:<span class="dv">5</span>]</span>
<span id="cb70-39"><a href="#cb70-39" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb70-40"><a href="#cb70-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># fallback: get from the model</span></span>
<span id="cb70-41"><a href="#cb70-41" aria-hidden="true" tabindex="-1"></a>    info <span class="op">=</span> topic_model.get_topic_info()</span>
<span id="cb70-42"><a href="#cb70-42" aria-hidden="true" tabindex="-1"></a>    topic_list <span class="op">=</span> [<span class="bu">int</span>(t) <span class="cf">for</span> t <span class="kw">in</span> info.Topic.tolist() <span class="cf">if</span> t <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>][:<span class="dv">5</span>]</span>
<span id="cb70-43"><a href="#cb70-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-44"><a href="#cb70-44" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb70-45"><a href="#cb70-45" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tid <span class="kw">in</span> topic_list:</span>
<span id="cb70-46"><a href="#cb70-46" aria-hidden="true" tabindex="-1"></a>    plot_top_terms(topic_model, <span class="bu">int</span>(tid), top_n<span class="op">=</span><span class="dv">10</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="topic-similarity-heatmap-correlation-table" class="level2">
<h2 class="anchored" data-anchor-id="topic-similarity-heatmap-correlation-table">11) Topic Similarity Heatmap + Correlation Table</h2>
<div id="44c03837" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 1Ô∏è‚É£ Get active model and topics</span></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>active_model <span class="op">=</span> topic_model</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>info <span class="op">=</span> active_model.get_topic_info()</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>topic_ids_sorted <span class="op">=</span> <span class="bu">sorted</span>([<span class="bu">int</span>(tid) <span class="cf">for</span> tid <span class="kw">in</span> info.Topic.tolist() <span class="cf">if</span> tid <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 2Ô∏è‚É£ Try to use topic embeddings (preferred)</span></span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>emb <span class="op">=</span> <span class="bu">getattr</span>(active_model, <span class="st">"topic_embeddings_"</span>, <span class="va">None</span>)</span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> emb <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a>    emb_ordered <span class="op">=</span> np.vstack([emb[tid] <span class="cf">for</span> tid <span class="kw">in</span> topic_ids_sorted])</span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a>    sim <span class="op">=</span> cosine_similarity(emb_ordered)</span>
<span id="cb71-16"><a href="#cb71-16" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb71-17"><a href="#cb71-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># fallback: bag-of-top-words similarity</span></span>
<span id="cb71-18"><a href="#cb71-18" aria-hidden="true" tabindex="-1"></a>    top_words <span class="op">=</span> {</span>
<span id="cb71-19"><a href="#cb71-19" aria-hidden="true" tabindex="-1"></a>        tid: [w <span class="cf">for</span> w, _ <span class="kw">in</span> active_model.get_topic(tid)[:<span class="dv">15</span>]]</span>
<span id="cb71-20"><a href="#cb71-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> tid <span class="kw">in</span> topic_ids_sorted</span>
<span id="cb71-21"><a href="#cb71-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb71-22"><a href="#cb71-22" aria-hidden="true" tabindex="-1"></a>    vocab <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>({w <span class="cf">for</span> ws <span class="kw">in</span> top_words.values() <span class="cf">for</span> w <span class="kw">in</span> ws}))</span>
<span id="cb71-23"><a href="#cb71-23" aria-hidden="true" tabindex="-1"></a>    word2idx <span class="op">=</span> {w: i <span class="cf">for</span> i, w <span class="kw">in</span> <span class="bu">enumerate</span>(vocab)}</span>
<span id="cb71-24"><a href="#cb71-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-25"><a href="#cb71-25" aria-hidden="true" tabindex="-1"></a>    mat <span class="op">=</span> np.zeros((<span class="bu">len</span>(topic_ids_sorted), <span class="bu">len</span>(vocab)), dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb71-26"><a href="#cb71-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, tid <span class="kw">in</span> <span class="bu">enumerate</span>(topic_ids_sorted):</span>
<span id="cb71-27"><a href="#cb71-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> w <span class="kw">in</span> top_words[tid]:</span>
<span id="cb71-28"><a href="#cb71-28" aria-hidden="true" tabindex="-1"></a>            mat[i, word2idx[w]] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb71-29"><a href="#cb71-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-30"><a href="#cb71-30" aria-hidden="true" tabindex="-1"></a>    sim <span class="op">=</span> cosine_similarity(mat)</span>
<span id="cb71-31"><a href="#cb71-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-32"><a href="#cb71-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 3Ô∏è‚É£ Plot heatmap (topic numbers only)</span></span>
<span id="cb71-33"><a href="#cb71-33" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">6</span>))</span>
<span id="cb71-34"><a href="#cb71-34" aria-hidden="true" tabindex="-1"></a>plt.imshow(sim, interpolation<span class="op">=</span><span class="st">"nearest"</span>, cmap<span class="op">=</span><span class="st">"viridis"</span>)</span>
<span id="cb71-35"><a href="#cb71-35" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Topic‚ÄìTopic Similarity (Cosine)"</span>)</span>
<span id="cb71-36"><a href="#cb71-36" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb71-37"><a href="#cb71-37" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="bu">len</span>(topic_ids_sorted)), topic_ids_sorted, rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb71-38"><a href="#cb71-38" aria-hidden="true" tabindex="-1"></a>plt.yticks(<span class="bu">range</span>(<span class="bu">len</span>(topic_ids_sorted)), topic_ids_sorted)</span>
<span id="cb71-39"><a href="#cb71-39" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb71-40"><a href="#cb71-40" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb71-41"><a href="#cb71-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-42"><a href="#cb71-42" aria-hidden="true" tabindex="-1"></a><span class="co"># keep similarity matrix for next cell</span></span>
<span id="cb71-43"><a href="#cb71-43" aria-hidden="true" tabindex="-1"></a>similarity_matrix <span class="op">=</span> sim</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="LVce_P8k4vIY" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 4Ô∏è‚É£ Build similarity / correlation table</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>corr_df <span class="op">=</span> pd.DataFrame(similarity_matrix, index<span class="op">=</span>topic_ids_sorted, columns<span class="op">=</span>topic_ids_sorted)</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"üìà Topic‚ÄìTopic Similarity (first 10 topics):"</span>)</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>display(corr_df.head(<span class="dv">10</span>))</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 5Ô∏è‚É£ Optional: Topic ID ‚Üí Label reference</span></span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"labels_df"</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a>    topic_lookup <span class="op">=</span> labels_df[[<span class="st">"topic_id"</span>, <span class="st">"ai_label"</span>]].sort_values(<span class="st">"topic_id"</span>)</span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">üß† Topic ID ‚Üí AI Label Reference"</span>)</span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a>    display(topic_lookup.head(<span class="dv">15</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="topic-trends-over-time" class="level2">
<h2 class="anchored" data-anchor-id="topic-trends-over-time">12) Topic Trends Over Time</h2>
<section id="build-the-base-trend-table" class="level3">
<h3 class="anchored" data-anchor-id="build-the-base-trend-table">12.1) Build the base trend table</h3>
<p>Why: everything (active, emerging, declining) needs the same base data: how many docs per topic per year.</p>
<div id="KhmkmK5KrCve" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Topic Trends Over Time ‚Äî build base trend table</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) Detect year column</span></span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>year_col <span class="op">=</span> <span class="va">None</span></span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> cand <span class="kw">in</span> [<span class="st">"year"</span>, <span class="st">"publication_year"</span>, <span class="st">"py"</span>, <span class="st">"pub_year"</span>, <span class="st">"Year"</span>]:</span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> cand <span class="kw">in</span> df_topics_all.columns:</span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>        year_col <span class="op">=</span> cand</span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> year_col:</span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"üìÖ Using year column: '</span><span class="sc">{</span>year_col<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2) Clean year data</span></span>
<span id="cb73-17"><a href="#cb73-17" aria-hidden="true" tabindex="-1"></a>    df_trends_src <span class="op">=</span> df_topics_all[df_topics_all[<span class="st">"topic_id"</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>].copy()</span>
<span id="cb73-18"><a href="#cb73-18" aria-hidden="true" tabindex="-1"></a>    df_trends_src[year_col] <span class="op">=</span> pd.to_numeric(df_trends_src[year_col], errors<span class="op">=</span><span class="st">'coerce'</span>)</span>
<span id="cb73-19"><a href="#cb73-19" aria-hidden="true" tabindex="-1"></a>    df_trends_src <span class="op">=</span> df_trends_src.dropna(subset<span class="op">=</span>[year_col])</span>
<span id="cb73-20"><a href="#cb73-20" aria-hidden="true" tabindex="-1"></a>    df_trends_src[year_col] <span class="op">=</span> df_trends_src[year_col].astype(<span class="bu">int</span>)</span>
<span id="cb73-21"><a href="#cb73-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-22"><a href="#cb73-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3) Aggregate: Count per Topic per Year</span></span>
<span id="cb73-23"><a href="#cb73-23" aria-hidden="true" tabindex="-1"></a>    trend_df <span class="op">=</span> (</span>
<span id="cb73-24"><a href="#cb73-24" aria-hidden="true" tabindex="-1"></a>        df_trends_src</span>
<span id="cb73-25"><a href="#cb73-25" aria-hidden="true" tabindex="-1"></a>        .groupby([<span class="st">"topic_id"</span>, year_col])</span>
<span id="cb73-26"><a href="#cb73-26" aria-hidden="true" tabindex="-1"></a>        .size()</span>
<span id="cb73-27"><a href="#cb73-27" aria-hidden="true" tabindex="-1"></a>        .reset_index(name<span class="op">=</span><span class="st">"count"</span>)</span>
<span id="cb73-28"><a href="#cb73-28" aria-hidden="true" tabindex="-1"></a>        .sort_values([<span class="st">"topic_id"</span>, year_col])</span>
<span id="cb73-29"><a href="#cb73-29" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb73-30"><a href="#cb73-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-31"><a href="#cb73-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4) Create Pivot for easier lookup: {topic: {year: count}}</span></span>
<span id="cb73-32"><a href="#cb73-32" aria-hidden="true" tabindex="-1"></a>    trend_dict <span class="op">=</span> {}</span>
<span id="cb73-33"><a href="#cb73-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> pid, grp <span class="kw">in</span> trend_df.groupby(<span class="st">"topic_id"</span>):</span>
<span id="cb73-34"><a href="#cb73-34" aria-hidden="true" tabindex="-1"></a>        trend_dict[pid] <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(grp[year_col], grp[<span class="st">"count"</span>]))</span>
<span id="cb73-35"><a href="#cb73-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-36"><a href="#cb73-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"‚úÖ Trend data prepared for </span><span class="sc">{</span><span class="bu">len</span>(trend_dict)<span class="sc">}</span><span class="ss"> topics."</span>)</span>
<span id="cb73-37"><a href="#cb73-37" aria-hidden="true" tabindex="-1"></a>    display(trend_df.head())</span>
<span id="cb73-38"><a href="#cb73-38" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb73-39"><a href="#cb73-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ö†Ô∏è No suitable 'year' column found. Trend analysis skipped."</span>)</span>
<span id="cb73-40"><a href="#cb73-40" aria-hidden="true" tabindex="-1"></a>    trend_df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb73-41"><a href="#cb73-41" aria-hidden="true" tabindex="-1"></a>    trend_dict <span class="op">=</span> {}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="compute-topic-level-metrics" class="level3">
<h3 class="anchored" data-anchor-id="compute-topic-level-metrics">12.2) Compute topic-level metrics</h3>
<p>Why: to classify topics, we need features: total volume, first/last year, trend (slope), variability. Slope tells us emerging vs declining.</p>
<p>Decision explanation:</p>
<ul>
<li><p>total_docs ‚Üí to find Most Active</p></li>
<li><p>slope ‚Üí to find Emerging (slope &gt; 0) and Declining (slope &lt; 0)</p></li>
<li><p>first_year ‚Üí to spot Newest topics</p></li>
<li><p>volatility ‚Üí to spot event-driven topics</p></li>
</ul>
<div id="M75Ag09-rYuD" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>topic_metrics <span class="op">=</span> []</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> trend_df.empty:</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tid, counts <span class="kw">in</span> trend_dict.items():</span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>        years <span class="op">=</span> <span class="bu">sorted</span>(counts.keys())</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>        vals <span class="op">=</span> [counts[y] <span class="cf">for</span> y <span class="kw">in</span> years]</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Basic stats</span></span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>        total_docs <span class="op">=</span> <span class="bu">sum</span>(vals)</span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a>        first_year <span class="op">=</span> years[<span class="dv">0</span>]</span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>        last_year <span class="op">=</span> years[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Slope (growth rate)</span></span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(years) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb74-17"><a href="#cb74-17" aria-hidden="true" tabindex="-1"></a>            slope <span class="op">=</span> np.polyfit(years, vals, <span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb74-18"><a href="#cb74-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb74-19"><a href="#cb74-19" aria-hidden="true" tabindex="-1"></a>            slope <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb74-20"><a href="#cb74-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-21"><a href="#cb74-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Volatility (std/mean)</span></span>
<span id="cb74-22"><a href="#cb74-22" aria-hidden="true" tabindex="-1"></a>        mean_val <span class="op">=</span> np.mean(vals)</span>
<span id="cb74-23"><a href="#cb74-23" aria-hidden="true" tabindex="-1"></a>        volatility <span class="op">=</span> (np.std(vals) <span class="op">/</span> mean_val) <span class="cf">if</span> mean_val <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb74-24"><a href="#cb74-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-25"><a href="#cb74-25" aria-hidden="true" tabindex="-1"></a>        topic_metrics.append({</span>
<span id="cb74-26"><a href="#cb74-26" aria-hidden="true" tabindex="-1"></a>            <span class="st">"topic_id"</span>: tid,</span>
<span id="cb74-27"><a href="#cb74-27" aria-hidden="true" tabindex="-1"></a>            <span class="st">"total_docs"</span>: total_docs,</span>
<span id="cb74-28"><a href="#cb74-28" aria-hidden="true" tabindex="-1"></a>            <span class="st">"first_year"</span>: first_year,</span>
<span id="cb74-29"><a href="#cb74-29" aria-hidden="true" tabindex="-1"></a>            <span class="st">"last_year"</span>: last_year,</span>
<span id="cb74-30"><a href="#cb74-30" aria-hidden="true" tabindex="-1"></a>            <span class="st">"slope"</span>: slope,</span>
<span id="cb74-31"><a href="#cb74-31" aria-hidden="true" tabindex="-1"></a>            <span class="st">"volatility"</span>: volatility</span>
<span id="cb74-32"><a href="#cb74-32" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb74-33"><a href="#cb74-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-34"><a href="#cb74-34" aria-hidden="true" tabindex="-1"></a>    metrics_df <span class="op">=</span> pd.DataFrame(topic_metrics)</span>
<span id="cb74-35"><a href="#cb74-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-36"><a href="#cb74-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Merge with AI Labels for readability</span></span>
<span id="cb74-37"><a href="#cb74-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">"labels_df"</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb74-38"><a href="#cb74-38" aria-hidden="true" tabindex="-1"></a>        metrics_df <span class="op">=</span> metrics_df.merge(labels_df[[<span class="st">"topic_id"</span>, <span class="st">"ai_label"</span>]], on<span class="op">=</span><span class="st">"topic_id"</span>, how<span class="op">=</span><span class="st">"left"</span>)</span>
<span id="cb74-39"><a href="#cb74-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-40"><a href="#cb74-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚úÖ Calculated trend metrics (slope, volatility)."</span>)</span>
<span id="cb74-41"><a href="#cb74-41" aria-hidden="true" tabindex="-1"></a>    display(metrics_df.sort_values(<span class="st">"slope"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">5</span>))</span>
<span id="cb74-42"><a href="#cb74-42" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb74-43"><a href="#cb74-43" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ö†Ô∏è No trend data available."</span>)</span>
<span id="cb74-44"><a href="#cb74-44" aria-hidden="true" tabindex="-1"></a>    metrics_df <span class="op">=</span> pd.DataFrame()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
</section>
<section id="most-active-topics-by-total-documents" class="level2">
<h2 class="anchored" data-anchor-id="most-active-topics-by-total-documents">12.3) Most Active Topics (by total documents)</h2>
<p>Why: this is the most common view in bibliometric papers ‚Äî ‚Äúwhat are the dominant themes?‚Äù</p>
<p>This gives you the topic IDs to plot.</p>
<div id="qpf36PEhrrmp" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>TOP_N <span class="op">=</span> <span class="dv">5</span>  <span class="co"># change if needed</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Select top topics by total document volume</span></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>most_active <span class="op">=</span> (</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>    topic_metrics_df</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>    .sort_values(<span class="st">"total_docs"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>    .head(TOP_N)</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Top </span><span class="sc">{</span>TOP_N<span class="sc">}</span><span class="ss"> Most Active Topics"</span>)</span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a>display(most_active[[<span class="st">"topic_id"</span>, <span class="st">"total_docs"</span>, <span class="st">"slope"</span>, <span class="st">"first_year"</span>, <span class="st">"last_year"</span>, <span class="st">"volatility"</span>]])</span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="emerging-fast-growing-topics" class="level2">
<h2 class="anchored" data-anchor-id="emerging-fast-growing-topics">12.4) Emerging / Fast-Growing Topics</h2>
<p>Why: sometimes a topic is small overall but exploding recently. We detect those by slope and recency.</p>
<p>Decision:</p>
<ul>
<li><p>we require recent presence so we don‚Äôt accidentally pick an old topic that just had a fluke increase early on</p></li>
<li><p>we sort by slope because we care about rate of growth, not just volume</p></li>
</ul>
<div id="RcVmeaxXrxws" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Emerging / Fast-Growing Topics</span></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Uses:</span></span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a><span class="co"># - topic_metrics_df  (slope, last_year, total_docs)</span></span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a><span class="co"># - trend (dict)      (for plotting later)</span></span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a><span class="co"># latest year in your corpus</span></span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a>max_year <span class="op">=</span> trend_df[<span class="st">"year"</span>].<span class="bu">max</span>()</span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-12"><a href="#cb76-12" aria-hidden="true" tabindex="-1"></a>EMERGING_TOP_N <span class="op">=</span> <span class="dv">5</span>  <span class="co"># change if needed</span></span>
<span id="cb76-13"><a href="#cb76-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-14"><a href="#cb76-14" aria-hidden="true" tabindex="-1"></a>emerging <span class="op">=</span> (</span>
<span id="cb76-15"><a href="#cb76-15" aria-hidden="true" tabindex="-1"></a>    topic_metrics_df</span>
<span id="cb76-16"><a href="#cb76-16" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">"slope &gt; 0"</span>)                    <span class="co"># growing</span></span>
<span id="cb76-17"><a href="#cb76-17" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">"last_year &gt;= @max_year - 2"</span>)   <span class="co"># active in the last 2 years</span></span>
<span id="cb76-18"><a href="#cb76-18" aria-hidden="true" tabindex="-1"></a>    .sort_values(<span class="st">"slope"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb76-19"><a href="#cb76-19" aria-hidden="true" tabindex="-1"></a>    .head(EMERGING_TOP_N)</span>
<span id="cb76-20"><a href="#cb76-20" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb76-21"><a href="#cb76-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb76-22"><a href="#cb76-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-23"><a href="#cb76-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üöÄ Emerging / Fast-Growing Topics (top </span><span class="sc">{</span>EMERGING_TOP_N<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb76-24"><a href="#cb76-24" aria-hidden="true" tabindex="-1"></a>display(emerging[[<span class="st">"topic_id"</span>, <span class="st">"total_docs"</span>, <span class="st">"slope"</span>, <span class="st">"first_year"</span>, <span class="st">"last_year"</span>, <span class="st">"volatility"</span>]])</span>
<span id="cb76-25"><a href="#cb76-25" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<section id="declining-topics" class="level3">
<h3 class="anchored" data-anchor-id="declining-topics">12.5) Declining Topics</h3>
<p>Why: nice for discussion sections ‚Äî ‚Äúearlier work focused on X but is now declining.‚Äù</p>
<div id="S32AFy3fsCO6" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Declining Topics</span></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Uses:</span></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a><span class="co"># - topic_metrics_df  (slope, first_year, total_docs)</span></span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a><span class="co"># - trend (dict)      (for plotting later)</span></span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a><span class="co"># latest year from your trend_df</span></span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a>max_year <span class="op">=</span> trend_df[<span class="st">"year"</span>].<span class="bu">max</span>()</span>
<span id="cb77-11"><a href="#cb77-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-12"><a href="#cb77-12" aria-hidden="true" tabindex="-1"></a>DECLINING_TOP_N <span class="op">=</span> <span class="dv">5</span>  <span class="co"># change if needed</span></span>
<span id="cb77-13"><a href="#cb77-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-14"><a href="#cb77-14" aria-hidden="true" tabindex="-1"></a>declining <span class="op">=</span> (</span>
<span id="cb77-15"><a href="#cb77-15" aria-hidden="true" tabindex="-1"></a>    topic_metrics_df</span>
<span id="cb77-16"><a href="#cb77-16" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">"slope &lt; 0"</span>)                    <span class="co"># shrinking</span></span>
<span id="cb77-17"><a href="#cb77-17" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">"first_year &lt;= @max_year - 3"</span>)  <span class="co"># existed for a while</span></span>
<span id="cb77-18"><a href="#cb77-18" aria-hidden="true" tabindex="-1"></a>    .sort_values(<span class="st">"slope"</span>, ascending<span class="op">=</span><span class="va">True</span>)  <span class="co"># more negative = steeper decline</span></span>
<span id="cb77-19"><a href="#cb77-19" aria-hidden="true" tabindex="-1"></a>    .head(DECLINING_TOP_N)</span>
<span id="cb77-20"><a href="#cb77-20" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb77-21"><a href="#cb77-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb77-22"><a href="#cb77-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-23"><a href="#cb77-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"üìâ Declining Topics (top </span><span class="sc">{</span>DECLINING_TOP_N<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb77-24"><a href="#cb77-24" aria-hidden="true" tabindex="-1"></a>display(declining[[<span class="st">"topic_id"</span>, <span class="st">"total_docs"</span>, <span class="st">"slope"</span>, <span class="st">"first_year"</span>, <span class="st">"last_year"</span>, <span class="st">"volatility"</span>]])</span>
<span id="cb77-25"><a href="#cb77-25" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="plot-any-category" class="level3">
<h3 class="anchored" data-anchor-id="plot-any-category">12.6) Plot any category</h3>
<p>Why: we don‚Äôt want to rewrite the plotting code every time. Let‚Äôs make a tiny function that accepts a list of topic IDs and uses your existing trend dict.</p>
<div id="bCEeBmoi_CIS" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- after you created most_active, emerging, declining ---</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Cross-check: topic IDs used in plots vs AI labels</span></span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a><span class="co"># (for inspection only ‚Äì NOT used in visualization)</span></span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------</span></span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_topic_check(title, df_topics, labels_df):</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">üîé </span><span class="sc">{</span>title<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a>    tmp <span class="op">=</span> df_topics[[<span class="st">"topic_id"</span>]].merge(</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>        labels_df[[<span class="st">"topic_id"</span>, <span class="st">"ai_label"</span>]],</span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a>        on<span class="op">=</span><span class="st">"topic_id"</span>,</span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a>        how<span class="op">=</span><span class="st">"left"</span></span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb78-14"><a href="#cb78-14" aria-hidden="true" tabindex="-1"></a>    display(tmp)</span>
<span id="cb78-15"><a href="#cb78-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-16"><a href="#cb78-16" aria-hidden="true" tabindex="-1"></a><span class="co"># only run if we actually have AI labels</span></span>
<span id="cb78-17"><a href="#cb78-17" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"labels_df"</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb78-18"><a href="#cb78-18" aria-hidden="true" tabindex="-1"></a>    show_topic_check(<span class="st">"Most Active Topics"</span>, most_active, labels_df)</span>
<span id="cb78-19"><a href="#cb78-19" aria-hidden="true" tabindex="-1"></a>    show_topic_check(<span class="st">"Emerging / Fast-Growing Topics"</span>, emerging, labels_df)</span>
<span id="cb78-20"><a href="#cb78-20" aria-hidden="true" tabindex="-1"></a>    show_topic_check(<span class="st">"Declining Topics"</span>, declining, labels_df)</span>
<span id="cb78-21"><a href="#cb78-21" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb78-22"><a href="#cb78-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"‚ÑπÔ∏è labels_df not found ‚Äì run AI labelling section first."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="kN_mOV6vsK0x" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_topic_trends(metrics_subset, title<span class="op">=</span><span class="st">"Topic Trends"</span>):</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> metrics_subset.empty:</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"No topics to plot."</span>)</span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot each topic in the subset</span></span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _, row <span class="kw">in</span> metrics_subset.iterrows():</span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>        tid <span class="op">=</span> row[<span class="st">"topic_id"</span>]</span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> row.get(<span class="st">"ai_label"</span>, <span class="ss">f"Topic </span><span class="sc">{</span>tid<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get data</span></span>
<span id="cb79-17"><a href="#cb79-17" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> trend_dict.get(tid, {})</span>
<span id="cb79-18"><a href="#cb79-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> data: <span class="cf">continue</span></span>
<span id="cb79-19"><a href="#cb79-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-20"><a href="#cb79-20" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="bu">sorted</span>(data.keys())</span>
<span id="cb79-21"><a href="#cb79-21" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> [data[yr] <span class="cf">for</span> yr <span class="kw">in</span> x]</span>
<span id="cb79-22"><a href="#cb79-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-23"><a href="#cb79-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plot line + markers</span></span>
<span id="cb79-24"><a href="#cb79-24" aria-hidden="true" tabindex="-1"></a>        plt.plot(x, y, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss"> (T</span><span class="sc">{</span>tid<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb79-25"><a href="#cb79-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-26"><a href="#cb79-26" aria-hidden="true" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb79-27"><a href="#cb79-27" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Year"</span>)</span>
<span id="cb79-28"><a href="#cb79-28" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Documents Published"</span>)</span>
<span id="cb79-29"><a href="#cb79-29" aria-hidden="true" tabindex="-1"></a>    plt.legend(bbox_to_anchor<span class="op">=</span>(<span class="fl">1.05</span>, <span class="dv">1</span>), loc<span class="op">=</span><span class="st">'upper left'</span>)</span>
<span id="cb79-30"><a href="#cb79-30" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb79-31"><a href="#cb79-31" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb79-32"><a href="#cb79-32" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb79-33"><a href="#cb79-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-34"><a href="#cb79-34" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> metrics_df.empty:</span>
<span id="cb79-35"><a href="#cb79-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Top Active (Volume)</span></span>
<span id="cb79-36"><a href="#cb79-36" aria-hidden="true" tabindex="-1"></a>    top_active <span class="op">=</span> metrics_df.sort_values(<span class="st">"total_docs"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">5</span>)</span>
<span id="cb79-37"><a href="#cb79-37" aria-hidden="true" tabindex="-1"></a>    plot_topic_trends(top_active, <span class="st">"üî• Most Active Topics (Total Volume)"</span>)</span>
<span id="cb79-38"><a href="#cb79-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-39"><a href="#cb79-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Emerging (High Slope, Recent Activity)</span></span>
<span id="cb79-40"><a href="#cb79-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filter: Active in last 3 years, positive slope</span></span>
<span id="cb79-41"><a href="#cb79-41" aria-hidden="true" tabindex="-1"></a>    max_yr <span class="op">=</span> trend_df[year_col].<span class="bu">max</span>()</span>
<span id="cb79-42"><a href="#cb79-42" aria-hidden="true" tabindex="-1"></a>    emerging <span class="op">=</span> metrics_df[</span>
<span id="cb79-43"><a href="#cb79-43" aria-hidden="true" tabindex="-1"></a>        (metrics_df[<span class="st">"slope"</span>] <span class="op">&gt;</span> <span class="dv">0</span>) <span class="op">&amp;</span></span>
<span id="cb79-44"><a href="#cb79-44" aria-hidden="true" tabindex="-1"></a>        (metrics_df[<span class="st">"last_year"</span>] <span class="op">&gt;=</span> max_yr <span class="op">-</span> <span class="dv">2</span>)</span>
<span id="cb79-45"><a href="#cb79-45" aria-hidden="true" tabindex="-1"></a>    ].sort_values(<span class="st">"slope"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">5</span>)</span>
<span id="cb79-46"><a href="#cb79-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-47"><a href="#cb79-47" aria-hidden="true" tabindex="-1"></a>    plot_topic_trends(emerging, <span class="st">"üöÄ Emerging Topics (Fastest Growth)"</span>)</span>
<span id="cb79-48"><a href="#cb79-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-49"><a href="#cb79-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Declining (Negative Slope)</span></span>
<span id="cb79-50"><a href="#cb79-50" aria-hidden="true" tabindex="-1"></a>    declining <span class="op">=</span> metrics_df[</span>
<span id="cb79-51"><a href="#cb79-51" aria-hidden="true" tabindex="-1"></a>        metrics_df[<span class="st">"slope"</span>] <span class="op">&lt;</span> <span class="dv">0</span></span>
<span id="cb79-52"><a href="#cb79-52" aria-hidden="true" tabindex="-1"></a>    ].sort_values(<span class="st">"slope"</span>, ascending<span class="op">=</span><span class="va">True</span>).head(<span class="dv">5</span>)</span>
<span id="cb79-53"><a href="#cb79-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-54"><a href="#cb79-54" aria-hidden="true" tabindex="-1"></a>    plot_topic_trends(declining, <span class="st">"üìâ Declining Topics"</span>)</span>
<span id="cb79-55"><a href="#cb79-55" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb79-56"><a href="#cb79-56" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Metrics DF is empty, cannot plot trends."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>